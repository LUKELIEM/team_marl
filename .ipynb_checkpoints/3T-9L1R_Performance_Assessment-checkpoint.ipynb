{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Performance Assessment\n",
    "\n",
    "We implement multi-episode play in order to better assess how good a team or a culture is. The output will be averaged results over these episodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.4\n",
      "Pytorch version: 0.4.1.post2\n",
      "OpenAI Gym version: 0.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import platform\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# This is the Gathering Game Environment based on Tribal Organization of agents\n",
    "from tribes_env import GatheringEnv\n",
    "from tribes_model import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Pytorch version: {}\".format(torch.__version__))\n",
    "print(\"OpenAI Gym version: {}\".format(gym.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load random agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 427.3\n",
      "Num laser fired = 378.1\n",
      "Total US Hit (friendly fire) = 20.0\n",
      "Total THEM Hit = 131.0\n",
      "friendly fire (%) = 0.133\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 96.0\n",
      "Tribe Saxons has total reward of 219.6\n",
      "Tribe Franks has total reward of 111.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 36.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 28.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 31.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.25\n",
      "Agent3 reward is 169.1\n",
      "US agents hit = 12.1\n",
      "THEM agents hit = 88.6\n",
      "Agent4 of Saxons aggressiveness is 0.13\n",
      "Agent4 reward is 50.5\n",
      "US agents hit = 8.0\n",
      "THEM agents hit = 42.4\n",
      "Agent5 of Franks aggressiveness is 0.00\n",
      "Agent5 reward is 34.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 30.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 47.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.25 sec\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_name = 'MA_models/no_fragging/p-1.0/'\n",
    "episodes = 2000  # This is used to recall a model file trained to a # of episodes\n",
    "\n",
    "# There will be 10 agents - 3 teams of 3 AI agents each and 1 random agents\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "\n",
    "# Load models for AI agents\n",
    "if episodes > 0:\n",
    "    agents= [[] for i in range(num_ai_agents)]\n",
    "    # If episodes is provided (not 0), load the model for each AI agent\n",
    "    for i in range(num_ai_agents):\n",
    "        model_file = dir_name+'MA{}_Gather__ep{}.p'.format(i,episodes)\n",
    "        try:\n",
    "            with open(model_file, 'rb') as f:\n",
    "                # Model File include both model and optim parameters\n",
    "                saved_model = pickle.load(f)\n",
    "                agents[i], _ = saved_model\n",
    "                print(\"Load saved model for agent {}\".format(i))\n",
    "        except OSError:\n",
    "            print('Model file not found.')\n",
    "            raise\n",
    "else:\n",
    "    # If episodes=0, start with a freshly initialized model for each AI agent\n",
    "    for i in range(num_ai_agents):\n",
    "        print(\"Load AI agent {}\".format(i))\n",
    "        agents.append(Policy(num_frames, num_actions, i))\n",
    "\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load random agent {}\".format(i))\n",
    "    agents.append(Rdn_Policy())\n",
    "\n",
    "# Establish tribal association\n",
    "tribes = []\n",
    "tribes.append(Tribe(name='Vikings',color='blue', agents=[agents[0], agents[1], agents[2]]))\n",
    "tribes.append(Tribe(name='Saxons', color='red', agents=[agents[3], agents[4]]))\n",
    "tribes.append(Tribe(name='Franks', color='purple', agents=[agents[5], agents[6], agents[7]]))\n",
    "tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[8]]))   # random agents are crazy!!!\n",
    "\n",
    "# 9 agents in 4 tribes, used map defined in default.txt\n",
    "agent_colors = [agent.color for agent in agents]\n",
    "agent_tribes = [agent.tribe for agent in agents]\n",
    "env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, map_name='default')  \n",
    "\n",
    "# Used to accumulate episode stats for averaging\n",
    "cum_rewards = 0\n",
    "cum_tags = 0\n",
    "cum_US_hits = 0\n",
    "cum_THEM_hits = 0\n",
    "cum_agent_rewards = [0 for agent in agents]\n",
    "cum_agent_tags = [0 for agent in agents]\n",
    "cum_agent_US_hits = [0 for agent in agents]\n",
    "cum_agent_THEM_hits = [0 for agent in agents]\n",
    "cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "cuda = False\n",
    "start = time.time()\n",
    "\n",
    "for ep in range(max_episodes):\n",
    "    \n",
    "    print('.', end='')  # To show progress\n",
    "    \n",
    "    # Initialize AI and random agent data\n",
    "    actions = [0 for i in range(num_agents)]\n",
    "    tags = [0 for i in range(num_agents)]\n",
    "    US_hits = [0 for i in range(num_agents)]\n",
    "    THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "    env_obs = env.reset()  # Environment return observations\n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack observations into data structure compatible with agent Policy\n",
    "    agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "    for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "        agents[i].reset_info()    \n",
    "    \n",
    "    if render:\n",
    "        env.render()\n",
    "        time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "    state = np.stack([state]*num_frames)\n",
    "\n",
    "    # Reset LSTM hidden units when episode begins\n",
    "    cx = Variable(torch.zeros(1, 256))\n",
    "    hx = Variable(torch.zeros(1, 256))\n",
    "    \"\"\"\n",
    "\n",
    "    for frame in range(max_frames):\n",
    "\n",
    "        for i in range(num_ai_agents):    # For AI agents\n",
    "            actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "            if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "        for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "            actions[i] = agents[i].select_action(agents_obs[i])\n",
    "            if actions[i] is 6:\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "        \"\"\"\n",
    "        For now, we do not implement LSTM\n",
    "        # Select action\n",
    "        action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "        \"\"\"\n",
    "\n",
    "        # if frame % 10 == 0:\n",
    "        #     print (actions)    \n",
    "            \n",
    "        # Perform step        \n",
    "        env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        \"\"\"\n",
    "        For Debug only\n",
    "        print (env_obs)\n",
    "        print (reward)\n",
    "        print (done) \n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(num_ai_agents):\n",
    "            agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "        # Unpack observations into data structure compatible with agent Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "        for i in range(num_agents):\n",
    "            US_hits[i] += agents[i].US_hit\n",
    "            THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "        \"\"\"\n",
    "        For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "        # Evict oldest diff add new diff to state\n",
    "        next_state = np.stack([next_state]*num_frames)\n",
    "        next_state[1:, :, :] = state[:-1, :, :]\n",
    "        state = next_state\n",
    "        \"\"\"\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "            time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "        if any(done):\n",
    "            print(\"Done after {} frames\".format(frame))\n",
    "            break\n",
    "            \n",
    "    # Print out statistics of AI agents\n",
    "    ep_rewards = 0\n",
    "    ep_tags = 0\n",
    "    ep_US_hits = 0\n",
    "    ep_THEM_hits = 0\n",
    "\n",
    "    if verbose:\n",
    "        print ('\\nStatistics by Agent')\n",
    "        print ('===================')\n",
    "    for i in range(num_ai_agents):\n",
    "        agent_tags = sum(agents[i].tag_hist)\n",
    "        ep_tags += agent_tags\n",
    "        cum_agent_tags[i] += agent_tags\n",
    "\n",
    "        agent_reward = sum(agents[i].rewards)\n",
    "        ep_rewards += agent_reward\n",
    "        cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "        agent_US_hits = sum(agents[i].US_hits)\n",
    "        agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "        ep_US_hits += agent_US_hits\n",
    "        ep_THEM_hits += agent_THEM_hits\n",
    "        cum_agent_US_hits[i] += agent_US_hits\n",
    "        cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "        if verbose:\n",
    "            print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "            print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "            print('US agents hit = {}'.format(agent_US_hits))\n",
    "            print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "    cum_rewards += ep_rewards\n",
    "    cum_tags += ep_tags\n",
    "    cum_US_hits += ep_US_hits\n",
    "    cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "    if verbose:\n",
    "        print ('\\nStatistics in Aggregate')\n",
    "        print ('=======================')\n",
    "        print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "        print ('Num laser fired = {}'.format(ep_tags))\n",
    "        print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "        print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "        print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "    if verbose:\n",
    "        print ('\\nStatistics by Tribe')\n",
    "        print ('===================')\n",
    "    for i, t in enumerate(tribes):\n",
    "        if t.name is not 'Crazies':\n",
    "            ep_tribe_reward = sum(t.sum_rewards())\n",
    "            cum_tribe_rewards[i] += ep_tribe_reward\n",
    "            if verbose:\n",
    "                print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "    for i in range(num_ai_agents):\n",
    "        agents[i].clear_history()\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "end = time.time()\n",
    "\n",
    "print ('\\nAverage Statistics in Aggregate')\n",
    "print ('=================================')\n",
    "print ('Total rewards gathered = {:.1f}'.format(cum_rewards/max_episodes))\n",
    "print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "print ('\\nAverage Statistics by Tribe')\n",
    "print ('=============================')\n",
    "for i, t in enumerate(tribes):\n",
    "    if t.name is not 'Crazies':\n",
    "        print ('Tribe {} has total reward of {:.1f}'.format(t.name, cum_tribe_rewards[i]/max_episodes))    \n",
    "\n",
    "print ('\\nAverage Statistics by Agent')\n",
    "print ('=============================')\n",
    "for i in range(num_ai_agents):\n",
    "    print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "    print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "    print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "    print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L1R/Indiv/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 305.2\n",
      "33.91481481481482\n",
      "Num laser fired = 588.8\n",
      "Total US Hit (friendly fire) = 79.1\n",
      "Total THEM Hit = 145.6\n",
      "friendly fire (%) = 0.352\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 21.2\n",
      "Tribe Saxons has total reward of 21.5\n",
      "Tribe Franks has total reward of 262.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 14.1\n",
      "Agent1 of Vikings aggressiveness is 0.11\n",
      "Agent1 reward is 0.1\n",
      "US agents hit = 11.4\n",
      "THEM agents hit = 26.9\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 21.1\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 2.2\n",
      "Agent3 of Saxons aggressiveness is 0.05\n",
      "Agent3 reward is 16.0\n",
      "US agents hit = 7.6\n",
      "THEM agents hit = 19.1\n",
      "Agent4 of Saxons aggressiveness is 0.21\n",
      "Agent4 reward is 0.3\n",
      "US agents hit = 21.5\n",
      "THEM agents hit = 49.8\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 5.2\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 2.5\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 83.5\n",
      "US agents hit = 8.6\n",
      "THEM agents hit = 9.4\n",
      "Agent7 of Franks aggressiveness is 0.10\n",
      "Agent7 reward is 114.1\n",
      "US agents hit = 17.5\n",
      "THEM agents hit = 15.9\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 65.0\n",
      "US agents hit = 4.9\n",
      "THEM agents hit = 5.7\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 356.2\n",
      "39.577777777777776\n",
      "Num laser fired = 656.5\n",
      "Total US Hit (friendly fire) = 65.2\n",
      "Total THEM Hit = 147.1\n",
      "friendly fire (%) = 0.307\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 31.0\n",
      "Tribe Saxons has total reward of 49.5\n",
      "Tribe Franks has total reward of 275.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.05\n",
      "Agent0 reward is 0.1\n",
      "US agents hit = 4.1\n",
      "THEM agents hit = 18.3\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 9.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 21.0\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 2.8\n",
      "Agent3 of Saxons aggressiveness is 0.06\n",
      "Agent3 reward is 33.7\n",
      "US agents hit = 4.7\n",
      "THEM agents hit = 18.2\n",
      "Agent4 of Saxons aggressiveness is 0.38\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 22.6\n",
      "THEM agents hit = 56.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 15.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 0.06\n",
      "Agent6 reward is 83.2\n",
      "US agents hit = 11.8\n",
      "THEM agents hit = 22.8\n",
      "Agent7 of Franks aggressiveness is 0.06\n",
      "Agent7 reward is 115.9\n",
      "US agents hit = 15.6\n",
      "THEM agents hit = 17.3\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 76.7\n",
      "US agents hit = 5.6\n",
      "THEM agents hit = 10.8\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 324.3\n",
      "36.029629629629625\n",
      "Num laser fired = 763.7\n",
      "Total US Hit (friendly fire) = 62.4\n",
      "Total THEM Hit = 151.4\n",
      "friendly fire (%) = 0.292\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 21.2\n",
      "Tribe Saxons has total reward of 75.5\n",
      "Tribe Franks has total reward of 227.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 4.9\n",
      "THEM agents hit = 14.9\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 7.5\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 0.3\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 13.6\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 2.7\n",
      "Agent3 of Saxons aggressiveness is 0.07\n",
      "Agent3 reward is 47.9\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 23.7\n",
      "Agent4 of Saxons aggressiveness is 0.43\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 21.9\n",
      "THEM agents hit = 61.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 27.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 52.6\n",
      "US agents hit = 6.2\n",
      "THEM agents hit = 8.4\n",
      "Agent7 of Franks aggressiveness is 0.12\n",
      "Agent7 reward is 112.6\n",
      "US agents hit = 17.4\n",
      "THEM agents hit = 23.6\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 62.3\n",
      "US agents hit = 7.9\n",
      "THEM agents hit = 16.5\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 328.6\n",
      "36.51111111111111\n",
      "Num laser fired = 762.4\n",
      "Total US Hit (friendly fire) = 63.1\n",
      "Total THEM Hit = 178.1\n",
      "friendly fire (%) = 0.262\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 35.2\n",
      "Tribe Saxons has total reward of 98.0\n",
      "Tribe Franks has total reward of 195.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.07\n",
      "Agent0 reward is 18.0\n",
      "US agents hit = 11.3\n",
      "THEM agents hit = 49.7\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 8.4\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 0.5\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 8.8\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.7\n",
      "Agent3 of Saxons aggressiveness is 0.08\n",
      "Agent3 reward is 62.5\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 28.4\n",
      "Agent4 of Saxons aggressiveness is 0.41\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 18.1\n",
      "THEM agents hit = 45.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 35.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.08\n",
      "Agent6 reward is 53.2\n",
      "US agents hit = 11.1\n",
      "THEM agents hit = 18.6\n",
      "Agent7 of Franks aggressiveness is 0.05\n",
      "Agent7 reward is 96.7\n",
      "US agents hit = 15.2\n",
      "THEM agents hit = 24.4\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 45.4\n",
      "US agents hit = 4.5\n",
      "THEM agents hit = 10.6\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 343.8\n",
      "38.196296296296296\n",
      "Num laser fired = 882.0\n",
      "Total US Hit (friendly fire) = 59.2\n",
      "Total THEM Hit = 172.4\n",
      "friendly fire (%) = 0.256\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 48.2\n",
      "Tribe Saxons has total reward of 90.1\n",
      "Tribe Franks has total reward of 205.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.07\n",
      "Agent0 reward is 18.8\n",
      "US agents hit = 3.4\n",
      "THEM agents hit = 41.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 20.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 8.6\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.4\n",
      "Agent3 of Saxons aggressiveness is 0.08\n",
      "Agent3 reward is 57.3\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 22.3\n",
      "Agent4 of Saxons aggressiveness is 0.50\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 19.7\n",
      "THEM agents hit = 45.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 32.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.06\n",
      "Agent6 reward is 63.5\n",
      "US agents hit = 10.2\n",
      "THEM agents hit = 15.1\n",
      "Agent7 of Franks aggressiveness is 0.08\n",
      "Agent7 reward is 75.7\n",
      "US agents hit = 13.1\n",
      "THEM agents hit = 27.3\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 66.3\n",
      "US agents hit = 10.4\n",
      "THEM agents hit = 19.8\n",
      "Training time per epochs: 2.99 sec\n",
      "[[33.91481481481482, 39.577777777777776, 36.029629629629625, 36.51111111111111, 38.196296296296296]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = ['MA_models/3T-9L1R/Indiv/']\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"individualist\"\n",
    "\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 10 agents - 3 teams of 3 AI agents each and 1 random agents\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather_ep_{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        print ('Total rewards gathered = {:.1f}'.format(cum_rewards/max_episodes))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print (av_agent_reward[dir_num][eps_num])\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "        for i, t in enumerate(tribes):\n",
    "            if t.name is not 'Crazies':\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(t.name, cum_tribe_rewards[i]/max_episodes))    \n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "                              \n",
    "print (av_agent_reward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Agent Reward - Individualist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.91481481481482, 39.577777777777776, 36.029629629629625, 36.51111111111111, 38.196296296296296]\n"
     ]
    }
   ],
   "source": [
    "for reward in av_agent_reward:\n",
    "    print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L1R/pacifist/p-0.01/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 505.0\n",
      "56.11481481481482\n",
      "Num laser fired = 0.9\n",
      "Total US Hit (friendly fire) = 0.4\n",
      "Total THEM Hit = 1.2\n",
      "friendly fire (%) = 0.265\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 66.8\n",
      "Tribe Saxons has total reward of 168.3\n",
      "Tribe Franks has total reward of 269.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 66.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 69.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 22.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 77.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 87.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 100.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 81.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Training time per epochs: 3.93 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 396.3\n",
      "44.03703703703704\n",
      "Num laser fired = 213.5\n",
      "Total US Hit (friendly fire) = 29.7\n",
      "Total THEM Hit = 60.6\n",
      "friendly fire (%) = 0.329\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 29.1\n",
      "Tribe Saxons has total reward of 110.6\n",
      "Tribe Franks has total reward of 256.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 29.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 37.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 30.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 43.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 53.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 63.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.21\n",
      "Agent8 reward is 139.0\n",
      "US agents hit = 29.7\n",
      "THEM agents hit = 60.5\n",
      "Training time per epochs: 3.87 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 469.6\n",
      "52.17407407407407\n",
      "Num laser fired = 57.6\n",
      "Total US Hit (friendly fire) = 25.4\n",
      "Total THEM Hit = 49.5\n",
      "friendly fire (%) = 0.339\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 30.2\n",
      "Tribe Saxons has total reward of 130.2\n",
      "Tribe Franks has total reward of 309.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 30.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 42.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 47.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 39.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 67.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 84.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 156.9\n",
      "US agents hit = 25.4\n",
      "THEM agents hit = 49.5\n",
      "Training time per epochs: 3.83 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 480.0\n",
      "53.33703703703704\n",
      "Num laser fired = 120.8\n",
      "Total US Hit (friendly fire) = 29.4\n",
      "Total THEM Hit = 63.5\n",
      "friendly fire (%) = 0.316\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 24.7\n",
      "Tribe Saxons has total reward of 118.9\n",
      "Tribe Franks has total reward of 336.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 24.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 33.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 43.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 42.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 56.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 60.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.12\n",
      "Agent8 reward is 219.5\n",
      "US agents hit = 29.4\n",
      "THEM agents hit = 63.4\n",
      "Training time per epochs: 3.84 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 534.2\n",
      "59.35555555555556\n",
      "Num laser fired = 205.1\n",
      "Total US Hit (friendly fire) = 21.8\n",
      "Total THEM Hit = 55.4\n",
      "friendly fire (%) = 0.283\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 28.6\n",
      "Tribe Saxons has total reward of 174.8\n",
      "Tribe Franks has total reward of 330.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 28.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 46.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 58.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 69.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 74.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 79.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.21\n",
      "Agent8 reward is 176.2\n",
      "US agents hit = 21.8\n",
      "THEM agents hit = 55.4\n",
      "Training time per epochs: 3.83 sec\n",
      "###### Dir = MA_models/3T-9L1R/pacifist/p-0.1/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 480.6\n",
      "53.400000000000006\n",
      "Num laser fired = 105.4\n",
      "Total US Hit (friendly fire) = 25.5\n",
      "Total THEM Hit = 64.1\n",
      "friendly fire (%) = 0.285\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 62.1\n",
      "Tribe Saxons has total reward of 141.2\n",
      "Tribe Franks has total reward of 277.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 23.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 39.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 31.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 58.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 51.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 58.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 38.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 180.2\n",
      "US agents hit = 25.4\n",
      "THEM agents hit = 63.8\n",
      "Training time per epochs: 3.86 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 508.5\n",
      "56.49629629629629\n",
      "Num laser fired = 126.6\n",
      "Total US Hit (friendly fire) = 25.5\n",
      "Total THEM Hit = 61.1\n",
      "friendly fire (%) = 0.294\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 71.2\n",
      "Tribe Saxons has total reward of 162.2\n",
      "Tribe Franks has total reward of 275.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 23.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 47.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 44.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 57.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 59.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 59.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 43.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.13\n",
      "Agent8 reward is 173.1\n",
      "US agents hit = 25.5\n",
      "THEM agents hit = 61.1\n",
      "Training time per epochs: 3.80 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 528.0\n",
      "58.662962962962965\n",
      "Num laser fired = 87.2\n",
      "Total US Hit (friendly fire) = 24.7\n",
      "Total THEM Hit = 43.4\n",
      "friendly fire (%) = 0.362\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 54.0\n",
      "Tribe Saxons has total reward of 147.1\n",
      "Tribe Franks has total reward of 326.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 54.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 40.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 53.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 53.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 55.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 50.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 221.3\n",
      "US agents hit = 24.7\n",
      "THEM agents hit = 43.4\n",
      "Training time per epochs: 3.88 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 566.0\n",
      "62.89259259259259\n",
      "Num laser fired = 56.7\n",
      "Total US Hit (friendly fire) = 23.6\n",
      "Total THEM Hit = 62.9\n",
      "friendly fire (%) = 0.273\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 54.0\n",
      "Tribe Saxons has total reward of 139.8\n",
      "Tribe Franks has total reward of 372.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 54.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 42.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 45.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 52.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 60.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 52.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 260.3\n",
      "US agents hit = 23.6\n",
      "THEM agents hit = 62.8\n",
      "Training time per epochs: 3.83 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 528.9\n",
      "58.770370370370365\n",
      "Num laser fired = 93.4\n",
      "Total US Hit (friendly fire) = 24.0\n",
      "Total THEM Hit = 58.8\n",
      "friendly fire (%) = 0.290\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 42.4\n",
      "Tribe Saxons has total reward of 136.1\n",
      "Tribe Franks has total reward of 350.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 42.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 37.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 58.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 40.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 58.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 37.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 254.8\n",
      "US agents hit = 24.0\n",
      "THEM agents hit = 58.8\n",
      "Training time per epochs: 3.87 sec\n",
      "###### Dir = MA_models/3T-9L1R/pacifist/p-1.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 511.5\n",
      "56.82962962962963\n",
      "Num laser fired = 0.2\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.3\n",
      "friendly fire (%) = 0.100\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 176.4\n",
      "Tribe Saxons has total reward of 138.5\n",
      "Tribe Franks has total reward of 196.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 32.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 67.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 76.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 26.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 57.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 54.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 67.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 55.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 73.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.89 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 562.3\n",
      "62.48148148148149\n",
      "Num laser fired = 0.4\n",
      "Total US Hit (friendly fire) = 0.3\n",
      "Total THEM Hit = 1.3\n",
      "friendly fire (%) = 0.204\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 183.7\n",
      "Tribe Saxons has total reward of 157.7\n",
      "Tribe Franks has total reward of 220.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 51.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 58.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 73.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 34.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 62.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 61.2\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 68.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 65.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 86.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.93 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 547.6\n",
      "60.84444444444445\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 128.5\n",
      "Tribe Saxons has total reward of 185.4\n",
      "Tribe Franks has total reward of 233.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 44.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 3.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 80.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 38.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 80.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 66.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 84.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 72.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 76.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.86 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 550.2\n",
      "61.129629629629626\n",
      "Num laser fired = 29.6\n",
      "Total US Hit (friendly fire) = 15.8\n",
      "Total THEM Hit = 50.0\n",
      "friendly fire (%) = 0.240\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 126.2\n",
      "Tribe Saxons has total reward of 229.0\n",
      "Tribe Franks has total reward of 195.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 45.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 44.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 36.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 28.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 59.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 141.6\n",
      "US agents hit = 15.8\n",
      "THEM agents hit = 50.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 64.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 62.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 67.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.86 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 565.5\n",
      "62.829629629629636\n",
      "Num laser fired = 25.6\n",
      "Total US Hit (friendly fire) = 15.9\n",
      "Total THEM Hit = 49.3\n",
      "friendly fire (%) = 0.244\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 144.4\n",
      "Tribe Saxons has total reward of 244.4\n",
      "Tribe Franks has total reward of 176.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 48.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 49.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 46.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 26.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 65.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 152.7\n",
      "US agents hit = 15.9\n",
      "THEM agents hit = 49.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 66.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 50.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 59.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.82 sec\n",
      "###### Dir = MA_models/3T-9L1R/pacifist/p-10.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 537.7\n",
      "59.74074074074073\n",
      "Num laser fired = 0.1\n",
      "Total US Hit (friendly fire) = 0.1\n",
      "Total THEM Hit = 0.2\n",
      "friendly fire (%) = 0.222\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 145.5\n",
      "Tribe Saxons has total reward of 193.3\n",
      "Tribe Franks has total reward of 198.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 50.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 23.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 72.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 80.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 56.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 56.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 52.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 58.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 87.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 3.89 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 564.1\n",
      "62.67777777777778\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 170.1\n",
      "Tribe Saxons has total reward of 180.1\n",
      "Tribe Franks has total reward of 213.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 52.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 36.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 81.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 63.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 55.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 60.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 72.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 52.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 89.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.87 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 566.5\n",
      "62.94814814814814\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 162.1\n",
      "Tribe Saxons has total reward of 184.5\n",
      "Tribe Franks has total reward of 220.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 48.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 52.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 61.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 71.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 52.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 60.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 65.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 79.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 74.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.86 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 588.5\n",
      "65.3851851851852\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 124.6\n",
      "Tribe Saxons has total reward of 213.9\n",
      "Tribe Franks has total reward of 250.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 63.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 61.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 82.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 58.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 73.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 76.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 81.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 92.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.89 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 571.1\n",
      "63.459259259259255\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 111.2\n",
      "Tribe Saxons has total reward of 216.7\n",
      "Tribe Franks has total reward of 243.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 58.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 53.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 77.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 56.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 82.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 73.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 81.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 87.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.86 sec\n",
      "###### Dir = MA_models/3T-9L1R/pacifist/p-100.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 524.9\n",
      "58.32592592592592\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 138.7\n",
      "Tribe Saxons has total reward of 173.3\n",
      "Tribe Franks has total reward of 212.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 43.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 27.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 67.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 46.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 60.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 66.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 62.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 72.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 78.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.86 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 567.4\n",
      "63.048148148148144\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 138.3\n",
      "Tribe Saxons has total reward of 170.9\n",
      "Tribe Franks has total reward of 258.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 36.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 29.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 72.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 47.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 65.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 57.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 78.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 86.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 93.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.85 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 575.6\n",
      "63.951851851851856\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 171.1\n",
      "Tribe Saxons has total reward of 167.6\n",
      "Tribe Franks has total reward of 236.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 58.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 48.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 64.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 53.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 57.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 57.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 71.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 82.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 82.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.85 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 568.4\n",
      "63.15555555555555\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 176.5\n",
      "Tribe Saxons has total reward of 171.8\n",
      "Tribe Franks has total reward of 220.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 53.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 58.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 64.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 57.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 53.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 61.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 73.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 52.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 93.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.85 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 584.2\n",
      "64.91111111111111\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 177.1\n",
      "Tribe Saxons has total reward of 173.5\n",
      "Tribe Franks has total reward of 233.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 57.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 58.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 61.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 55.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 62.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 55.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 84.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 71.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 78.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.88 sec\n",
      "[[56.11481481481482, 44.03703703703704, 52.17407407407407, 53.33703703703704, 59.35555555555556], [53.400000000000006, 56.49629629629629, 58.662962962962965, 62.89259259259259, 58.770370370370365], [56.82962962962963, 62.48148148148149, 60.84444444444445, 61.129629629629626, 62.829629629629636], [59.74074074074073, 62.67777777777778, 62.94814814814814, 65.3851851851852, 63.459259259259255], [58.32592592592592, 63.048148148148144, 63.951851851851856, 63.15555555555555, 64.91111111111111]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\"MA_models/3T-9L1R/pacifist/p-0.01/\",\n",
    "             \"MA_models/3T-9L1R/pacifist/p-0.1/\", \n",
    "             \"MA_models/3T-9L1R/pacifist/p-1.0/\",\n",
    "             \"MA_models/3T-9L1R/pacifist/p-10.0/\",\n",
    "             \"MA_models/3T-9L1R/pacifist/p-100.0/\"]\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"pacifist\"\n",
    "\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 10 agents - 3 teams of 3 AI agents each and 1 random agents\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather__ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        print ('Total rewards gathered = {:.1f}'.format(cum_rewards/max_episodes))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print (av_agent_reward[dir_num][eps_num])\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "        for i, t in enumerate(tribes):\n",
    "            if t.name is not 'Crazies':\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(t.name, cum_tribe_rewards[i]/max_episodes))    \n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "                              \n",
    "print (av_agent_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Agent Reward - Pacifists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.11481481481482, 44.03703703703704, 52.17407407407407, 53.33703703703704, 59.35555555555556]\n",
      "[53.400000000000006, 56.49629629629629, 58.662962962962965, 62.89259259259259, 58.770370370370365]\n",
      "[56.82962962962963, 62.48148148148149, 60.84444444444445, 61.129629629629626, 62.829629629629636]\n",
      "[59.74074074074073, 62.67777777777778, 62.94814814814814, 65.3851851851852, 63.459259259259255]\n",
      "[58.32592592592592, 63.048148148148144, 63.951851851851856, 63.15555555555555, 64.91111111111111]\n"
     ]
    }
   ],
   "source": [
    "for reward in av_agent_reward:\n",
    "    print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L1R/no_fragging/p-0.01/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 423.5\n",
      "47.05555555555556\n",
      "Num laser fired = 205.5\n",
      "Total US Hit (friendly fire) = 31.3\n",
      "Total THEM Hit = 128.6\n",
      "friendly fire (%) = 0.196\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.4\n",
      "Tribe Saxons has total reward of 122.4\n",
      "Tribe Franks has total reward of 104.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 22.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 13.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.15\n",
      "Agent2 reward is 159.8\n",
      "US agents hit = 22.2\n",
      "THEM agents hit = 93.6\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 30.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 26.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.05\n",
      "Agent5 reward is 65.4\n",
      "US agents hit = 7.8\n",
      "THEM agents hit = 30.5\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 31.5\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 34.5\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 38.7\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 2.7\n",
      "Training time per epochs: 3.18 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 406.4\n",
      "45.15555555555555\n",
      "Num laser fired = 250.1\n",
      "Total US Hit (friendly fire) = 39.8\n",
      "Total THEM Hit = 179.0\n",
      "friendly fire (%) = 0.182\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 213.8\n",
      "Tribe Saxons has total reward of 135.9\n",
      "Tribe Franks has total reward of 56.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 41.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 19.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.14\n",
      "Agent2 reward is 152.9\n",
      "US agents hit = 25.8\n",
      "THEM agents hit = 105.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 29.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 19.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.11\n",
      "Agent5 reward is 86.3\n",
      "US agents hit = 13.9\n",
      "THEM agents hit = 73.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 16.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 16.4\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 23.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 3.15 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 437.3\n",
      "48.58888888888889\n",
      "Num laser fired = 223.4\n",
      "Total US Hit (friendly fire) = 38.6\n",
      "Total THEM Hit = 159.6\n",
      "friendly fire (%) = 0.195\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 209.7\n",
      "Tribe Saxons has total reward of 129.1\n",
      "Tribe Franks has total reward of 98.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 24.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 37.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.11\n",
      "Agent2 reward is 148.6\n",
      "US agents hit = 22.9\n",
      "THEM agents hit = 101.3\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 24.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 8.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.11\n",
      "Agent5 reward is 96.0\n",
      "US agents hit = 15.1\n",
      "THEM agents hit = 56.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 22.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 42.4\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 33.4\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.8\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 445.9\n",
      "49.54814814814815\n",
      "Num laser fired = 361.0\n",
      "Total US Hit (friendly fire) = 36.2\n",
      "Total THEM Hit = 174.5\n",
      "friendly fire (%) = 0.172\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 235.8\n",
      "Tribe Saxons has total reward of 137.7\n",
      "Tribe Franks has total reward of 72.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 30.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 25.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.18\n",
      "Agent2 reward is 180.5\n",
      "US agents hit = 26.0\n",
      "THEM agents hit = 100.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 30.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 12.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.18\n",
      "Agent5 reward is 95.3\n",
      "US agents hit = 10.2\n",
      "THEM agents hit = 73.9\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 25.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 19.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 27.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 450.9\n",
      "50.096296296296295\n",
      "Num laser fired = 245.9\n",
      "Total US Hit (friendly fire) = 42.2\n",
      "Total THEM Hit = 170.0\n",
      "friendly fire (%) = 0.199\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 235.8\n",
      "Tribe Saxons has total reward of 145.1\n",
      "Tribe Franks has total reward of 69.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 28.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 28.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.12\n",
      "Agent2 reward is 178.7\n",
      "US agents hit = 25.7\n",
      "THEM agents hit = 118.9\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 32.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 105.9\n",
      "US agents hit = 16.5\n",
      "THEM agents hit = 51.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 18.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 30.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 21.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Dir = MA_models/3T-9L1R/no_fragging/p-0.1/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 393.6\n",
      "43.733333333333334\n",
      "Num laser fired = 371.7\n",
      "Total US Hit (friendly fire) = 27.5\n",
      "Total THEM Hit = 131.6\n",
      "friendly fire (%) = 0.173\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 22.4\n",
      "Tribe Saxons has total reward of 50.1\n",
      "Tribe Franks has total reward of 321.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 10.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 11.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 17.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 16.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 16.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 76.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.37\n",
      "Agent7 reward is 192.0\n",
      "US agents hit = 26.8\n",
      "THEM agents hit = 129.8\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 52.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 440.1\n",
      "48.8962962962963\n",
      "Num laser fired = 243.2\n",
      "Total US Hit (friendly fire) = 34.9\n",
      "Total THEM Hit = 121.1\n",
      "friendly fire (%) = 0.224\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 49.6\n",
      "Tribe Saxons has total reward of 209.2\n",
      "Tribe Franks has total reward of 181.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 24.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 1.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 23.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 27.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 19.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 161.9\n",
      "US agents hit = 22.0\n",
      "THEM agents hit = 74.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 50.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.12\n",
      "Agent7 reward is 98.9\n",
      "US agents hit = 12.9\n",
      "THEM agents hit = 46.7\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 32.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 466.9\n",
      "51.88148148148148\n",
      "Num laser fired = 281.8\n",
      "Total US Hit (friendly fire) = 34.2\n",
      "Total THEM Hit = 122.7\n",
      "friendly fire (%) = 0.218\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 58.0\n",
      "Tribe Saxons has total reward of 207.7\n",
      "Tribe Franks has total reward of 201.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 23.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 9.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 25.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 26.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 28.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.13\n",
      "Agent5 reward is 153.3\n",
      "US agents hit = 19.1\n",
      "THEM agents hit = 68.4\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 36.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.15\n",
      "Agent7 reward is 122.7\n",
      "US agents hit = 15.1\n",
      "THEM agents hit = 54.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 42.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.03 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 464.8\n",
      "51.64074074074074\n",
      "Num laser fired = 352.7\n",
      "Total US Hit (friendly fire) = 41.8\n",
      "Total THEM Hit = 139.4\n",
      "friendly fire (%) = 0.231\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 50.5\n",
      "Tribe Saxons has total reward of 209.0\n",
      "Tribe Franks has total reward of 205.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 22.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 7.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 20.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 17.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 20.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.21\n",
      "Agent5 reward is 171.8\n",
      "US agents hit = 24.7\n",
      "THEM agents hit = 77.6\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 27.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.14\n",
      "Agent7 reward is 138.3\n",
      "US agents hit = 17.1\n",
      "THEM agents hit = 61.8\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 40.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 485.3\n",
      "53.91851851851852\n",
      "Num laser fired = 230.8\n",
      "Total US Hit (friendly fire) = 35.8\n",
      "Total THEM Hit = 128.6\n",
      "friendly fire (%) = 0.218\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 58.3\n",
      "Tribe Saxons has total reward of 223.1\n",
      "Tribe Franks has total reward of 203.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 26.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 12.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 19.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 25.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 30.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.14\n",
      "Agent5 reward is 166.9\n",
      "US agents hit = 21.2\n",
      "THEM agents hit = 77.4\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 22.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.09\n",
      "Agent7 reward is 137.3\n",
      "US agents hit = 14.5\n",
      "THEM agents hit = 51.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 44.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Dir = MA_models/3T-9L1R/no_fragging/p-1.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 433.6\n",
      "48.17407407407407\n",
      "Num laser fired = 160.2\n",
      "Total US Hit (friendly fire) = 30.1\n",
      "Total THEM Hit = 90.7\n",
      "friendly fire (%) = 0.249\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 76.7\n",
      "Tribe Saxons has total reward of 102.9\n",
      "Tribe Franks has total reward of 253.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 22.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 28.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 25.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 22.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 44.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 36.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 28.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.16\n",
      "Agent7 reward is 166.8\n",
      "US agents hit = 29.8\n",
      "THEM agents hit = 90.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 58.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 508.0\n",
      "56.44814814814815\n",
      "Num laser fired = 170.3\n",
      "Total US Hit (friendly fire) = 32.3\n",
      "Total THEM Hit = 90.5\n",
      "friendly fire (%) = 0.263\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 80.1\n",
      "Tribe Saxons has total reward of 110.6\n",
      "Tribe Franks has total reward of 317.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 18.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 26.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 35.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 22.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 47.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 40.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 38.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.17\n",
      "Agent7 reward is 228.3\n",
      "US agents hit = 32.3\n",
      "THEM agents hit = 90.5\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 50.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 510.0\n",
      "56.66296296296296\n",
      "Num laser fired = 231.4\n",
      "Total US Hit (friendly fire) = 35.8\n",
      "Total THEM Hit = 96.7\n",
      "friendly fire (%) = 0.270\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 70.3\n",
      "Tribe Saxons has total reward of 94.1\n",
      "Tribe Franks has total reward of 345.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 18.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 24.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 28.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 19.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 37.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 37.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 37.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.23\n",
      "Agent7 reward is 261.9\n",
      "US agents hit = 35.7\n",
      "THEM agents hit = 96.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 46.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 545.1\n",
      "60.56296296296297\n",
      "Num laser fired = 181.3\n",
      "Total US Hit (friendly fire) = 32.2\n",
      "Total THEM Hit = 92.4\n",
      "friendly fire (%) = 0.258\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 74.9\n",
      "Tribe Saxons has total reward of 123.0\n",
      "Tribe Franks has total reward of 347.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 16.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 32.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 26.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 24.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 51.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 46.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 41.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.18\n",
      "Agent7 reward is 244.3\n",
      "US agents hit = 32.2\n",
      "THEM agents hit = 92.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 61.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 547.6\n",
      "60.84814814814815\n",
      "Num laser fired = 91.6\n",
      "Total US Hit (friendly fire) = 28.7\n",
      "Total THEM Hit = 85.2\n",
      "friendly fire (%) = 0.252\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 86.6\n",
      "Tribe Saxons has total reward of 119.1\n",
      "Tribe Franks has total reward of 341.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 14.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 40.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 31.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 26.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 46.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 46.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 48.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.09\n",
      "Agent7 reward is 232.9\n",
      "US agents hit = 28.7\n",
      "THEM agents hit = 85.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 60.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.03 sec\n",
      "###### Dir = MA_models/3T-9L1R/no_fragging/p-10.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 530.6\n",
      "58.959259259259255\n",
      "Num laser fired = 0.6\n",
      "Total US Hit (friendly fire) = 0.1\n",
      "Total THEM Hit = 0.6\n",
      "friendly fire (%) = 0.136\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 112.2\n",
      "Tribe Saxons has total reward of 187.6\n",
      "Tribe Franks has total reward of 230.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 47.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 64.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 58.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 68.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 61.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 69.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 86.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 75.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 545.1\n",
      "60.56666666666667\n",
      "Num laser fired = 0.1\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 120.1\n",
      "Tribe Saxons has total reward of 176.1\n",
      "Tribe Franks has total reward of 248.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 54.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 65.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 58.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 57.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 60.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 71.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 89.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 87.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 564.3\n",
      "62.70370370370371\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.1\n",
      "friendly fire (%) = 0.333\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 117.1\n",
      "Tribe Saxons has total reward of 180.1\n",
      "Tribe Franks has total reward of 267.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 49.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 67.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 51.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 71.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 57.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 80.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 79.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 107.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 598.6\n",
      "66.50740740740741\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.4\n",
      "Tribe Saxons has total reward of 189.4\n",
      "Tribe Franks has total reward of 268.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 61.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 79.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 59.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 70.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 59.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 81.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 92.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 95.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 559.6\n",
      "62.17407407407408\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 152.1\n",
      "Tribe Saxons has total reward of 225.8\n",
      "Tribe Franks has total reward of 181.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 68.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 84.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 63.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 84.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 78.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 61.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 120.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.04 sec\n",
      "###### Dir = MA_models/3T-9L1R/no_fragging/p-100.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 545.5\n",
      "60.60740740740741\n",
      "Num laser fired = 0.1\n",
      "Total US Hit (friendly fire) = 0.1\n",
      "Total THEM Hit = 0.3\n",
      "friendly fire (%) = 0.273\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 132.4\n",
      "Tribe Saxons has total reward of 193.6\n",
      "Tribe Franks has total reward of 219.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 29.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 54.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 48.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 51.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 81.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 60.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 70.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 65.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 84.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 573.3\n",
      "63.70370370370371\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 159.0\n",
      "Tribe Saxons has total reward of 177.9\n",
      "Tribe Franks has total reward of 236.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 47.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 52.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 59.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 47.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 64.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 66.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 75.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 84.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 77.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 569.7\n",
      "63.29629629629629\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 172.8\n",
      "Tribe Saxons has total reward of 166.3\n",
      "Tribe Franks has total reward of 230.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 46.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 62.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 64.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 47.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 73.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 45.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 72.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 71.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 86.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 579.2\n",
      "64.35925925925926\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 181.1\n",
      "Tribe Saxons has total reward of 181.1\n",
      "Tribe Franks has total reward of 217.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 51.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 58.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 71.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 49.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 73.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 58.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 72.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 79.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 65.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 564.2\n",
      "62.68518518518518\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.5\n",
      "Tribe Saxons has total reward of 168.2\n",
      "Tribe Franks has total reward of 211.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 46.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 61.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 77.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 94.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 74.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 64.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 77.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 69.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.07 sec\n",
      "[[47.05555555555556, 45.15555555555555, 48.58888888888889, 49.54814814814815, 50.096296296296295], [43.733333333333334, 48.8962962962963, 51.88148148148148, 51.64074074074074, 53.91851851851852], [48.17407407407407, 56.44814814814815, 56.66296296296296, 60.56296296296297, 60.84814814814815], [58.959259259259255, 60.56666666666667, 62.70370370370371, 66.50740740740741, 62.17407407407408], [60.60740740740741, 63.70370370370371, 63.29629629629629, 64.35925925925926, 62.68518518518518]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\"MA_models/3T-9L1R/no_fragging/p-0.01/\",\n",
    "             \"MA_models/3T-9L1R/no_fragging/p-0.1/\", \n",
    "             \"MA_models/3T-9L1R/no_fragging/p-1.0/\",\n",
    "             \"MA_models/3T-9L1R/no_fragging/p-10.0/\",\n",
    "             \"MA_models/3T-9L1R/no_fragging/p-100.0/\"]\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"no_fragging\"\n",
    "\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 10 agents - 3 teams of 3 AI agents each and 1 random agents\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather__ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        print ('Total rewards gathered = {:.1f}'.format(cum_rewards/max_episodes))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print (av_agent_reward[dir_num][eps_num])\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "        for i, t in enumerate(tribes):\n",
    "            if t.name is not 'Crazies':\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(t.name, cum_tribe_rewards[i]/max_episodes))    \n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "                              \n",
    "print (av_agent_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Agent Reward - No Fraticide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.05555555555556, 45.15555555555555, 48.58888888888889, 49.54814814814815, 50.096296296296295]\n",
      "[43.733333333333334, 48.8962962962963, 51.88148148148148, 51.64074074074074, 53.91851851851852]\n",
      "[48.17407407407407, 56.44814814814815, 56.66296296296296, 60.56296296296297, 60.84814814814815]\n",
      "[58.959259259259255, 60.56666666666667, 62.70370370370371, 66.50740740740741, 62.17407407407408]\n",
      "[60.60740740740741, 63.70370370370371, 63.29629629629629, 64.35925925925926, 62.68518518518518]\n"
     ]
    }
   ],
   "source": [
    "for reward in av_agent_reward:\n",
    "    print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L1R/cooperative/cf0.01/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 285.0\n",
      "31.666666666666668\n",
      "Num laser fired = 767.1\n",
      "Total US Hit (friendly fire) = 51.9\n",
      "Total THEM Hit = 145.3\n",
      "friendly fire (%) = 0.263\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 61.5\n",
      "Tribe Saxons has total reward of 58.4\n",
      "Tribe Franks has total reward of 165.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.07\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 6.0\n",
      "THEM agents hit = 19.6\n",
      "Agent1 of Vikings aggressiveness is 0.32\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 19.8\n",
      "THEM agents hit = 1.1\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 61.5\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 23.6\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 25.6\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Agent4 of Saxons aggressiveness is 0.19\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 6.7\n",
      "THEM agents hit = 52.7\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 32.8\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.7\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 8.4\n",
      "US agents hit = 3.9\n",
      "THEM agents hit = 21.9\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 28.7\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 2.6\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 128.0\n",
      "US agents hit = 10.1\n",
      "THEM agents hit = 22.7\n",
      "Training time per epochs: 3.11 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 248.7\n",
      "27.637037037037036\n",
      "Num laser fired = 1074.5\n",
      "Total US Hit (friendly fire) = 56.1\n",
      "Total THEM Hit = 153.7\n",
      "friendly fire (%) = 0.268\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 113.5\n",
      "Tribe Saxons has total reward of 50.6\n",
      "Tribe Franks has total reward of 84.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.56\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 27.6\n",
      "THEM agents hit = 0.2\n",
      "Agent2 of Vikings aggressiveness is 0.25\n",
      "Agent2 reward is 113.5\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 79.7\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 13.1\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 2.2\n",
      "Agent4 of Saxons aggressiveness is 0.10\n",
      "Agent4 reward is 12.3\n",
      "US agents hit = 7.4\n",
      "THEM agents hit = 30.0\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 25.2\n",
      "US agents hit = 2.5\n",
      "THEM agents hit = 8.7\n",
      "Agent6 of Franks aggressiveness is 0.12\n",
      "Agent6 reward is 30.1\n",
      "US agents hit = 12.3\n",
      "THEM agents hit = 25.8\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 23.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 31.5\n",
      "US agents hit = 4.0\n",
      "THEM agents hit = 6.9\n",
      "Training time per epochs: 2.94 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 319.1\n",
      "35.455555555555556\n",
      "Num laser fired = 982.4\n",
      "Total US Hit (friendly fire) = 85.4\n",
      "Total THEM Hit = 135.1\n",
      "friendly fire (%) = 0.387\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 89.2\n",
      "Tribe Saxons has total reward of 73.3\n",
      "Tribe Franks has total reward of 156.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent1 of Vikings aggressiveness is 0.52\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 28.3\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 89.2\n",
      "US agents hit = 13.4\n",
      "THEM agents hit = 33.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 15.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.12\n",
      "Agent4 reward is 45.8\n",
      "US agents hit = 16.4\n",
      "THEM agents hit = 39.9\n",
      "Agent5 of Saxons aggressiveness is 0.11\n",
      "Agent5 reward is 12.2\n",
      "US agents hit = 10.3\n",
      "THEM agents hit = 25.4\n",
      "Agent6 of Franks aggressiveness is 0.07\n",
      "Agent6 reward is 36.1\n",
      "US agents hit = 4.8\n",
      "THEM agents hit = 12.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 20.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 99.9\n",
      "US agents hit = 11.9\n",
      "THEM agents hit = 23.9\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 321.5\n",
      "35.718518518518515\n",
      "Num laser fired = 457.3\n",
      "Total US Hit (friendly fire) = 46.0\n",
      "Total THEM Hit = 119.1\n",
      "friendly fire (%) = 0.279\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 94.4\n",
      "Tribe Saxons has total reward of 91.4\n",
      "Tribe Franks has total reward of 135.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.08\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 94.4\n",
      "US agents hit = 12.4\n",
      "THEM agents hit = 51.0\n",
      "Agent3 of Saxons aggressiveness is 0.02\n",
      "Agent3 reward is 17.0\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 4.0\n",
      "Agent4 of Saxons aggressiveness is 0.15\n",
      "Agent4 reward is 35.5\n",
      "US agents hit = 17.8\n",
      "THEM agents hit = 31.3\n",
      "Agent5 of Saxons aggressiveness is 0.07\n",
      "Agent5 reward is 38.9\n",
      "US agents hit = 3.8\n",
      "THEM agents hit = 9.6\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 14.6\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.9\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 26.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 94.1\n",
      "US agents hit = 10.5\n",
      "THEM agents hit = 21.2\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 347.7\n",
      "38.63333333333333\n",
      "Num laser fired = 799.3\n",
      "Total US Hit (friendly fire) = 65.0\n",
      "Total THEM Hit = 139.9\n",
      "friendly fire (%) = 0.317\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 105.9\n",
      "Tribe Saxons has total reward of 61.3\n",
      "Tribe Franks has total reward of 180.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.17\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.12\n",
      "Agent2 reward is 105.9\n",
      "US agents hit = 14.5\n",
      "THEM agents hit = 54.9\n",
      "Agent3 of Saxons aggressiveness is 0.13\n",
      "Agent3 reward is 8.3\n",
      "US agents hit = 9.1\n",
      "THEM agents hit = 16.1\n",
      "Agent4 of Saxons aggressiveness is 0.21\n",
      "Agent4 reward is 19.1\n",
      "US agents hit = 18.0\n",
      "THEM agents hit = 24.4\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 33.9\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 13.0\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 43.8\n",
      "US agents hit = 3.8\n",
      "THEM agents hit = 5.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 32.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 104.6\n",
      "US agents hit = 13.0\n",
      "THEM agents hit = 26.5\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf0.1/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 284.1\n",
      "31.56666666666667\n",
      "Num laser fired = 807.2\n",
      "Total US Hit (friendly fire) = 46.9\n",
      "Total THEM Hit = 200.2\n",
      "friendly fire (%) = 0.190\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 5.1\n",
      "Tribe Saxons has total reward of 25.8\n",
      "Tribe Franks has total reward of 253.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 0.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 4.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 0.5\n",
      "US agents hit = 4.9\n",
      "THEM agents hit = 8.0\n",
      "Agent3 of Saxons aggressiveness is 0.07\n",
      "Agent3 reward is 25.7\n",
      "US agents hit = 13.8\n",
      "THEM agents hit = 20.7\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.1\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 4.3\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 4.9\n",
      "Agent6 of Franks aggressiveness is 0.38\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 123.6\n",
      "Agent7 of Franks aggressiveness is 0.21\n",
      "Agent7 reward is 160.4\n",
      "US agents hit = 16.3\n",
      "THEM agents hit = 30.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 92.8\n",
      "US agents hit = 6.2\n",
      "THEM agents hit = 7.7\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 380.2\n",
      "42.24814814814815\n",
      "Num laser fired = 711.3\n",
      "Total US Hit (friendly fire) = 29.2\n",
      "Total THEM Hit = 199.1\n",
      "friendly fire (%) = 0.128\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 13.0\n",
      "Tribe Saxons has total reward of 53.7\n",
      "Tribe Franks has total reward of 313.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.6\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 12.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.1\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.4\n",
      "Agent3 of Saxons aggressiveness is 0.06\n",
      "Agent3 reward is 53.6\n",
      "US agents hit = 7.7\n",
      "THEM agents hit = 22.1\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.1\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 5.6\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 2.3\n",
      "Agent6 of Franks aggressiveness is 0.52\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 145.8\n",
      "Agent7 of Franks aggressiveness is 0.06\n",
      "Agent7 reward is 174.4\n",
      "US agents hit = 7.7\n",
      "THEM agents hit = 11.5\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 139.2\n",
      "US agents hit = 9.8\n",
      "THEM agents hit = 10.8\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 323.3\n",
      "35.925925925925924\n",
      "Num laser fired = 849.5\n",
      "Total US Hit (friendly fire) = 39.1\n",
      "Total THEM Hit = 235.1\n",
      "friendly fire (%) = 0.143\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 11.6\n",
      "Tribe Saxons has total reward of 29.2\n",
      "Tribe Franks has total reward of 282.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 11.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 29.2\n",
      "US agents hit = 11.5\n",
      "THEM agents hit = 20.2\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.9\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.53\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 158.4\n",
      "Agent7 of Franks aggressiveness is 0.13\n",
      "Agent7 reward is 168.6\n",
      "US agents hit = 10.1\n",
      "THEM agents hit = 16.5\n",
      "Agent8 of Franks aggressiveness is 0.14\n",
      "Agent8 reward is 114.0\n",
      "US agents hit = 16.3\n",
      "THEM agents hit = 37.6\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 360.1\n",
      "40.01481481481481\n",
      "Num laser fired = 804.3\n",
      "Total US Hit (friendly fire) = 20.5\n",
      "Total THEM Hit = 213.7\n",
      "friendly fire (%) = 0.088\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 11.7\n",
      "Tribe Saxons has total reward of 23.6\n",
      "Tribe Franks has total reward of 324.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.6\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 11.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 23.6\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 3.5\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.68\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 185.2\n",
      "Agent7 of Franks aggressiveness is 0.03\n",
      "Agent7 reward is 145.0\n",
      "US agents hit = 5.0\n",
      "THEM agents hit = 4.3\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 179.9\n",
      "US agents hit = 13.8\n",
      "THEM agents hit = 19.9\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 366.6\n",
      "40.733333333333334\n",
      "Num laser fired = 585.5\n",
      "Total US Hit (friendly fire) = 17.4\n",
      "Total THEM Hit = 327.9\n",
      "friendly fire (%) = 0.050\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 20.7\n",
      "Tribe Saxons has total reward of 23.0\n",
      "Tribe Franks has total reward of 322.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 19.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.21\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 148.1\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 23.0\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 3.2\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.22\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 151.4\n",
      "Agent7 of Franks aggressiveness is 0.09\n",
      "Agent7 reward is 95.0\n",
      "US agents hit = 5.6\n",
      "THEM agents hit = 6.4\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 227.9\n",
      "US agents hit = 8.0\n",
      "THEM agents hit = 18.7\n",
      "Training time per epochs: 3.09 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf1.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 264.1\n",
      "29.34444444444445\n",
      "Num laser fired = 412.9\n",
      "Total US Hit (friendly fire) = 44.7\n",
      "Total THEM Hit = 172.6\n",
      "friendly fire (%) = 0.206\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.5\n",
      "Tribe Saxons has total reward of 110.8\n",
      "Tribe Franks has total reward of 152.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 7.7\n",
      "THEM agents hit = 14.9\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 6.9\n",
      "THEM agents hit = 14.3\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 0.5\n",
      "US agents hit = 6.9\n",
      "THEM agents hit = 7.3\n",
      "Agent3 of Saxons aggressiveness is 0.02\n",
      "Agent3 reward is 1.2\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 7.0\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 5.3\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 109.5\n",
      "US agents hit = 1.6\n",
      "THEM agents hit = 20.0\n",
      "Agent6 of Franks aggressiveness is 0.17\n",
      "Agent6 reward is 1.2\n",
      "US agents hit = 9.1\n",
      "THEM agents hit = 93.7\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 59.8\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 2.9\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 91.8\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 7.2\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 321.3\n",
      "35.7\n",
      "Num laser fired = 857.0\n",
      "Total US Hit (friendly fire) = 17.5\n",
      "Total THEM Hit = 207.6\n",
      "friendly fire (%) = 0.078\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 30.5\n",
      "Tribe Saxons has total reward of 105.7\n",
      "Tribe Franks has total reward of 185.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 12.7\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 30.5\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 4.8\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 1.3\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 3.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.9\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 2.1\n",
      "Agent5 of Saxons aggressiveness is 0.13\n",
      "Agent5 reward is 103.4\n",
      "US agents hit = 3.9\n",
      "THEM agents hit = 27.6\n",
      "Agent6 of Franks aggressiveness is 0.64\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 144.5\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 98.3\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 5.2\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 86.9\n",
      "US agents hit = 6.1\n",
      "THEM agents hit = 7.3\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 357.9\n",
      "39.77037037037037\n",
      "Num laser fired = 1046.0\n",
      "Total US Hit (friendly fire) = 21.3\n",
      "Total THEM Hit = 224.2\n",
      "friendly fire (%) = 0.087\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 24.0\n",
      "Tribe Saxons has total reward of 70.7\n",
      "Tribe Franks has total reward of 263.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 2.0\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 24.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 4.9\n",
      "Agent3 of Saxons aggressiveness is 0.02\n",
      "Agent3 reward is 2.0\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 6.2\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.6\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 68.7\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 16.9\n",
      "Agent6 of Franks aggressiveness is 0.74\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 170.8\n",
      "Agent7 of Franks aggressiveness is 0.13\n",
      "Agent7 reward is 147.9\n",
      "US agents hit = 11.0\n",
      "THEM agents hit = 15.1\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 115.3\n",
      "US agents hit = 5.3\n",
      "THEM agents hit = 6.7\n",
      "Training time per epochs: 3.09 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 398.7\n",
      "44.303703703703704\n",
      "Num laser fired = 940.5\n",
      "Total US Hit (friendly fire) = 17.5\n",
      "Total THEM Hit = 215.2\n",
      "friendly fire (%) = 0.075\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 47.2\n",
      "Tribe Saxons has total reward of 93.5\n",
      "Tribe Franks has total reward of 258.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 2.1\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 47.2\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 15.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 4.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 3.8\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent5 of Saxons aggressiveness is 0.09\n",
      "Agent5 reward is 85.5\n",
      "US agents hit = 5.4\n",
      "THEM agents hit = 24.8\n",
      "Agent6 of Franks aggressiveness is 0.70\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 153.6\n",
      "Agent7 of Franks aggressiveness is 0.06\n",
      "Agent7 reward is 156.6\n",
      "US agents hit = 7.2\n",
      "THEM agents hit = 14.1\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 101.5\n",
      "US agents hit = 3.1\n",
      "THEM agents hit = 4.5\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 413.6\n",
      "45.955555555555556\n",
      "Num laser fired = 947.6\n",
      "Total US Hit (friendly fire) = 21.9\n",
      "Total THEM Hit = 221.6\n",
      "friendly fire (%) = 0.090\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 48.5\n",
      "Tribe Saxons has total reward of 26.8\n",
      "Tribe Franks has total reward of 338.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.3\n",
      "Agent2 of Vikings aggressiveness is 0.05\n",
      "Agent2 reward is 48.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 17.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 4.4\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 22.4\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 5.8\n",
      "Agent6 of Franks aggressiveness is 0.70\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 175.4\n",
      "Agent7 of Franks aggressiveness is 0.12\n",
      "Agent7 reward is 252.3\n",
      "US agents hit = 15.0\n",
      "THEM agents hit = 15.2\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 86.0\n",
      "US agents hit = 4.4\n",
      "THEM agents hit = 7.4\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf5.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 244.7\n",
      "27.185185185185183\n",
      "Num laser fired = 538.8\n",
      "Total US Hit (friendly fire) = 40.9\n",
      "Total THEM Hit = 163.2\n",
      "friendly fire (%) = 0.201\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 34.5\n",
      "Tribe Saxons has total reward of 47.4\n",
      "Tribe Franks has total reward of 162.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.20\n",
      "Agent0 reward is 34.5\n",
      "US agents hit = 20.4\n",
      "THEM agents hit = 75.7\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 0.9\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 4.0\n",
      "Agent3 of Saxons aggressiveness is 0.02\n",
      "Agent3 reward is 18.8\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 6.4\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 26.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 1.8\n",
      "US agents hit = 5.3\n",
      "THEM agents hit = 19.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 14.1\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.6\n",
      "Agent7 of Franks aggressiveness is 0.06\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 23.7\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 148.6\n",
      "US agents hit = 9.0\n",
      "THEM agents hit = 32.3\n",
      "Training time per epochs: 3.09 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 363.5\n",
      "40.388888888888886\n",
      "Num laser fired = 826.0\n",
      "Total US Hit (friendly fire) = 38.5\n",
      "Total THEM Hit = 229.8\n",
      "friendly fire (%) = 0.143\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 67.6\n",
      "Tribe Saxons has total reward of 45.7\n",
      "Tribe Franks has total reward of 250.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.07\n",
      "Agent0 reward is 67.4\n",
      "US agents hit = 10.5\n",
      "THEM agents hit = 38.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.7\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 9.9\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.9\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 32.4\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 3.2\n",
      "Agent5 of Saxons aggressiveness is 0.07\n",
      "Agent5 reward is 3.4\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 20.6\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 10.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.57\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 18.9\n",
      "THEM agents hit = 137.5\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 239.8\n",
      "US agents hit = 4.9\n",
      "THEM agents hit = 28.2\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 436.6\n",
      "48.51481481481481\n",
      "Num laser fired = 415.7\n",
      "Total US Hit (friendly fire) = 61.1\n",
      "Total THEM Hit = 309.6\n",
      "friendly fire (%) = 0.165\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 14.5\n",
      "Tribe Saxons has total reward of 235.7\n",
      "Tribe Franks has total reward of 186.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.03\n",
      "Agent0 reward is 14.5\n",
      "US agents hit = 47.0\n",
      "THEM agents hit = 117.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.02\n",
      "Agent3 reward is 4.4\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.7\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 223.8\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.9\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 7.6\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 7.7\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 52.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.31\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 9.4\n",
      "THEM agents hit = 170.2\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 134.1\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 11.2\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 367.8\n",
      "40.86296296296296\n",
      "Num laser fired = 938.9\n",
      "Total US Hit (friendly fire) = 35.4\n",
      "Total THEM Hit = 219.5\n",
      "friendly fire (%) = 0.139\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 17.3\n",
      "Tribe Saxons has total reward of 32.2\n",
      "Tribe Franks has total reward of 318.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 17.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 4.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 10.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 21.6\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 2.7\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.6\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 2.5\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 14.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.73\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 26.2\n",
      "THEM agents hit = 178.2\n",
      "Agent8 of Franks aggressiveness is 0.17\n",
      "Agent8 reward is 304.1\n",
      "US agents hit = 7.8\n",
      "THEM agents hit = 31.5\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 447.6\n",
      "49.737037037037034\n",
      "Num laser fired = 857.3\n",
      "Total US Hit (friendly fire) = 34.8\n",
      "Total THEM Hit = 225.5\n",
      "friendly fire (%) = 0.134\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 20.2\n",
      "Tribe Saxons has total reward of 42.3\n",
      "Tribe Franks has total reward of 385.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 20.2\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 8.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 7.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 16.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 18.2\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 8.9\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 19.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.72\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 25.0\n",
      "THEM agents hit = 175.2\n",
      "Agent8 of Franks aggressiveness is 0.10\n",
      "Agent8 reward is 365.4\n",
      "US agents hit = 7.4\n",
      "THEM agents hit = 32.7\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf10/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 288.8\n",
      "32.08518518518518\n",
      "Num laser fired = 288.5\n",
      "Total US Hit (friendly fire) = 23.5\n",
      "Total THEM Hit = 134.2\n",
      "friendly fire (%) = 0.149\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 93.0\n",
      "Tribe Saxons has total reward of 110.5\n",
      "Tribe Franks has total reward of 85.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.09\n",
      "Agent0 reward is 71.5\n",
      "US agents hit = 7.9\n",
      "THEM agents hit = 26.1\n",
      "Agent1 of Vikings aggressiveness is 0.09\n",
      "Agent1 reward is 20.5\n",
      "US agents hit = 4.1\n",
      "THEM agents hit = 46.8\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 1.0\n",
      "US agents hit = 4.2\n",
      "THEM agents hit = 9.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.8\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 1.4\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.3\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 2.0\n",
      "Agent5 of Saxons aggressiveness is 0.07\n",
      "Agent5 reward is 109.4\n",
      "US agents hit = 4.0\n",
      "THEM agents hit = 44.6\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 6.7\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 1.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.9\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 78.6\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.7\n",
      "Training time per epochs: 3.15 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 321.7\n",
      "35.74814814814815\n",
      "Num laser fired = 323.6\n",
      "Total US Hit (friendly fire) = 23.4\n",
      "Total THEM Hit = 143.2\n",
      "friendly fire (%) = 0.140\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 107.4\n",
      "Tribe Saxons has total reward of 119.9\n",
      "Tribe Franks has total reward of 94.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 77.2\n",
      "US agents hit = 7.2\n",
      "THEM agents hit = 23.6\n",
      "Agent1 of Vikings aggressiveness is 0.12\n",
      "Agent1 reward is 29.9\n",
      "US agents hit = 5.0\n",
      "THEM agents hit = 59.8\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 10.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.09\n",
      "Agent5 reward is 109.2\n",
      "US agents hit = 6.7\n",
      "THEM agents hit = 44.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 22.8\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 1.3\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.5\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 2.1\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 71.2\n",
      "US agents hit = 3.6\n",
      "THEM agents hit = 12.1\n",
      "Training time per epochs: 3.14 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 349.0\n",
      "38.77777777777778\n",
      "Num laser fired = 260.5\n",
      "Total US Hit (friendly fire) = 22.0\n",
      "Total THEM Hit = 129.0\n",
      "friendly fire (%) = 0.146\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 121.9\n",
      "Tribe Saxons has total reward of 136.6\n",
      "Tribe Franks has total reward of 90.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.06\n",
      "Agent0 reward is 68.6\n",
      "US agents hit = 8.1\n",
      "THEM agents hit = 29.7\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 53.2\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 32.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 24.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.11\n",
      "Agent5 reward is 111.1\n",
      "US agents hit = 9.0\n",
      "THEM agents hit = 50.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 24.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 65.8\n",
      "US agents hit = 3.3\n",
      "THEM agents hit = 16.3\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 309.0\n",
      "34.32962962962963\n",
      "Num laser fired = 398.5\n",
      "Total US Hit (friendly fire) = 31.4\n",
      "Total THEM Hit = 156.4\n",
      "friendly fire (%) = 0.167\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 114.4\n",
      "Tribe Saxons has total reward of 91.3\n",
      "Tribe Franks has total reward of 103.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.09\n",
      "Agent0 reward is 62.1\n",
      "US agents hit = 10.3\n",
      "THEM agents hit = 24.3\n",
      "Agent1 of Vikings aggressiveness is 0.03\n",
      "Agent1 reward is 51.3\n",
      "US agents hit = 4.8\n",
      "THEM agents hit = 47.3\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 1.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 16.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.20\n",
      "Agent5 reward is 74.1\n",
      "US agents hit = 8.4\n",
      "THEM agents hit = 57.1\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 60.7\n",
      "US agents hit = 6.2\n",
      "THEM agents hit = 21.9\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 42.5\n",
      "US agents hit = 1.6\n",
      "THEM agents hit = 5.6\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 352.4\n",
      "39.15925925925926\n",
      "Num laser fired = 274.9\n",
      "Total US Hit (friendly fire) = 30.1\n",
      "Total THEM Hit = 151.0\n",
      "friendly fire (%) = 0.166\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 95.4\n",
      "Tribe Saxons has total reward of 130.3\n",
      "Tribe Franks has total reward of 126.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 46.3\n",
      "US agents hit = 4.7\n",
      "THEM agents hit = 16.9\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 49.1\n",
      "US agents hit = 5.1\n",
      "THEM agents hit = 53.5\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 24.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 105.3\n",
      "US agents hit = 6.0\n",
      "THEM agents hit = 42.8\n",
      "Agent6 of Franks aggressiveness is 0.13\n",
      "Agent6 reward is 119.6\n",
      "US agents hit = 14.4\n",
      "THEM agents hit = 37.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 2.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 4.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.15 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf15/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 262.5\n",
      "29.16296296296296\n",
      "Num laser fired = 720.1\n",
      "Total US Hit (friendly fire) = 35.5\n",
      "Total THEM Hit = 191.5\n",
      "friendly fire (%) = 0.157\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 20.1\n",
      "Tribe Saxons has total reward of 130.7\n",
      "Tribe Franks has total reward of 111.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.27\n",
      "Agent0 reward is 0.1\n",
      "US agents hit = 15.2\n",
      "THEM agents hit = 41.9\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 19.9\n",
      "US agents hit = 3.1\n",
      "THEM agents hit = 16.5\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 1.2\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 4.5\n",
      "THEM agents hit = 9.7\n",
      "Agent5 of Saxons aggressiveness is 0.17\n",
      "Agent5 reward is 130.7\n",
      "US agents hit = 1.6\n",
      "THEM agents hit = 39.0\n",
      "Agent6 of Franks aggressiveness is 0.19\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 60.5\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 13.5\n",
      "US agents hit = 3.8\n",
      "THEM agents hit = 12.9\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 98.0\n",
      "US agents hit = 5.4\n",
      "THEM agents hit = 9.7\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 334.9\n",
      "37.214814814814815\n",
      "Num laser fired = 921.3\n",
      "Total US Hit (friendly fire) = 10.7\n",
      "Total THEM Hit = 202.2\n",
      "friendly fire (%) = 0.050\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 19.9\n",
      "Tribe Saxons has total reward of 104.0\n",
      "Tribe Franks has total reward of 211.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.17\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.7\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 19.9\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 15.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.05\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 2.6\n",
      "THEM agents hit = 6.6\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 104.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 17.9\n",
      "Agent6 of Franks aggressiveness is 0.63\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 155.8\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 90.0\n",
      "US agents hit = 2.8\n",
      "THEM agents hit = 3.9\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 121.0\n",
      "US agents hit = 1.6\n",
      "THEM agents hit = 1.7\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 399.6\n",
      "44.403703703703705\n",
      "Num laser fired = 904.8\n",
      "Total US Hit (friendly fire) = 2.2\n",
      "Total THEM Hit = 216.0\n",
      "friendly fire (%) = 0.010\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 34.6\n",
      "Tribe Saxons has total reward of 128.8\n",
      "Tribe Franks has total reward of 236.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.15\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 34.6\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 15.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 128.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 25.9\n",
      "Agent6 of Franks aggressiveness is 0.68\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 174.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 92.1\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 144.1\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.3\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 385.2\n",
      "42.7962962962963\n",
      "Num laser fired = 656.1\n",
      "Total US Hit (friendly fire) = 7.9\n",
      "Total THEM Hit = 238.8\n",
      "friendly fire (%) = 0.032\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 35.5\n",
      "Tribe Saxons has total reward of 115.9\n",
      "Tribe Franks has total reward of 233.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.11\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 35.5\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 38.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.18\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 39.4\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 115.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 28.3\n",
      "Agent6 of Franks aggressiveness is 0.31\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 132.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 80.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 153.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 359.9\n",
      "39.98518518518519\n",
      "Num laser fired = 792.0\n",
      "Total US Hit (friendly fire) = 7.3\n",
      "Total THEM Hit = 248.9\n",
      "friendly fire (%) = 0.028\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 41.3\n",
      "Tribe Saxons has total reward of 99.8\n",
      "Tribe Franks has total reward of 218.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.09\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 41.3\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 11.7\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.14\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 20.5\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 99.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 36.5\n",
      "Agent6 of Franks aggressiveness is 0.51\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 179.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 9.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 209.3\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.6\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf20/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 266.1\n",
      "29.562962962962963\n",
      "Num laser fired = 273.4\n",
      "Total US Hit (friendly fire) = 30.2\n",
      "Total THEM Hit = 130.6\n",
      "friendly fire (%) = 0.188\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 83.3\n",
      "Tribe Saxons has total reward of 41.7\n",
      "Tribe Franks has total reward of 141.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 7.1\n",
      "Agent1 of Vikings aggressiveness is 0.15\n",
      "Agent1 reward is 82.2\n",
      "US agents hit = 11.1\n",
      "THEM agents hit = 57.0\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 1.2\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 6.1\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 0.1\n",
      "US agents hit = 2.7\n",
      "THEM agents hit = 12.3\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 4.8\n",
      "THEM agents hit = 14.8\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 41.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.9\n",
      "Agent7 of Franks aggressiveness is 0.05\n",
      "Agent7 reward is 0.6\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 26.6\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 140.4\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 5.4\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 376.2\n",
      "41.803703703703704\n",
      "Num laser fired = 252.3\n",
      "Total US Hit (friendly fire) = 20.3\n",
      "Total THEM Hit = 117.8\n",
      "friendly fire (%) = 0.147\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 218.1\n",
      "Tribe Saxons has total reward of 36.3\n",
      "Tribe Franks has total reward of 121.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 3.2\n",
      "Agent1 of Vikings aggressiveness is 0.14\n",
      "Agent1 reward is 218.0\n",
      "US agents hit = 6.9\n",
      "THEM agents hit = 57.1\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 0.2\n",
      "US agents hit = 2.4\n",
      "THEM agents hit = 2.7\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 0.1\n",
      "US agents hit = 6.9\n",
      "THEM agents hit = 35.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.6\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 29.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 9.8\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 121.7\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 9.2\n",
      "Training time per epochs: 3.03 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 390.1\n",
      "43.34074074074074\n",
      "Num laser fired = 248.9\n",
      "Total US Hit (friendly fire) = 11.5\n",
      "Total THEM Hit = 85.8\n",
      "friendly fire (%) = 0.118\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 201.8\n",
      "Tribe Saxons has total reward of 56.1\n",
      "Tribe Franks has total reward of 132.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.19\n",
      "Agent1 reward is 201.8\n",
      "US agents hit = 8.4\n",
      "THEM agents hit = 65.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 3.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.7\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 4.9\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 21.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 33.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 132.2\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 12.5\n",
      "Training time per epochs: 3.11 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 341.3\n",
      "37.922222222222224\n",
      "Num laser fired = 282.2\n",
      "Total US Hit (friendly fire) = 12.1\n",
      "Total THEM Hit = 87.8\n",
      "friendly fire (%) = 0.121\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 180.5\n",
      "Tribe Saxons has total reward of 84.6\n",
      "Tribe Franks has total reward of 76.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent1 of Vikings aggressiveness is 0.23\n",
      "Agent1 reward is 180.3\n",
      "US agents hit = 7.3\n",
      "THEM agents hit = 68.6\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.3\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 2.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 44.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 39.9\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 5.7\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 76.2\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 10.8\n",
      "Training time per epochs: 3.09 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 330.6\n",
      "36.737037037037034\n",
      "Num laser fired = 411.8\n",
      "Total US Hit (friendly fire) = 8.4\n",
      "Total THEM Hit = 100.6\n",
      "friendly fire (%) = 0.077\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 168.8\n",
      "Tribe Saxons has total reward of 56.9\n",
      "Tribe Franks has total reward of 104.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.33\n",
      "Agent1 reward is 168.8\n",
      "US agents hit = 7.1\n",
      "THEM agents hit = 77.8\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 34.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 22.7\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 1.5\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.4\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 104.9\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 19.6\n",
      "Training time per epochs: 3.15 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf25/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 317.5\n",
      "35.27407407407407\n",
      "Num laser fired = 308.7\n",
      "Total US Hit (friendly fire) = 31.8\n",
      "Total THEM Hit = 139.7\n",
      "friendly fire (%) = 0.185\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 88.1\n",
      "Tribe Saxons has total reward of 61.0\n",
      "Tribe Franks has total reward of 168.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 87.7\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 29.6\n",
      "Agent1 of Vikings aggressiveness is 0.05\n",
      "Agent1 reward is 0.4\n",
      "US agents hit = 6.7\n",
      "THEM agents hit = 26.4\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 2.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 37.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 23.9\n",
      "US agents hit = 5.6\n",
      "THEM agents hit = 25.4\n",
      "Agent6 of Franks aggressiveness is 0.06\n",
      "Agent6 reward is 1.2\n",
      "US agents hit = 7.0\n",
      "THEM agents hit = 37.6\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 9.5\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 167.1\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 7.2\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 372.1\n",
      "41.34444444444445\n",
      "Num laser fired = 766.7\n",
      "Total US Hit (friendly fire) = 21.2\n",
      "Total THEM Hit = 246.3\n",
      "friendly fire (%) = 0.079\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 277.6\n",
      "Tribe Saxons has total reward of 40.9\n",
      "Tribe Franks has total reward of 53.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.07\n",
      "Agent0 reward is 277.4\n",
      "US agents hit = 3.5\n",
      "THEM agents hit = 12.9\n",
      "Agent1 of Vikings aggressiveness is 0.60\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 15.5\n",
      "THEM agents hit = 200.7\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 20.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.07\n",
      "Agent5 reward is 20.2\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 25.7\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 0.4\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 2.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.6\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 53.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 3.7\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 447.4\n",
      "49.714814814814815\n",
      "Num laser fired = 973.3\n",
      "Total US Hit (friendly fire) = 37.3\n",
      "Total THEM Hit = 280.5\n",
      "friendly fire (%) = 0.117\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 434.5\n",
      "Tribe Saxons has total reward of 5.2\n",
      "Tribe Franks has total reward of 7.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.23\n",
      "Agent0 reward is 434.5\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 10.6\n",
      "Agent1 of Vikings aggressiveness is 0.67\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 35.3\n",
      "THEM agents hit = 257.3\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 5.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.05\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 11.3\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 1.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 7.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 474.3\n",
      "52.696296296296296\n",
      "Num laser fired = 712.5\n",
      "Total US Hit (friendly fire) = 8.0\n",
      "Total THEM Hit = 194.7\n",
      "friendly fire (%) = 0.040\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 264.2\n",
      "Tribe Saxons has total reward of 47.8\n",
      "Tribe Franks has total reward of 162.2\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.03\n",
      "Agent0 reward is 263.7\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 13.0\n",
      "Agent1 of Vikings aggressiveness is 0.28\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 3.8\n",
      "THEM agents hit = 123.3\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 47.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.30\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 35.4\n",
      "Agent6 of Franks aggressiveness is 0.08\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 2.5\n",
      "THEM agents hit = 14.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 1.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 161.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 8.8\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 392.8\n",
      "43.64074074074074\n",
      "Num laser fired = 1194.4\n",
      "Total US Hit (friendly fire) = 12.5\n",
      "Total THEM Hit = 254.6\n",
      "friendly fire (%) = 0.047\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 383.5\n",
      "Tribe Saxons has total reward of 3.6\n",
      "Tribe Franks has total reward of 5.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.15\n",
      "Agent0 reward is 383.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 2.2\n",
      "Agent1 of Vikings aggressiveness is 0.95\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 12.4\n",
      "THEM agents hit = 249.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 3.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.07\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 2.6\n",
      "Agent6 of Franks aggressiveness is 0.03\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 5.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Dir = MA_models/3T-9L1R/cooperative/cf50/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 291.6\n",
      "32.400000000000006\n",
      "Num laser fired = 394.5\n",
      "Total US Hit (friendly fire) = 33.2\n",
      "Total THEM Hit = 135.3\n",
      "friendly fire (%) = 0.197\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 69.5\n",
      "Tribe Saxons has total reward of 156.9\n",
      "Tribe Franks has total reward of 65.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.06\n",
      "Agent1 reward is 19.7\n",
      "US agents hit = 4.1\n",
      "THEM agents hit = 17.8\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 49.8\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 1.8\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.4\n",
      "Agent4 of Saxons aggressiveness is 0.09\n",
      "Agent4 reward is 0.7\n",
      "US agents hit = 5.6\n",
      "THEM agents hit = 17.3\n",
      "Agent5 of Saxons aggressiveness is 0.13\n",
      "Agent5 reward is 155.8\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 37.3\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 0.6\n",
      "US agents hit = 4.2\n",
      "THEM agents hit = 22.4\n",
      "Agent7 of Franks aggressiveness is 0.05\n",
      "Agent7 reward is 1.4\n",
      "US agents hit = 9.2\n",
      "THEM agents hit = 29.0\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 63.3\n",
      "US agents hit = 2.6\n",
      "THEM agents hit = 9.2\n",
      "Training time per epochs: 3.13 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 382.8\n",
      "42.53703703703704\n",
      "Num laser fired = 293.5\n",
      "Total US Hit (friendly fire) = 21.4\n",
      "Total THEM Hit = 130.1\n",
      "friendly fire (%) = 0.141\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 124.7\n",
      "Tribe Saxons has total reward of 138.4\n",
      "Tribe Franks has total reward of 119.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.05\n",
      "Agent1 reward is 70.4\n",
      "US agents hit = 2.9\n",
      "THEM agents hit = 32.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 54.3\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 0.2\n",
      "US agents hit = 6.0\n",
      "THEM agents hit = 21.5\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 138.3\n",
      "US agents hit = 4.4\n",
      "THEM agents hit = 39.8\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 7.9\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 3.5\n",
      "THEM agents hit = 11.7\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 119.7\n",
      "US agents hit = 2.7\n",
      "THEM agents hit = 15.7\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 385.9\n",
      "42.87777777777777\n",
      "Num laser fired = 796.4\n",
      "Total US Hit (friendly fire) = 26.6\n",
      "Total THEM Hit = 165.6\n",
      "friendly fire (%) = 0.138\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 81.4\n",
      "Tribe Saxons has total reward of 178.6\n",
      "Tribe Franks has total reward of 125.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 59.2\n",
      "US agents hit = 2.8\n",
      "THEM agents hit = 27.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 22.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.58\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 17.6\n",
      "THEM agents hit = 77.2\n",
      "Agent5 of Saxons aggressiveness is 0.09\n",
      "Agent5 reward is 178.6\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 41.7\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 0.5\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 5.3\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 125.9\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 13.7\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 400.2\n",
      "44.46666666666667\n",
      "Num laser fired = 836.6\n",
      "Total US Hit (friendly fire) = 30.5\n",
      "Total THEM Hit = 179.1\n",
      "friendly fire (%) = 0.145\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 84.9\n",
      "Tribe Saxons has total reward of 192.0\n",
      "Tribe Franks has total reward of 123.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 70.0\n",
      "US agents hit = 2.6\n",
      "THEM agents hit = 33.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 14.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.60\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 17.1\n",
      "THEM agents hit = 77.7\n",
      "Agent5 of Saxons aggressiveness is 0.10\n",
      "Agent5 reward is 192.0\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 42.2\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 0.2\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 5.4\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 1.3\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 4.7\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 121.8\n",
      "US agents hit = 6.1\n",
      "THEM agents hit = 16.0\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 349.8\n",
      "38.86666666666667\n",
      "Num laser fired = 1123.3\n",
      "Total US Hit (friendly fire) = 24.8\n",
      "Total THEM Hit = 147.7\n",
      "friendly fire (%) = 0.144\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 40.4\n",
      "Tribe Saxons has total reward of 204.4\n",
      "Tribe Franks has total reward of 105.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 24.3\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 3.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 16.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.73\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 20.5\n",
      "THEM agents hit = 85.6\n",
      "Agent5 of Saxons aggressiveness is 0.35\n",
      "Agent5 reward is 204.4\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 49.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.5\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.2\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 4.3\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 104.8\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 4.9\n",
      "Training time per epochs: 3.18 sec\n",
      "[[31.666666666666668, 27.637037037037036, 35.455555555555556, 35.718518518518515, 38.63333333333333], [31.56666666666667, 42.24814814814815, 35.925925925925924, 40.01481481481481, 40.733333333333334], [29.34444444444445, 35.7, 39.77037037037037, 44.303703703703704, 45.955555555555556], [27.185185185185183, 40.388888888888886, 48.51481481481481, 40.86296296296296, 49.737037037037034], [32.08518518518518, 35.74814814814815, 38.77777777777778, 34.32962962962963, 39.15925925925926], [29.16296296296296, 37.214814814814815, 44.403703703703705, 42.7962962962963, 39.98518518518519], [29.562962962962963, 41.803703703703704, 43.34074074074074, 37.922222222222224, 36.737037037037034], [35.27407407407407, 41.34444444444445, 49.714814814814815, 52.696296296296296, 43.64074074074074], [32.400000000000006, 42.53703703703704, 42.87777777777777, 44.46666666666667, 38.86666666666667]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\"MA_models/3T-9L1R/cooperative/cf0.01/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf0.1/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf1.0/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf5.0/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf10/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf15/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf20/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf25/\",\n",
    "             \"MA_models/3T-9L1R/cooperative/cf50/\"]\n",
    "\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"cooperative\"\n",
    "\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 10 agents - 3 teams of 3 AI agents each and 1 random agents\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather__ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        print ('Total rewards gathered = {:.1f}'.format(cum_rewards/max_episodes))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print (av_agent_reward[dir_num][eps_num])\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "        for i, t in enumerate(tribes):\n",
    "            if t.name is not 'Crazies':\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(t.name, cum_tribe_rewards[i]/max_episodes))    \n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "                              \n",
    "print (av_agent_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Agent Reward - Cooperative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.666666666666668, 27.637037037037036, 35.455555555555556, 35.718518518518515, 38.63333333333333]\n",
      "[31.56666666666667, 42.24814814814815, 35.925925925925924, 40.01481481481481, 40.733333333333334]\n",
      "[29.34444444444445, 35.7, 39.77037037037037, 44.303703703703704, 45.955555555555556]\n",
      "[27.185185185185183, 40.388888888888886, 48.51481481481481, 40.86296296296296, 49.737037037037034]\n",
      "[32.08518518518518, 35.74814814814815, 38.77777777777778, 34.32962962962963, 39.15925925925926]\n",
      "[29.16296296296296, 37.214814814814815, 44.403703703703705, 42.7962962962963, 39.98518518518519]\n",
      "[29.562962962962963, 41.803703703703704, 43.34074074074074, 37.922222222222224, 36.737037037037034]\n",
      "[35.27407407407407, 41.34444444444445, 49.714814814814815, 52.696296296296296, 43.64074074074074]\n",
      "[32.400000000000006, 42.53703703703704, 42.87777777777777, 44.46666666666667, 38.86666666666667]\n"
     ]
    }
   ],
   "source": [
    "for reward in av_agent_reward:\n",
    "    print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L1R/warlike/p-1.0_r0.0001/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 377.9\n",
      "41.992592592592594\n",
      "Num laser fired = 1026.6\n",
      "Total US Hit (friendly fire) = 32.0\n",
      "Total THEM Hit = 179.3\n",
      "friendly fire (%) = 0.151\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 38.4\n",
      "Tribe Saxons has total reward of 124.7\n",
      "Tribe Franks has total reward of 214.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 11.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 7.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 20.0\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 20.0\n",
      "Agent3 of Saxons aggressiveness is 0.77\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 84.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 33.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 90.8\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 36.5\n",
      "Agent6 of Franks aggressiveness is 0.08\n",
      "Agent6 reward is 53.5\n",
      "US agents hit = 8.8\n",
      "THEM agents hit = 11.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 45.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 115.5\n",
      "US agents hit = 14.6\n",
      "THEM agents hit = 27.1\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 445.8\n",
      "49.529629629629625\n",
      "Num laser fired = 1056.0\n",
      "Total US Hit (friendly fire) = 27.4\n",
      "Total THEM Hit = 182.6\n",
      "friendly fire (%) = 0.131\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 41.1\n",
      "Tribe Saxons has total reward of 168.9\n",
      "Tribe Franks has total reward of 235.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 7.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 10.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 22.9\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 21.7\n",
      "Agent3 of Saxons aggressiveness is 0.79\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 84.5\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 45.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.09\n",
      "Agent5 reward is 123.0\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 37.7\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 56.5\n",
      "US agents hit = 5.2\n",
      "THEM agents hit = 6.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 50.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 129.0\n",
      "US agents hit = 14.7\n",
      "THEM agents hit = 32.1\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 424.5\n",
      "47.166666666666664\n",
      "Num laser fired = 1081.3\n",
      "Total US Hit (friendly fire) = 29.3\n",
      "Total THEM Hit = 189.3\n",
      "friendly fire (%) = 0.134\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 42.2\n",
      "Tribe Saxons has total reward of 171.4\n",
      "Tribe Franks has total reward of 210.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 7.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 9.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.03\n",
      "Agent2 reward is 25.6\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 21.0\n",
      "Agent3 of Saxons aggressiveness is 0.82\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 89.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 44.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 127.0\n",
      "US agents hit = 7.5\n",
      "THEM agents hit = 43.7\n",
      "Agent6 of Franks aggressiveness is 0.07\n",
      "Agent6 reward is 78.0\n",
      "US agents hit = 12.5\n",
      "THEM agents hit = 16.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 47.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 85.6\n",
      "US agents hit = 7.2\n",
      "THEM agents hit = 19.1\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 410.0\n",
      "45.55555555555556\n",
      "Num laser fired = 1145.4\n",
      "Total US Hit (friendly fire) = 33.2\n",
      "Total THEM Hit = 204.0\n",
      "friendly fire (%) = 0.140\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 54.9\n",
      "Tribe Saxons has total reward of 129.2\n",
      "Tribe Franks has total reward of 225.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 7.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 8.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.06\n",
      "Agent2 reward is 38.4\n",
      "US agents hit = 3.5\n",
      "THEM agents hit = 30.1\n",
      "Agent3 of Saxons aggressiveness is 0.81\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 89.5\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 31.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.11\n",
      "Agent5 reward is 97.2\n",
      "US agents hit = 6.0\n",
      "THEM agents hit = 40.7\n",
      "Agent6 of Franks aggressiveness is 0.03\n",
      "Agent6 reward is 67.6\n",
      "US agents hit = 8.2\n",
      "THEM agents hit = 14.3\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 42.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.12\n",
      "Agent8 reward is 115.7\n",
      "US agents hit = 15.5\n",
      "THEM agents hit = 29.5\n",
      "Training time per epochs: 3.03 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 421.4\n",
      "46.82592592592593\n",
      "Num laser fired = 1091.5\n",
      "Total US Hit (friendly fire) = 35.5\n",
      "Total THEM Hit = 206.8\n",
      "friendly fire (%) = 0.147\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 45.7\n",
      "Tribe Saxons has total reward of 148.6\n",
      "Tribe Franks has total reward of 227.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 8.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 3.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.05\n",
      "Agent2 reward is 33.9\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 29.0\n",
      "Agent3 of Saxons aggressiveness is 0.82\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 92.6\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 41.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.05\n",
      "Agent5 reward is 107.4\n",
      "US agents hit = 5.0\n",
      "THEM agents hit = 33.9\n",
      "Agent6 of Franks aggressiveness is 0.08\n",
      "Agent6 reward is 95.3\n",
      "US agents hit = 15.1\n",
      "THEM agents hit = 28.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 38.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 92.9\n",
      "US agents hit = 11.7\n",
      "THEM agents hit = 22.9\n",
      "Training time per epochs: 3.09 sec\n",
      "###### Dir = MA_models/3T-9L1R/warlike/p-1.0_r0.001/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 401.2\n",
      "44.577777777777776\n",
      "Num laser fired = 328.4\n",
      "Total US Hit (friendly fire) = 36.1\n",
      "Total THEM Hit = 142.6\n",
      "friendly fire (%) = 0.202\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 166.6\n",
      "Tribe Saxons has total reward of 83.1\n",
      "Tribe Franks has total reward of 151.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 25.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.11\n",
      "Agent1 reward is 118.9\n",
      "US agents hit = 15.3\n",
      "THEM agents hit = 65.9\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 21.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 22.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 35.3\n",
      "US agents hit = 2.5\n",
      "THEM agents hit = 8.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 24.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 21.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 29.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.19\n",
      "Agent8 reward is 101.5\n",
      "US agents hit = 18.1\n",
      "THEM agents hit = 67.7\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 403.6\n",
      "44.84814814814815\n",
      "Num laser fired = 302.8\n",
      "Total US Hit (friendly fire) = 41.1\n",
      "Total THEM Hit = 160.9\n",
      "friendly fire (%) = 0.203\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 158.5\n",
      "Tribe Saxons has total reward of 156.1\n",
      "Tribe Franks has total reward of 89.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 26.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.10\n",
      "Agent1 reward is 111.4\n",
      "US agents hit = 16.0\n",
      "THEM agents hit = 69.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 20.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.06\n",
      "Agent3 reward is 77.8\n",
      "US agents hit = 9.7\n",
      "THEM agents hit = 30.8\n",
      "Agent4 of Saxons aggressiveness is 0.08\n",
      "Agent4 reward is 54.9\n",
      "US agents hit = 9.5\n",
      "THEM agents hit = 38.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 23.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 16.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 19.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 52.7\n",
      "US agents hit = 5.9\n",
      "THEM agents hit = 22.7\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 389.2\n",
      "43.24814814814815\n",
      "Num laser fired = 429.2\n",
      "Total US Hit (friendly fire) = 44.0\n",
      "Total THEM Hit = 179.3\n",
      "friendly fire (%) = 0.197\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 150.3\n",
      "Tribe Saxons has total reward of 113.7\n",
      "Tribe Franks has total reward of 125.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 27.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.08\n",
      "Agent1 reward is 108.1\n",
      "US agents hit = 16.6\n",
      "THEM agents hit = 68.6\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 14.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.06\n",
      "Agent3 reward is 62.9\n",
      "US agents hit = 6.9\n",
      "THEM agents hit = 30.9\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 32.0\n",
      "US agents hit = 3.5\n",
      "THEM agents hit = 15.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 18.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 15.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 20.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.27\n",
      "Agent8 reward is 89.9\n",
      "US agents hit = 17.0\n",
      "THEM agents hit = 64.7\n",
      "Training time per epochs: 3.03 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 428.9\n",
      "47.65925925925926\n",
      "Num laser fired = 330.7\n",
      "Total US Hit (friendly fire) = 37.0\n",
      "Total THEM Hit = 188.0\n",
      "friendly fire (%) = 0.164\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 109.2\n",
      "Tribe Saxons has total reward of 169.3\n",
      "Tribe Franks has total reward of 150.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 21.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.05\n",
      "Agent1 reward is 61.4\n",
      "US agents hit = 8.3\n",
      "THEM agents hit = 41.9\n",
      "Agent2 of Vikings aggressiveness is 0.03\n",
      "Agent2 reward is 26.3\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 9.7\n",
      "Agent3 of Saxons aggressiveness is 0.14\n",
      "Agent3 reward is 116.1\n",
      "US agents hit = 17.4\n",
      "THEM agents hit = 69.1\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 45.5\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 20.4\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 7.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 27.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 25.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 97.7\n",
      "US agents hit = 9.5\n",
      "THEM agents hit = 46.9\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 348.9\n",
      "38.77037037037037\n",
      "Num laser fired = 513.2\n",
      "Total US Hit (friendly fire) = 40.0\n",
      "Total THEM Hit = 201.3\n",
      "friendly fire (%) = 0.166\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 125.9\n",
      "Tribe Saxons has total reward of 117.8\n",
      "Tribe Franks has total reward of 105.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 13.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.17\n",
      "Agent1 reward is 84.6\n",
      "US agents hit = 8.2\n",
      "THEM agents hit = 42.4\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 27.8\n",
      "US agents hit = 4.6\n",
      "THEM agents hit = 27.2\n",
      "Agent3 of Saxons aggressiveness is 0.11\n",
      "Agent3 reward is 80.1\n",
      "US agents hit = 14.5\n",
      "THEM agents hit = 53.6\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 28.2\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 31.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 9.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 14.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 19.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.14\n",
      "Agent8 reward is 71.5\n",
      "US agents hit = 9.4\n",
      "THEM agents hit = 46.9\n",
      "Training time per epochs: 3.09 sec\n",
      "###### Dir = MA_models/3T-9L1R/warlike/p-1.0_r0.005/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 427.8\n",
      "47.53333333333333\n",
      "Num laser fired = 255.7\n",
      "Total US Hit (friendly fire) = 33.7\n",
      "Total THEM Hit = 147.8\n",
      "friendly fire (%) = 0.186\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 175.6\n",
      "Tribe Saxons has total reward of 93.8\n",
      "Tribe Franks has total reward of 158.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 21.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 45.7\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.4\n",
      "Agent2 of Vikings aggressiveness is 0.08\n",
      "Agent2 reward is 108.4\n",
      "US agents hit = 9.7\n",
      "THEM agents hit = 67.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 21.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 41.3\n",
      "US agents hit = 2.7\n",
      "THEM agents hit = 14.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 31.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 28.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.11\n",
      "Agent7 reward is 63.3\n",
      "US agents hit = 13.6\n",
      "THEM agents hit = 41.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 67.0\n",
      "US agents hit = 7.1\n",
      "THEM agents hit = 23.6\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 417.3\n",
      "46.37037037037037\n",
      "Num laser fired = 259.2\n",
      "Total US Hit (friendly fire) = 34.5\n",
      "Total THEM Hit = 151.5\n",
      "friendly fire (%) = 0.186\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 152.0\n",
      "Tribe Saxons has total reward of 100.6\n",
      "Tribe Franks has total reward of 164.8\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 29.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 45.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 77.9\n",
      "US agents hit = 7.8\n",
      "THEM agents hit = 62.5\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 22.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.06\n",
      "Agent4 reward is 56.5\n",
      "US agents hit = 7.4\n",
      "THEM agents hit = 29.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 21.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 25.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.06\n",
      "Agent7 reward is 60.2\n",
      "US agents hit = 9.3\n",
      "THEM agents hit = 26.7\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 79.4\n",
      "US agents hit = 10.0\n",
      "THEM agents hit = 33.2\n",
      "Training time per epochs: 3.23 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 456.4\n",
      "50.714814814814815\n",
      "Num laser fired = 226.9\n",
      "Total US Hit (friendly fire) = 31.4\n",
      "Total THEM Hit = 154.3\n",
      "friendly fire (%) = 0.169\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 180.8\n",
      "Tribe Saxons has total reward of 91.7\n",
      "Tribe Franks has total reward of 183.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 40.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 53.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.06\n",
      "Agent2 reward is 86.9\n",
      "US agents hit = 5.4\n",
      "THEM agents hit = 68.5\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 19.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 40.6\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 10.7\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 31.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 21.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.05\n",
      "Agent7 reward is 58.5\n",
      "US agents hit = 8.3\n",
      "THEM agents hit = 26.4\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 103.6\n",
      "US agents hit = 15.4\n",
      "THEM agents hit = 48.7\n",
      "Training time per epochs: 3.37 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 424.2\n",
      "47.13703703703704\n",
      "Num laser fired = 321.0\n",
      "Total US Hit (friendly fire) = 30.7\n",
      "Total THEM Hit = 196.2\n",
      "friendly fire (%) = 0.135\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 176.5\n",
      "Tribe Saxons has total reward of 141.4\n",
      "Tribe Franks has total reward of 106.3\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 42.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 53.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.06\n",
      "Agent2 reward is 80.5\n",
      "US agents hit = 2.4\n",
      "THEM agents hit = 67.7\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 12.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.05\n",
      "Agent4 reward is 58.3\n",
      "US agents hit = 8.6\n",
      "THEM agents hit = 33.7\n",
      "Agent5 of Saxons aggressiveness is 0.05\n",
      "Agent5 reward is 70.5\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 35.7\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 18.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.07\n",
      "Agent7 reward is 44.9\n",
      "US agents hit = 5.1\n",
      "THEM agents hit = 25.8\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 43.5\n",
      "US agents hit = 8.1\n",
      "THEM agents hit = 33.3\n",
      "Training time per epochs: 3.55 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 396.1\n",
      "44.01111111111111\n",
      "Num laser fired = 397.9\n",
      "Total US Hit (friendly fire) = 31.7\n",
      "Total THEM Hit = 208.6\n",
      "friendly fire (%) = 0.132\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 154.1\n",
      "Tribe Saxons has total reward of 171.3\n",
      "Tribe Franks has total reward of 70.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 33.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 41.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.10\n",
      "Agent2 reward is 78.8\n",
      "US agents hit = 7.4\n",
      "THEM agents hit = 76.3\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 15.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.03\n",
      "Agent4 reward is 35.2\n",
      "US agents hit = 4.0\n",
      "THEM agents hit = 12.0\n",
      "Agent5 of Saxons aggressiveness is 0.15\n",
      "Agent5 reward is 120.5\n",
      "US agents hit = 14.3\n",
      "THEM agents hit = 85.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 12.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.05\n",
      "Agent7 reward is 25.2\n",
      "US agents hit = 2.8\n",
      "THEM agents hit = 17.5\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 33.5\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 17.7\n",
      "Training time per epochs: 3.68 sec\n",
      "###### Dir = MA_models/3T-9L1R/warlike/p-1.0_r0.01/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 371.9\n",
      "41.32222222222222\n",
      "Num laser fired = 1149.4\n",
      "Total US Hit (friendly fire) = 30.8\n",
      "Total THEM Hit = 183.8\n",
      "friendly fire (%) = 0.143\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 15.3\n",
      "Tribe Saxons has total reward of 135.1\n",
      "Tribe Franks has total reward of 221.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 5.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 6.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 3.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.82\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 92.9\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 36.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.16\n",
      "Agent5 reward is 98.4\n",
      "US agents hit = 8.4\n",
      "THEM agents hit = 50.4\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 26.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.03\n",
      "Agent7 reward is 48.5\n",
      "US agents hit = 5.2\n",
      "THEM agents hit = 7.8\n",
      "Agent8 of Franks aggressiveness is 0.13\n",
      "Agent8 reward is 146.8\n",
      "US agents hit = 17.1\n",
      "THEM agents hit = 32.6\n",
      "Training time per epochs: 3.40 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 420.6\n",
      "46.737037037037034\n",
      "Num laser fired = 1063.4\n",
      "Total US Hit (friendly fire) = 25.9\n",
      "Total THEM Hit = 190.3\n",
      "friendly fire (%) = 0.120\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 31.5\n",
      "Tribe Saxons has total reward of 185.7\n",
      "Tribe Franks has total reward of 203.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 10.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 11.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 9.9\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 14.1\n",
      "Agent3 of Saxons aggressiveness is 0.77\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 84.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 41.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.14\n",
      "Agent5 reward is 144.7\n",
      "US agents hit = 8.4\n",
      "THEM agents hit = 58.4\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 29.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.10\n",
      "Agent7 reward is 82.8\n",
      "US agents hit = 10.5\n",
      "THEM agents hit = 17.2\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 91.1\n",
      "US agents hit = 6.7\n",
      "THEM agents hit = 16.4\n",
      "Training time per epochs: 3.35 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 389.8\n",
      "43.31111111111111\n",
      "Num laser fired = 1184.0\n",
      "Total US Hit (friendly fire) = 30.3\n",
      "Total THEM Hit = 201.2\n",
      "friendly fire (%) = 0.131\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 25.1\n",
      "Tribe Saxons has total reward of 159.7\n",
      "Tribe Franks has total reward of 205.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 4.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 11.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 8.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 9.8\n",
      "Agent3 of Saxons aggressiveness is 0.81\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 91.6\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 36.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.15\n",
      "Agent5 reward is 122.9\n",
      "US agents hit = 7.6\n",
      "THEM agents hit = 54.2\n",
      "Agent6 of Franks aggressiveness is 0.08\n",
      "Agent6 reward is 34.4\n",
      "US agents hit = 5.7\n",
      "THEM agents hit = 13.3\n",
      "Agent7 of Franks aggressiveness is 0.06\n",
      "Agent7 reward is 60.5\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 9.1\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 110.2\n",
      "US agents hit = 10.3\n",
      "THEM agents hit = 23.2\n",
      "Training time per epochs: 3.41 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 383.0\n",
      "42.55555555555556\n",
      "Num laser fired = 1161.3\n",
      "Total US Hit (friendly fire) = 31.9\n",
      "Total THEM Hit = 200.3\n",
      "friendly fire (%) = 0.137\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 28.5\n",
      "Tribe Saxons has total reward of 133.6\n",
      "Tribe Franks has total reward of 220.9\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 10.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 10.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 8.2\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 12.8\n",
      "Agent3 of Saxons aggressiveness is 0.80\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 89.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 33.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.10\n",
      "Agent5 reward is 99.8\n",
      "US agents hit = 7.2\n",
      "THEM agents hit = 51.6\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 35.8\n",
      "US agents hit = 4.1\n",
      "THEM agents hit = 5.7\n",
      "Agent7 of Franks aggressiveness is 0.11\n",
      "Agent7 reward is 85.3\n",
      "US agents hit = 8.7\n",
      "THEM agents hit = 16.2\n",
      "Agent8 of Franks aggressiveness is 0.10\n",
      "Agent8 reward is 99.8\n",
      "US agents hit = 10.8\n",
      "THEM agents hit = 24.6\n",
      "Training time per epochs: 3.22 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 358.9\n",
      "39.87407407407407\n",
      "Num laser fired = 1230.1\n",
      "Total US Hit (friendly fire) = 32.8\n",
      "Total THEM Hit = 197.4\n",
      "friendly fire (%) = 0.143\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 15.6\n",
      "Tribe Saxons has total reward of 142.8\n",
      "Tribe Franks has total reward of 200.5\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 7.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 7.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 7.2\n",
      "Agent3 of Saxons aggressiveness is 0.82\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 98.2\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 29.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.13\n",
      "Agent5 reward is 113.4\n",
      "US agents hit = 8.0\n",
      "THEM agents hit = 49.8\n",
      "Agent6 of Franks aggressiveness is 0.03\n",
      "Agent6 reward is 30.9\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 5.2\n",
      "Agent7 of Franks aggressiveness is 0.14\n",
      "Agent7 reward is 75.7\n",
      "US agents hit = 10.7\n",
      "THEM agents hit = 16.6\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 93.8\n",
      "US agents hit = 11.8\n",
      "THEM agents hit = 20.3\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Dir = MA_models/3T-9L1R/warlike/p-1.0_r0.05/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 400.4\n",
      "44.48518518518519\n",
      "Num laser fired = 401.5\n",
      "Total US Hit (friendly fire) = 39.0\n",
      "Total THEM Hit = 161.1\n",
      "friendly fire (%) = 0.195\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.7\n",
      "Tribe Saxons has total reward of 130.6\n",
      "Tribe Franks has total reward of 85.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 30.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.13\n",
      "Agent1 reward is 54.9\n",
      "US agents hit = 10.1\n",
      "THEM agents hit = 54.3\n",
      "Agent2 of Vikings aggressiveness is 0.16\n",
      "Agent2 reward is 99.8\n",
      "US agents hit = 16.7\n",
      "THEM agents hit = 49.3\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 22.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 10.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.11\n",
      "Agent5 reward is 97.8\n",
      "US agents hit = 11.5\n",
      "THEM agents hit = 55.8\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 21.6\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 34.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 29.4\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.9\n",
      "Training time per epochs: 3.24 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 341.1\n",
      "37.903703703703705\n",
      "Num laser fired = 404.4\n",
      "Total US Hit (friendly fire) = 44.9\n",
      "Total THEM Hit = 199.4\n",
      "friendly fire (%) = 0.184\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 182.3\n",
      "Tribe Saxons has total reward of 72.2\n",
      "Tribe Franks has total reward of 86.7\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 46.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.10\n",
      "Agent1 reward is 89.9\n",
      "US agents hit = 16.6\n",
      "THEM agents hit = 57.5\n",
      "Agent2 of Vikings aggressiveness is 0.08\n",
      "Agent2 reward is 46.1\n",
      "US agents hit = 9.9\n",
      "THEM agents hit = 65.6\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 14.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 8.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 49.1\n",
      "US agents hit = 7.2\n",
      "THEM agents hit = 38.8\n",
      "Agent6 of Franks aggressiveness is 0.14\n",
      "Agent6 reward is 32.8\n",
      "US agents hit = 7.0\n",
      "THEM agents hit = 24.3\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 19.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 34.5\n",
      "US agents hit = 4.2\n",
      "THEM agents hit = 13.2\n",
      "Training time per epochs: 3.40 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 314.5\n",
      "34.940740740740736\n",
      "Num laser fired = 511.2\n",
      "Total US Hit (friendly fire) = 45.3\n",
      "Total THEM Hit = 225.7\n",
      "friendly fire (%) = 0.167\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 161.8\n",
      "Tribe Saxons has total reward of 68.6\n",
      "Tribe Franks has total reward of 84.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 40.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.16\n",
      "Agent1 reward is 85.8\n",
      "US agents hit = 17.0\n",
      "THEM agents hit = 70.6\n",
      "Agent2 of Vikings aggressiveness is 0.13\n",
      "Agent2 reward is 35.9\n",
      "US agents hit = 10.7\n",
      "THEM agents hit = 68.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 10.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 8.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.14\n",
      "Agent5 reward is 50.2\n",
      "US agents hit = 10.4\n",
      "THEM agents hit = 63.5\n",
      "Agent6 of Franks aggressiveness is 0.06\n",
      "Agent6 reward is 26.4\n",
      "US agents hit = 4.4\n",
      "THEM agents hit = 13.8\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 18.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 39.3\n",
      "US agents hit = 2.8\n",
      "THEM agents hit = 9.4\n",
      "Training time per epochs: 3.36 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 368.2\n",
      "40.91111111111111\n",
      "Num laser fired = 385.8\n",
      "Total US Hit (friendly fire) = 29.2\n",
      "Total THEM Hit = 224.8\n",
      "friendly fire (%) = 0.115\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 147.6\n",
      "Tribe Saxons has total reward of 149.6\n",
      "Tribe Franks has total reward of 71.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 31.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.09\n",
      "Agent1 reward is 79.0\n",
      "US agents hit = 14.3\n",
      "THEM agents hit = 41.0\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 36.7\n",
      "US agents hit = 5.8\n",
      "THEM agents hit = 64.6\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 3.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.21\n",
      "Agent5 reward is 146.0\n",
      "US agents hit = 5.9\n",
      "THEM agents hit = 105.2\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 30.7\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 9.3\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 13.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 26.8\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 4.8\n",
      "Training time per epochs: 3.52 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 544.6\n",
      "60.51481481481481\n",
      "Num laser fired = 305.9\n",
      "Total US Hit (friendly fire) = 5.9\n",
      "Total THEM Hit = 500.2\n",
      "friendly fire (%) = 0.012\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 85.8\n",
      "Tribe Saxons has total reward of 17.9\n",
      "Tribe Franks has total reward of 441.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 12.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.05\n",
      "Agent1 reward is 50.3\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 7.7\n",
      "Agent2 of Vikings aggressiveness is 0.03\n",
      "Agent2 reward is 22.7\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 171.9\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 1.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 1.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.05\n",
      "Agent5 reward is 15.3\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 95.6\n",
      "Agent6 of Franks aggressiveness is 0.14\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 193.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 417.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 23.7\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 31.7\n",
      "Training time per epochs: 3.34 sec\n",
      "###### Dir = MA_models/3T-9L1R/warlike/p-1.0_r0.1/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 300.0\n",
      "33.33703703703704\n",
      "Num laser fired = 1096.8\n",
      "Total US Hit (friendly fire) = 33.2\n",
      "Total THEM Hit = 202.1\n",
      "friendly fire (%) = 0.141\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 43.8\n",
      "Tribe Saxons has total reward of 104.2\n",
      "Tribe Franks has total reward of 152.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 37.9\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 5.5\n",
      "Agent2 of Vikings aggressiveness is 0.11\n",
      "Agent2 reward is 5.9\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 34.9\n",
      "Agent3 of Saxons aggressiveness is 0.72\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 84.0\n",
      "Agent4 of Saxons aggressiveness is 0.08\n",
      "Agent4 reward is 46.6\n",
      "US agents hit = 5.4\n",
      "THEM agents hit = 20.4\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 57.6\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 26.5\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 45.9\n",
      "US agents hit = 7.0\n",
      "THEM agents hit = 5.0\n",
      "Agent7 of Franks aggressiveness is 0.05\n",
      "Agent7 reward is 48.3\n",
      "US agents hit = 7.9\n",
      "THEM agents hit = 15.6\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 57.9\n",
      "US agents hit = 6.7\n",
      "THEM agents hit = 10.0\n",
      "Training time per epochs: 3.58 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 639.4\n",
      "71.04444444444444\n",
      "Num laser fired = 1016.2\n",
      "Total US Hit (friendly fire) = 4.8\n",
      "Total THEM Hit = 274.7\n",
      "friendly fire (%) = 0.017\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 559.1\n",
      "Tribe Saxons has total reward of 39.4\n",
      "Tribe Franks has total reward of 41.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 92.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 466.2\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 1.3\n",
      "Agent2 of Vikings aggressiveness is 0.82\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 232.3\n",
      "Agent3 of Saxons aggressiveness is 0.14\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 22.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 27.2\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 2.3\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 12.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 9.8\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 14.6\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 2.2\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 9.4\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 0.7\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 17.0\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 4.0\n",
      "Training time per epochs: 3.56 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 645.7\n",
      "71.74814814814815\n",
      "Num laser fired = 992.2\n",
      "Total US Hit (friendly fire) = 1.8\n",
      "Total THEM Hit = 289.9\n",
      "friendly fire (%) = 0.006\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 588.4\n",
      "Tribe Saxons has total reward of 18.0\n",
      "Tribe Franks has total reward of 39.4\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 99.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 488.7\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.0\n",
      "Agent2 of Vikings aggressiveness is 0.84\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 240.5\n",
      "Agent3 of Saxons aggressiveness is 0.03\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 9.6\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 10.9\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 8.9\n",
      "Agent6 of Franks aggressiveness is 0.09\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 25.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 10.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 29.1\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 4.7\n",
      "Training time per epochs: 3.47 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 621.7\n",
      "69.07407407407408\n",
      "Num laser fired = 1074.9\n",
      "Total US Hit (friendly fire) = 1.7\n",
      "Total THEM Hit = 283.6\n",
      "friendly fire (%) = 0.006\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 557.7\n",
      "Tribe Saxons has total reward of 34.9\n",
      "Tribe Franks has total reward of 29.1\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 92.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 465.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.5\n",
      "Agent2 of Vikings aggressiveness is 0.84\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 237.9\n",
      "Agent3 of Saxons aggressiveness is 0.03\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 9.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 11.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 24.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 8.4\n",
      "Agent6 of Franks aggressiveness is 0.09\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 24.2\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 16.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.10\n",
      "Agent8 reward is 12.4\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 3.5\n",
      "Training time per epochs: 3.44 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 646.3\n",
      "71.81481481481482\n",
      "Num laser fired = 1015.7\n",
      "Total US Hit (friendly fire) = 2.4\n",
      "Total THEM Hit = 288.4\n",
      "friendly fire (%) = 0.008\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 586.9\n",
      "Tribe Saxons has total reward of 29.9\n",
      "Tribe Franks has total reward of 29.6\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 100.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 486.7\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 1.0\n",
      "Agent2 of Vikings aggressiveness is 0.83\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 237.9\n",
      "Agent3 of Saxons aggressiveness is 0.03\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 9.5\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 17.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 12.7\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 8.6\n",
      "Agent6 of Franks aggressiveness is 0.10\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 25.9\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 11.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 18.2\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 5.0\n",
      "Training time per epochs: 3.69 sec\n",
      "###### Dir = MA_models/3T-9L1R/warlike/p-1.0_r0.5/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 0.0\n",
      "0.0\n",
      "Num laser fired = 350.7\n",
      "Total US Hit (friendly fire) = 272.8\n",
      "Total THEM Hit = 1948.0\n",
      "friendly fire (%) = 0.123\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.0\n",
      "Tribe Saxons has total reward of 0.0\n",
      "Tribe Franks has total reward of 0.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 77.9\n",
      "THEM agents hit = 272.8\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 273.0\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 272.5\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 116.8\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 155.9\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 155.6\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 233.8\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 38.9\n",
      "THEM agents hit = 233.6\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Training time per epochs: 3.42 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "Load random agent 9\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 0.0\n",
      "0.0\n",
      "Num laser fired = 351.0\n",
      "Total US Hit (friendly fire) = 273.0\n",
      "Total THEM Hit = 1950.0\n",
      "friendly fire (%) = 0.123\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.0\n",
      "Tribe Saxons has total reward of 0.0\n",
      "Tribe Franks has total reward of 0.0\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 273.0\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 273.0\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 273.0\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 156.0\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 156.0\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 234.0\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 234.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Training time per epochs: 3.25 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Model file not found.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MA_models/3T-9L1R/warlike/p-1.0_r0.5/MA0_Gather__ep3000.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b6a44c9955f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'MA{}_Gather__ep{}.p'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m                     \u001b[0;31m# Model File include both model and optim parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MA_models/3T-9L1R/warlike/p-1.0_r0.5/MA0_Gather__ep3000.p'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\"MA_models/3T-9L1R/warlike/p-1.0_r0.0001/\",\n",
    "             \"MA_models/3T-9L1R/warlike/p-1.0_r0.001/\",\n",
    "             \"MA_models/3T-9L1R/warlike/p-1.0_r0.005/\",  \n",
    "             \"MA_models/3T-9L1R/warlike/p-1.0_r0.01/\",   \n",
    "             \"MA_models/3T-9L1R/warlike/p-1.0_r0.05/\",   \n",
    "             \"MA_models/3T-9L1R/warlike/p-1.0_r0.1/\",\n",
    "             \"MA_models/3T-9L1R/warlike/p-1.0_r0.5/\",\n",
    "             \"MA_models/3T-9L1R/warlike/p-1.0_r1.0/\"]\n",
    "\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"warlike\"\n",
    "\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 10 agents - 3 teams of 3 AI agents each and 1 random agents\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 1\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather__ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        print ('Total rewards gathered = {:.1f}'.format(cum_rewards/max_episodes))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print (av_agent_reward[dir_num][eps_num])\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "        for i, t in enumerate(tribes):\n",
    "            if t.name is not 'Crazies':\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(t.name, cum_tribe_rewards[i]/max_episodes))    \n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "                              \n",
    "print (av_agent_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Agent Reward - Warlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.992592592592594, 49.529629629629625, 47.166666666666664, 45.55555555555556, 46.82592592592593]\n",
      "[44.577777777777776, 44.84814814814815, 43.24814814814815, 47.65925925925926, 38.77037037037037]\n",
      "[47.53333333333333, 46.37037037037037, 50.714814814814815, 47.13703703703704, 44.01111111111111]\n",
      "[41.32222222222222, 46.737037037037034, 43.31111111111111, 42.55555555555556, 39.87407407407407]\n",
      "[44.48518518518519, 37.903703703703705, 34.940740740740736, 40.91111111111111, 60.51481481481481]\n",
      "[33.33703703703704, 71.04444444444444, 71.74814814814815, 69.07407407407408, 71.81481481481482]\n",
      "[0.0, 0.0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for reward in av_agent_reward:\n",
    "    print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
