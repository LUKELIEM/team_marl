{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dream Teams\n",
    "\n",
    "We will run tournaments pitting teams composed of specialist agents against random agents, trained teams of different cultures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.4\n",
      "Pytorch version: 0.4.1.post2\n",
      "OpenAI Gym version: 0.9.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import platform\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# This is the Gathering Game Environment based on Tribal Organization of agents\n",
    "from tribes_env import GatheringEnv\n",
    "from tribes_model import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Pytorch version: {}\".format(torch.__version__))\n",
    "print(\"OpenAI Gym version: {}\".format(gym.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play 1 Game with Rendering\n",
    "\n",
    "We will rewrite the code for playing one game rendered so that:\n",
    "\n",
    "(1) each agent can be loaded with any specific trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# There will be 9 AI agents\n",
    "agent_models = [\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA0_Gather_ep5000.p'\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA1_Gather_ep5000.p'\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA2_Gather_ep5000.p'\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA3_Gather_ep5000.p'\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA4_Gather_ep5000.p'\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA5_Gather_ep5000.p'    \n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA6_Gather_ep5000.p'\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA7_Gather_ep5000.p'\n",
    "                'MA_models/3T-9L/pacifist/p-100.0/MA8_Gather_ep5000.p'    \n",
    "                ]\n",
    "\n",
    "# There will be 9 AI agents and 0 random agent\n",
    "num_ai_agents = len(agent_models)\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = True\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 1\n",
    "max_frames = 300\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "# Load models for AI agents\n",
    "agents= [[] for i in range(num_ai_agents)]\n",
    "\n",
    "for i, model_file in enumerate(agent_models):\n",
    "    try:\n",
    "        with open(model_file, 'rb') as f:\n",
    "            # Model File include both model and optim parameters\n",
    "            saved_model = pickle.load(f)\n",
    "            agents[i], _ = saved_model\n",
    "            print(\"Load saved model for agent {}\".format(i))\n",
    "    except OSError:\n",
    "        print('Model file not found.')\n",
    "        raise\n",
    "\n",
    "# Load random agents    \n",
    "for i in range(num_ai_agents,num_agents):\n",
    "    print(\"Load random agent {}\".format(i))\n",
    "    agents.append(Rdn_Policy())\n",
    "\n",
    "# Initialize AI and random agent data\n",
    "actions = [0 for i in range(num_agents)]\n",
    "tags = [0 for i in range(num_agents)]\n",
    "\n",
    "# Establish tribal association\n",
    "\n",
    "tribes = []\n",
    "tribes.append(Tribe(name='Vikings',color='blue', agents=[agents[0], agents[1], agents[2]]))\n",
    "tribes.append(Tribe(name='Saxons', color='red', agents=[agents[3], agents[4], agents[5]]))\n",
    "tribes.append(Tribe(name='Franks', color='purple', agents=[agents[6], agents[7], agents[8]]))\n",
    "# tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "# 3 tribes of 9 agents, used map defined in default.txt\n",
    "agent_colors = [agent.color for agent in agents]\n",
    "agent_tribes = [agent.tribe for agent in agents]\n",
    "    \n",
    "env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, map_name='default')    \n",
    "    \n",
    "for ep in range(max_episodes):\n",
    "    \n",
    "    US_hits = [0 for i in range(num_agents)]\n",
    "    THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "    env_obs = env.reset()  # Environment return observations\n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack observations into data structure compatible with agent Policy\n",
    "    agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "    for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "        agents[i].reset_info()    \n",
    "    \n",
    "    env.render()\n",
    "    time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "    \"\"\"\n",
    "    # For Debug only\n",
    "    print (len(agents_obs))\n",
    "    print (agents_obs[0].shape)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "    state = np.stack([state]*num_frames)\n",
    "\n",
    "    # Reset LSTM hidden units when episode begins\n",
    "    cx = Variable(torch.zeros(1, 256))\n",
    "    hx = Variable(torch.zeros(1, 256))\n",
    "    \"\"\"\n",
    "\n",
    "    for frame in range(max_frames):\n",
    "\n",
    "        for i in range(num_ai_agents):    # For AI agents\n",
    "            actions[i], _ = select_action(agents[i], agents_obs[i], cuda=False)\n",
    "            if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "        for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "            actions[i] = agents[i].select_action(agents_obs[i])\n",
    "            if actions[i] is 6:\n",
    "                tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "        \"\"\"\n",
    "        For now, we do not implement LSTM\n",
    "        # Select action\n",
    "        action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "        \"\"\"\n",
    "\n",
    "        # if frame % 10 == 0:\n",
    "        #     print (actions)    \n",
    "            \n",
    "        # Perform step        \n",
    "        env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "        \"\"\"\n",
    "        For Debug only\n",
    "        print (env_obs)\n",
    "        print (reward)\n",
    "        print (done) \n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(num_ai_agents):\n",
    "            agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "        # Unpack observations into data structure compatible with agent Policy\n",
    "        agents_obs = unpack_env_obs(env_obs)\n",
    "        load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "        for i in range(num_agents):\n",
    "            US_hits[i] += agents[i].US_hit\n",
    "            THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "        \"\"\"\n",
    "        For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "        # Evict oldest diff add new diff to state\n",
    "        next_state = np.stack([next_state]*num_frames)\n",
    "        next_state[1:, :, :] = state[:-1, :, :]\n",
    "        state = next_state\n",
    "        \"\"\"\n",
    "        \n",
    "        env.render()\n",
    "        time.sleep(1/30)  # Change speed of video rendering\n",
    "\n",
    "        if any(done):\n",
    "            print(\"Done after {} frames\".format(frame))\n",
    "            break\n",
    "\n",
    "env.close()  # Close the rendering window\n",
    "\n",
    "\n",
    "# Print out statistics of AI agents\n",
    "\n",
    "total_rewards = 0\n",
    "total_tags = 0\n",
    "total_US_hits = 0\n",
    "total_THEM_hits = 0\n",
    "\n",
    "print ('\\nStatistics by Agent')\n",
    "print ('===================')\n",
    "for i in range(num_ai_agents):\n",
    "    agent_tags = sum(agents[i].tag_hist)\n",
    "    total_tags += agent_tags\n",
    "    print (\"Agent{} aggressiveness is {:.2f}\".format(i, sum(agents[i].tag_hist)/frame))\n",
    "\n",
    "    agent_reward = sum(agents[i].rewards)\n",
    "    total_rewards += agent_reward\n",
    "    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "\n",
    "    agent_US_hits = sum(agents[i].US_hits)\n",
    "    agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "    total_US_hits += agent_US_hits\n",
    "    total_THEM_hits += agent_THEM_hits\n",
    "\n",
    "    print('US agents hit = {}'.format(agent_US_hits))\n",
    "    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "\n",
    "print ('\\nStatistics in Aggregate')\n",
    "print ('=======================')\n",
    "print ('Total rewards gathered = {}'.format(total_rewards))\n",
    "print ('Av. rewards per agent = {0:.2f}'.format(total_rewards/num_ai_agents))\n",
    "print ('Num laser fired = {}'.format(total_tags))\n",
    "print ('Total US Hit (friendly fire) = {}'.format(total_US_hits))\n",
    "print ('Total THEM Hit = {}'.format(total_THEM_hits))\n",
    "print ('friendly fire (%) = {0:.3f}'.format(total_US_hits/(total_US_hits+total_THEM_hits+1e-7)))\n",
    "\n",
    "print ('\\nStatistics by Team')\n",
    "print ('===================')\n",
    "top_tribe = None\n",
    "top_tribe_reward = 0\n",
    "\n",
    "for i, tribe in enumerate(tribes):\n",
    "    if tribe.name is not 'Crazies':\n",
    "        tribe_reward = sum(tribe.sum_rewards())\n",
    "        print ('Tribe {} has total reward of {}'.format(tribe.name, tribe_reward))\n",
    "                           \n",
    "        if tribe_reward > top_tribe_reward:   # Keep track of dominating team\n",
    "            top_tribe_reward = tribe_reward\n",
    "            top_tribe = tribe.name\n",
    "\n",
    "# Team dominance calculation                           \n",
    "print ('Dominating Team: {}'.format(top_tribe))\n",
    "dominance = top_tribe_reward/((total_rewards-top_tribe_reward+1.1e-7)/(len(tribes)-1))    \n",
    "print ('Team dominance: {0:.2f}x'.format(dominance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Stats - Individualist\n",
    "\n",
    "Our research requires the gathering of these agent and team statistics averaged over 30 episodes of game play:\n",
    "\n",
    "* Average agent reward - average number of apples gathered per agent per episode  \n",
    "* The dominating team per game episode  \n",
    "* Team dominance of the dominating team, defined by the following ratio:  \n",
    "    Apples gathered by dominating team / average( Apples gathered by other competing teams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L/individualist/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 371.1\n",
      "Av. agent reward = 41.23\n",
      "Num laser fired = 404.5\n",
      "Total US Hit (friendly fire) = 56.9\n",
      "Total THEM Hit = 137.3\n",
      "friendly fire (%) = 0.293\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 18.2\n",
      "Tribe Saxons has total reward of 168.8\n",
      "Tribe Franks has total reward of 184.0\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.97x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.03\n",
      "Agent0 reward is 0.6\n",
      "US agents hit = 6.1\n",
      "THEM agents hit = 6.4\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 17.7\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.08\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 13.2\n",
      "THEM agents hit = 25.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 23.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.5\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 36.4\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 4.1\n",
      "Agent5 of Saxons aggressiveness is 0.10\n",
      "Agent5 reward is 109.4\n",
      "US agents hit = 10.7\n",
      "THEM agents hit = 35.1\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 46.7\n",
      "US agents hit = 6.6\n",
      "THEM agents hit = 11.6\n",
      "Agent7 of Franks aggressiveness is 0.13\n",
      "Agent7 reward is 84.0\n",
      "US agents hit = 16.7\n",
      "THEM agents hit = 51.6\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 53.3\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 2.9\n",
      "Training time per epochs: 32.38 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 382.1\n",
      "Av. agent reward = 42.46\n",
      "Num laser fired = 433.6\n",
      "Total US Hit (friendly fire) = 58.4\n",
      "Total THEM Hit = 144.9\n",
      "friendly fire (%) = 0.287\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 17.0\n",
      "Tribe Saxons has total reward of 155.3\n",
      "Tribe Franks has total reward of 209.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.44x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 3.8\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 13.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.18\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 18.8\n",
      "THEM agents hit = 40.8\n",
      "Agent3 of Saxons aggressiveness is 0.03\n",
      "Agent3 reward is 55.4\n",
      "US agents hit = 4.5\n",
      "THEM agents hit = 11.6\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 28.7\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 71.2\n",
      "US agents hit = 4.9\n",
      "THEM agents hit = 20.8\n",
      "Agent6 of Franks aggressiveness is 0.06\n",
      "Agent6 reward is 44.0\n",
      "US agents hit = 8.8\n",
      "THEM agents hit = 18.0\n",
      "Agent7 of Franks aggressiveness is 0.13\n",
      "Agent7 reward is 105.4\n",
      "US agents hit = 20.6\n",
      "THEM agents hit = 52.7\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 60.5\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.5\n",
      "Training time per epochs: 34.23 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 407.5\n",
      "Av. agent reward = 45.27\n",
      "Num laser fired = 393.9\n",
      "Total US Hit (friendly fire) = 52.8\n",
      "Total THEM Hit = 148.9\n",
      "friendly fire (%) = 0.262\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 61.9\n",
      "Tribe Saxons has total reward of 147.0\n",
      "Tribe Franks has total reward of 198.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.90x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 8.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 14.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 38.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 1.5\n",
      "Agent3 of Saxons aggressiveness is 0.03\n",
      "Agent3 reward is 62.0\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 12.2\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 38.3\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 7.1\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 46.6\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 28.6\n",
      "Agent6 of Franks aggressiveness is 0.06\n",
      "Agent6 reward is 54.0\n",
      "US agents hit = 10.0\n",
      "THEM agents hit = 23.1\n",
      "Agent7 of Franks aggressiveness is 0.22\n",
      "Agent7 reward is 81.0\n",
      "US agents hit = 26.4\n",
      "THEM agents hit = 71.4\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 63.6\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 5.0\n",
      "Training time per epochs: 33.48 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 379.4\n",
      "Av. agent reward = 42.16\n",
      "Num laser fired = 397.8\n",
      "Total US Hit (friendly fire) = 44.3\n",
      "Total THEM Hit = 174.1\n",
      "friendly fire (%) = 0.203\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 78.8\n",
      "Tribe Saxons has total reward of 104.0\n",
      "Tribe Franks has total reward of 196.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.15x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 11.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 17.6\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 3.2\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 49.8\n",
      "US agents hit = 4.5\n",
      "THEM agents hit = 37.0\n",
      "Agent3 of Saxons aggressiveness is 0.07\n",
      "Agent3 reward is 37.9\n",
      "US agents hit = 8.3\n",
      "THEM agents hit = 19.4\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 17.4\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.4\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 48.8\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 14.9\n",
      "Agent6 of Franks aggressiveness is 0.13\n",
      "Agent6 reward is 70.6\n",
      "US agents hit = 16.8\n",
      "THEM agents hit = 42.4\n",
      "Agent7 of Franks aggressiveness is 0.08\n",
      "Agent7 reward is 81.0\n",
      "US agents hit = 11.3\n",
      "THEM agents hit = 55.5\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 45.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.4\n",
      "Training time per epochs: 33.38 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 394.9\n",
      "Av. agent reward = 43.87\n",
      "Num laser fired = 402.4\n",
      "Total US Hit (friendly fire) = 47.1\n",
      "Total THEM Hit = 156.4\n",
      "friendly fire (%) = 0.232\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 44.3\n",
      "Tribe Saxons has total reward of 118.4\n",
      "Tribe Franks has total reward of 232.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.85x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 16.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 27.7\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 14.7\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 29.1\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 5.4\n",
      "Agent4 of Saxons aggressiveness is 0.03\n",
      "Agent4 reward is 36.0\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 5.8\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 53.3\n",
      "US agents hit = 6.6\n",
      "THEM agents hit = 27.6\n",
      "Agent6 of Franks aggressiveness is 0.12\n",
      "Agent6 reward is 85.7\n",
      "US agents hit = 18.6\n",
      "THEM agents hit = 41.5\n",
      "Agent7 of Franks aggressiveness is 0.10\n",
      "Agent7 reward is 102.0\n",
      "US agents hit = 16.5\n",
      "THEM agents hit = 60.1\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 44.5\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 0.8\n",
      "Training time per epochs: 33.33 sec\n",
      "[41.22962962962963, 42.459259259259255, 45.27407407407407, 42.15555555555555, 43.87407407407407]\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "[1.967920155677395, 2.435674210091367, 1.901691668324995, 2.1502278929634, 2.8539233744277914]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = ['MA_models/3T-9L/individualist/']\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"individualist\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominating_tribe = [[None for i in episodes] for j in dir_names]\n",
    "dom_tribe_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominance = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 9 agents - 3 teams of 3 AI agents each and 0 random agent\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather_ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        # tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        total_rewards = cum_rewards/max_episodes\n",
    "        print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print ('Av. agent reward = {:.2f}'.format(av_agent_reward[dir_num][eps_num]))\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "       \n",
    "        for i, tribe in enumerate(tribes):\n",
    "            if tribe.name is not 'Crazies':\n",
    "                tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                # Keep track of dominating team and the rewards gathered\n",
    "                if tribe_reward > dom_tribe_reward[dir_num][eps_num]:   \n",
    "                    dom_tribe_reward[dir_num][eps_num] = tribe_reward\n",
    "                    dominating_tribe[dir_num][eps_num]  = tribe.name\n",
    "\n",
    "        # Team dominance calculation                           \n",
    "        print ('Dominating Tribe: {}'.format(dominating_tribe[dir_num][eps_num]))\n",
    "        dominance[dir_num][eps_num] = dom_tribe_reward[dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "        print ('Team dominance: {0:.2f}x'.format(dominance[dir_num][eps_num]))\n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "    \n",
    "for tribe in dominating_tribe:   # Dominating team\n",
    "    print(tribe)\n",
    "\n",
    "for value in dominance:      # Team dominance\n",
    "    print(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Stats - Pacifists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L/pacifist/p-0.01/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 386.5\n",
      "Av. agent reward = 42.95\n",
      "Num laser fired = 281.6\n",
      "Total US Hit (friendly fire) = 40.8\n",
      "Total THEM Hit = 108.7\n",
      "friendly fire (%) = 0.273\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 140.9\n",
      "Tribe Saxons has total reward of 50.8\n",
      "Tribe Franks has total reward of 194.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.03x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.17\n",
      "Agent0 reward is 106.9\n",
      "US agents hit = 16.8\n",
      "THEM agents hit = 61.3\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 12.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 21.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 21.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 29.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.11\n",
      "Agent6 reward is 119.5\n",
      "US agents hit = 23.8\n",
      "THEM agents hit = 47.3\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 38.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 37.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.36 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 426.2\n",
      "Av. agent reward = 47.36\n",
      "Num laser fired = 240.2\n",
      "Total US Hit (friendly fire) = 45.6\n",
      "Total THEM Hit = 102.7\n",
      "friendly fire (%) = 0.308\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 127.4\n",
      "Tribe Saxons has total reward of 66.0\n",
      "Tribe Franks has total reward of 232.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.41x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.08\n",
      "Agent0 reward is 88.2\n",
      "US agents hit = 14.3\n",
      "THEM agents hit = 43.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 20.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 19.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 32.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 33.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.16\n",
      "Agent6 reward is 138.8\n",
      "US agents hit = 31.3\n",
      "THEM agents hit = 59.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 40.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 54.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.25 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 413.2\n",
      "Av. agent reward = 45.91\n",
      "Num laser fired = 321.3\n",
      "Total US Hit (friendly fire) = 50.2\n",
      "Total THEM Hit = 116.3\n",
      "friendly fire (%) = 0.302\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 103.2\n",
      "Tribe Saxons has total reward of 66.2\n",
      "Tribe Franks has total reward of 243.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.88x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.10\n",
      "Agent0 reward is 64.5\n",
      "US agents hit = 16.2\n",
      "THEM agents hit = 47.3\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 22.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 16.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 30.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 35.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.22\n",
      "Agent6 reward is 161.4\n",
      "US agents hit = 34.0\n",
      "THEM agents hit = 69.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 32.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 49.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.12 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 455.8\n",
      "Av. agent reward = 50.64\n",
      "Num laser fired = 272.3\n",
      "Total US Hit (friendly fire) = 42.4\n",
      "Total THEM Hit = 111.3\n",
      "friendly fire (%) = 0.276\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 182.4\n",
      "Tribe Saxons has total reward of 82.0\n",
      "Tribe Franks has total reward of 191.4\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.45x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.18\n",
      "Agent0 reward is 141.7\n",
      "US agents hit = 20.3\n",
      "THEM agents hit = 69.5\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 25.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 14.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 39.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 42.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.09\n",
      "Agent6 reward is 114.0\n",
      "US agents hit = 22.2\n",
      "THEM agents hit = 41.8\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 28.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 49.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.39 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 436.2\n",
      "Av. agent reward = 48.47\n",
      "Num laser fired = 301.4\n",
      "Total US Hit (friendly fire) = 48.0\n",
      "Total THEM Hit = 113.6\n",
      "friendly fire (%) = 0.297\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 158.7\n",
      "Tribe Saxons has total reward of 60.1\n",
      "Tribe Franks has total reward of 217.4\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.99x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.19\n",
      "Agent0 reward is 117.4\n",
      "US agents hit = 22.3\n",
      "THEM agents hit = 66.5\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 30.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 11.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 31.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 28.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.11\n",
      "Agent6 reward is 135.6\n",
      "US agents hit = 25.7\n",
      "THEM agents hit = 47.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 32.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 48.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.22 sec\n",
      "###### Dir = MA_models/3T-9L/pacifist/p-0.1/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 511.4\n",
      "Av. agent reward = 56.82\n",
      "Num laser fired = 130.3\n",
      "Total US Hit (friendly fire) = 36.0\n",
      "Total THEM Hit = 80.2\n",
      "friendly fire (%) = 0.310\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 75.3\n",
      "Tribe Saxons has total reward of 116.4\n",
      "Tribe Franks has total reward of 319.7\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.33x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 30.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 44.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 34.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 54.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 27.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 40.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.13\n",
      "Agent7 reward is 219.2\n",
      "US agents hit = 35.9\n",
      "THEM agents hit = 80.1\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 59.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 3.52 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 573.3\n",
      "Av. agent reward = 63.70\n",
      "Num laser fired = 126.8\n",
      "Total US Hit (friendly fire) = 40.2\n",
      "Total THEM Hit = 81.9\n",
      "friendly fire (%) = 0.329\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 67.4\n",
      "Tribe Saxons has total reward of 122.0\n",
      "Tribe Franks has total reward of 383.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.05x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 30.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 37.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 39.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 45.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 37.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 46.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.13\n",
      "Agent7 reward is 271.5\n",
      "US agents hit = 40.0\n",
      "THEM agents hit = 81.8\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 65.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 3.49 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 568.3\n",
      "Av. agent reward = 63.14\n",
      "Num laser fired = 200.1\n",
      "Total US Hit (friendly fire) = 45.3\n",
      "Total THEM Hit = 97.9\n",
      "friendly fire (%) = 0.316\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 67.6\n",
      "Tribe Saxons has total reward of 101.6\n",
      "Tribe Franks has total reward of 399.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.72x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 24.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 43.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 32.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 36.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 32.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 37.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.20\n",
      "Agent7 reward is 304.1\n",
      "US agents hit = 45.2\n",
      "THEM agents hit = 97.9\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 57.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.34 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 539.5\n",
      "Av. agent reward = 59.95\n",
      "Num laser fired = 237.4\n",
      "Total US Hit (friendly fire) = 49.4\n",
      "Total THEM Hit = 103.7\n",
      "friendly fire (%) = 0.323\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 64.4\n",
      "Tribe Saxons has total reward of 88.4\n",
      "Tribe Franks has total reward of 386.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 5.06x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 22.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 41.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 28.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 33.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 26.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 39.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.24\n",
      "Agent7 reward is 297.1\n",
      "US agents hit = 49.4\n",
      "THEM agents hit = 103.7\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 50.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.20 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 582.4\n",
      "Av. agent reward = 64.71\n",
      "Num laser fired = 113.1\n",
      "Total US Hit (friendly fire) = 39.3\n",
      "Total THEM Hit = 94.3\n",
      "friendly fire (%) = 0.294\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 81.4\n",
      "Tribe Saxons has total reward of 130.2\n",
      "Tribe Franks has total reward of 370.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.51x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 24.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 57.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 38.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 52.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 39.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 54.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.11\n",
      "Agent7 reward is 239.4\n",
      "US agents hit = 39.3\n",
      "THEM agents hit = 94.3\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 77.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.24 sec\n",
      "###### Dir = MA_models/3T-9L/pacifist/p-1.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 691.8\n",
      "Av. agent reward = 76.87\n",
      "Num laser fired = 0.7\n",
      "Total US Hit (friendly fire) = 0.7\n",
      "Total THEM Hit = 1.3\n",
      "friendly fire (%) = 0.333\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 232.6\n",
      "Tribe Saxons has total reward of 243.9\n",
      "Tribe Franks has total reward of 215.2\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.09x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 72.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 67.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 92.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 80.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 89.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 74.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 68.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 67.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 79.1\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Training time per epochs: 3.34 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 715.3\n",
      "Av. agent reward = 79.48\n",
      "Num laser fired = 0.1\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.1\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 244.9\n",
      "Tribe Saxons has total reward of 231.8\n",
      "Tribe Franks has total reward of 238.6\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.04x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 80.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 75.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 88.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 77.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 75.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 78.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 73.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 71.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 93.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.43 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 727.1\n",
      "Av. agent reward = 80.79\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 249.6\n",
      "Tribe Saxons has total reward of 254.6\n",
      "Tribe Franks has total reward of 222.9\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.08x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 81.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 73.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 94.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 104.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 75.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 73.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 73.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 79.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 70.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.15 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 705.4\n",
      "Av. agent reward = 78.38\n",
      "Num laser fired = 0.1\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.1\n",
      "friendly fire (%) = 0.250\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 258.8\n",
      "Tribe Saxons has total reward of 259.4\n",
      "Tribe Franks has total reward of 187.3\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.16x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 88.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 69.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 101.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 108.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 78.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 72.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 51.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 66.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 69.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 711.6\n",
      "Av. agent reward = 79.07\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 226.8\n",
      "Tribe Saxons has total reward of 269.6\n",
      "Tribe Franks has total reward of 215.2\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.22x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 92.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 59.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 74.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 117.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 80.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 71.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 66.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 85.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 63.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.04 sec\n",
      "###### Dir = MA_models/3T-9L/pacifist/p-10.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 655.3\n",
      "Av. agent reward = 72.81\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 230.9\n",
      "Tribe Saxons has total reward of 206.1\n",
      "Tribe Franks has total reward of 218.2\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.09x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 79.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 84.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 66.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 57.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 66.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 81.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 57.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 73.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 87.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 704.3\n",
      "Av. agent reward = 78.26\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 238.2\n",
      "Tribe Saxons has total reward of 222.7\n",
      "Tribe Franks has total reward of 243.4\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.06x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 69.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 80.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 88.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 64.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 76.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 81.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 74.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 81.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 87.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 707.5\n",
      "Av. agent reward = 78.61\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 255.6\n",
      "Tribe Saxons has total reward of 216.3\n",
      "Tribe Franks has total reward of 235.6\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.13x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 75.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 94.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 86.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 77.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 53.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 85.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 61.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 92.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 81.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 711.0\n",
      "Av. agent reward = 79.00\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 253.3\n",
      "Tribe Saxons has total reward of 225.0\n",
      "Tribe Franks has total reward of 232.7\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.11x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 75.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 81.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 96.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 61.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 62.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 101.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 62.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 96.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 74.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.11 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 681.2\n",
      "Av. agent reward = 75.69\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 239.7\n",
      "Tribe Saxons has total reward of 211.4\n",
      "Tribe Franks has total reward of 230.1\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.09x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 82.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 79.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 78.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 73.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 63.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 74.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 69.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 93.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 67.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.12 sec\n",
      "###### Dir = MA_models/3T-9L/pacifist/p-100.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 697.5\n",
      "Av. agent reward = 77.50\n",
      "Num laser fired = 0.1\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.1\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 225.9\n",
      "Tribe Saxons has total reward of 236.1\n",
      "Tribe Franks has total reward of 235.5\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.02x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 63.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 78.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 83.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 86.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 82.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 66.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 76.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 77.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 81.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.14 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 686.4\n",
      "Av. agent reward = 76.27\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 212.2\n",
      "Tribe Saxons has total reward of 211.2\n",
      "Tribe Franks has total reward of 263.0\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.24x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 72.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 71.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 67.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 72.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 77.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 60.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 97.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 94.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 71.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.10 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 696.5\n",
      "Av. agent reward = 77.39\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 227.8\n",
      "Tribe Saxons has total reward of 223.5\n",
      "Tribe Franks has total reward of 245.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.09x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 72.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 71.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 84.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 75.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 84.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 63.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 88.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 83.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 73.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 722.8\n",
      "Av. agent reward = 80.31\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 251.0\n",
      "Tribe Saxons has total reward of 236.0\n",
      "Tribe Franks has total reward of 235.8\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.06x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 91.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 75.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 84.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 87.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 90.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 58.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 77.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 80.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 78.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.21 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 670.3\n",
      "Av. agent reward = 74.47\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 223.4\n",
      "Tribe Saxons has total reward of 212.6\n",
      "Tribe Franks has total reward of 234.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.07x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 87.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 66.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 69.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 76.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 75.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 60.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 69.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 82.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 81.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.17 sec\n",
      "[42.94814814814815, 47.35925925925926, 45.90740740740741, 50.644444444444446, 48.46666666666667]\n",
      "[56.82222222222222, 63.699999999999996, 63.14074074074074, 59.94814814814814, 64.7074074074074]\n",
      "[76.86666666666666, 79.48148148148148, 80.7925925925926, 78.38148148148147, 79.07037037037037]\n",
      "[72.80740740740741, 78.25555555555555, 78.61111111111111, 79.0, 75.68518518518518]\n",
      "[77.4962962962963, 76.27037037037036, 77.38888888888889, 80.30740740740741, 74.47407407407407]\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Saxons', 'Vikings', 'Saxons', 'Saxons', 'Saxons']\n",
      "['Vikings', 'Franks', 'Vikings', 'Vikings', 'Vikings']\n",
      "['Saxons', 'Franks', 'Franks', 'Vikings', 'Franks']\n",
      "[2.0319888722695474, 2.4093103434567715, 2.8780007852228646, 1.4478063534067374, 1.9865955816365934]\n",
      "[3.334492348573745, 4.053854274308744, 4.717100075735534, 5.063495523301433, 3.5052780823117353]\n",
      "[1.0893122950584453, 1.0411677174636254, 1.0773788528210941, 1.162905395020357, 1.2198175096881536]\n",
      "[1.088452474187597, 1.0564154489016224, 1.1312237217870444, 1.1066122921896433, 1.0856927139612846]\n",
      "[1.0234809621141907, 1.242481498653741, 1.0864106348903135, 1.0638688707424921, 1.0748528172224932]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\"MA_models/3T-9L/pacifist/p-0.01/\",\n",
    "             \"MA_models/3T-9L/pacifist/p-0.1/\", \n",
    "             \"MA_models/3T-9L/pacifist/p-1.0/\",\n",
    "             \"MA_models/3T-9L/pacifist/p-10.0/\",\n",
    "             \"MA_models/3T-9L/pacifist/p-100.0/\"]\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"pacifist\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominating_tribe = [[None for i in episodes] for j in dir_names]\n",
    "dom_tribe_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominance = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 9 agents - 3 teams of 3 AI agents each and 0 random agent\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather_ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        # tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        total_rewards = cum_rewards/max_episodes\n",
    "        print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print ('Av. agent reward = {:.2f}'.format(av_agent_reward[dir_num][eps_num]))\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "       \n",
    "        for i, tribe in enumerate(tribes):\n",
    "            if tribe.name is not 'Crazies':\n",
    "                tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                # Keep track of dominating team and the rewards gathered\n",
    "                if tribe_reward > dom_tribe_reward[dir_num][eps_num]:   \n",
    "                    dom_tribe_reward[dir_num][eps_num] = tribe_reward\n",
    "                    dominating_tribe[dir_num][eps_num]  = tribe.name\n",
    "\n",
    "        # Team dominance calculation                           \n",
    "        print ('Dominating Tribe: {}'.format(dominating_tribe[dir_num][eps_num]))\n",
    "        dominance[dir_num][eps_num] = dom_tribe_reward[dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "        print ('Team dominance: {0:.2f}x'.format(dominance[dir_num][eps_num]))\n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "    \n",
    "for tribe in dominating_tribe:   # Dominating team\n",
    "    print(tribe)\n",
    "\n",
    "for value in dominance:      # Team dominance\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Stats - No_Fragging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L/no_fragging/p-0.01/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 406.5\n",
      "Av. agent reward = 45.17\n",
      "Num laser fired = 331.4\n",
      "Total US Hit (friendly fire) = 46.9\n",
      "Total THEM Hit = 135.9\n",
      "friendly fire (%) = 0.257\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 68.8\n",
      "Tribe Saxons has total reward of 182.7\n",
      "Tribe Franks has total reward of 155.0\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.63x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 26.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 20.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 22.8\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 35.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 21.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.22\n",
      "Agent5 reward is 126.4\n",
      "US agents hit = 28.8\n",
      "THEM agents hit = 81.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 34.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 15.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 106.0\n",
      "US agents hit = 17.9\n",
      "THEM agents hit = 54.3\n",
      "Training time per epochs: 3.03 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 457.4\n",
      "Av. agent reward = 50.82\n",
      "Num laser fired = 394.9\n",
      "Total US Hit (friendly fire) = 49.1\n",
      "Total THEM Hit = 144.5\n",
      "friendly fire (%) = 0.254\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 62.4\n",
      "Tribe Saxons has total reward of 251.8\n",
      "Tribe Franks has total reward of 143.2\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 2.45x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 20.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.6\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 21.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 20.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 28.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 32.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.21\n",
      "Agent5 reward is 190.9\n",
      "US agents hit = 24.6\n",
      "THEM agents hit = 77.9\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 34.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 15.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.18\n",
      "Agent8 reward is 93.2\n",
      "US agents hit = 24.4\n",
      "THEM agents hit = 65.9\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 407.8\n",
      "Av. agent reward = 45.31\n",
      "Num laser fired = 444.6\n",
      "Total US Hit (friendly fire) = 44.1\n",
      "Total THEM Hit = 151.9\n",
      "friendly fire (%) = 0.225\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 129.0\n",
      "Tribe Saxons has total reward of 204.5\n",
      "Tribe Franks has total reward of 74.3\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 2.01x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.09\n",
      "Agent0 reward is 97.0\n",
      "US agents hit = 14.1\n",
      "THEM agents hit = 38.9\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 16.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 15.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 23.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 33.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.13\n",
      "Agent5 reward is 147.5\n",
      "US agents hit = 16.2\n",
      "THEM agents hit = 53.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 41.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 10.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.22\n",
      "Agent8 reward is 22.5\n",
      "US agents hit = 13.7\n",
      "THEM agents hit = 59.8\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 433.7\n",
      "Av. agent reward = 48.19\n",
      "Num laser fired = 310.7\n",
      "Total US Hit (friendly fire) = 46.3\n",
      "Total THEM Hit = 143.1\n",
      "friendly fire (%) = 0.245\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 195.2\n",
      "Tribe Saxons has total reward of 133.9\n",
      "Tribe Franks has total reward of 104.6\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.64x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.11\n",
      "Agent0 reward is 160.5\n",
      "US agents hit = 16.1\n",
      "THEM agents hit = 53.3\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 22.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 12.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 26.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 29.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.13\n",
      "Agent5 reward is 78.5\n",
      "US agents hit = 13.4\n",
      "THEM agents hit = 47.8\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 23.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 11.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 70.1\n",
      "US agents hit = 16.8\n",
      "THEM agents hit = 41.9\n",
      "Training time per epochs: 3.14 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 392.4\n",
      "Av. agent reward = 43.60\n",
      "Num laser fired = 404.5\n",
      "Total US Hit (friendly fire) = 51.8\n",
      "Total THEM Hit = 157.6\n",
      "friendly fire (%) = 0.247\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 117.0\n",
      "Tribe Saxons has total reward of 157.2\n",
      "Tribe Franks has total reward of 118.2\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.34x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.14\n",
      "Agent0 reward is 72.7\n",
      "US agents hit = 12.7\n",
      "THEM agents hit = 53.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 13.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 30.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 31.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 32.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.08\n",
      "Agent5 reward is 92.6\n",
      "US agents hit = 14.0\n",
      "THEM agents hit = 41.7\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 36.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 10.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.19\n",
      "Agent8 reward is 71.2\n",
      "US agents hit = 25.0\n",
      "THEM agents hit = 62.9\n",
      "Training time per epochs: 3.13 sec\n",
      "###### Dir = MA_models/3T-9L/no_fragging/p-0.1/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 357.7\n",
      "Av. agent reward = 39.75\n",
      "Num laser fired = 398.6\n",
      "Total US Hit (friendly fire) = 54.6\n",
      "Total THEM Hit = 115.3\n",
      "friendly fire (%) = 0.321\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 48.5\n",
      "Tribe Saxons has total reward of 76.8\n",
      "Tribe Franks has total reward of 232.4\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.71x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 27.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 20.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 31.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 19.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 25.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 39.0\n",
      "US agents hit = 5.4\n",
      "THEM agents hit = 6.1\n",
      "Agent7 of Franks aggressiveness is 0.14\n",
      "Agent7 reward is 90.9\n",
      "US agents hit = 22.2\n",
      "THEM agents hit = 43.4\n",
      "Agent8 of Franks aggressiveness is 0.24\n",
      "Agent8 reward is 102.5\n",
      "US agents hit = 26.8\n",
      "THEM agents hit = 65.1\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 460.0\n",
      "Av. agent reward = 51.11\n",
      "Num laser fired = 316.0\n",
      "Total US Hit (friendly fire) = 49.4\n",
      "Total THEM Hit = 128.0\n",
      "friendly fire (%) = 0.278\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 76.3\n",
      "Tribe Saxons has total reward of 134.9\n",
      "Tribe Franks has total reward of 248.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.36x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 57.0\n",
      "US agents hit = 3.3\n",
      "THEM agents hit = 22.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 19.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 43.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 33.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.09\n",
      "Agent5 reward is 58.3\n",
      "US agents hit = 9.1\n",
      "THEM agents hit = 26.8\n",
      "Agent6 of Franks aggressiveness is 0.07\n",
      "Agent6 reward is 105.4\n",
      "US agents hit = 16.7\n",
      "THEM agents hit = 28.2\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 40.1\n",
      "US agents hit = 2.7\n",
      "THEM agents hit = 4.5\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 103.3\n",
      "US agents hit = 17.6\n",
      "THEM agents hit = 46.4\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 450.7\n",
      "Av. agent reward = 50.07\n",
      "Num laser fired = 294.7\n",
      "Total US Hit (friendly fire) = 48.5\n",
      "Total THEM Hit = 148.4\n",
      "friendly fire (%) = 0.246\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 25.3\n",
      "Tribe Saxons has total reward of 135.5\n",
      "Tribe Franks has total reward of 289.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.61x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 25.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 28.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 33.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.09\n",
      "Agent5 reward is 73.4\n",
      "US agents hit = 11.7\n",
      "THEM agents hit = 36.7\n",
      "Agent6 of Franks aggressiveness is 0.07\n",
      "Agent6 reward is 124.3\n",
      "US agents hit = 13.1\n",
      "THEM agents hit = 25.3\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 40.5\n",
      "US agents hit = 3.0\n",
      "THEM agents hit = 3.8\n",
      "Agent8 of Franks aggressiveness is 0.11\n",
      "Agent8 reward is 125.0\n",
      "US agents hit = 20.7\n",
      "THEM agents hit = 82.6\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 435.2\n",
      "Av. agent reward = 48.36\n",
      "Num laser fired = 334.3\n",
      "Total US Hit (friendly fire) = 47.9\n",
      "Total THEM Hit = 114.4\n",
      "friendly fire (%) = 0.295\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 22.6\n",
      "Tribe Saxons has total reward of 170.0\n",
      "Tribe Franks has total reward of 242.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.52x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 22.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 29.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 31.4\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 5.1\n",
      "Agent5 of Saxons aggressiveness is 0.18\n",
      "Agent5 reward is 108.7\n",
      "US agents hit = 17.9\n",
      "THEM agents hit = 43.3\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 83.2\n",
      "US agents hit = 9.3\n",
      "THEM agents hit = 15.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 43.2\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 1.4\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 116.2\n",
      "US agents hit = 18.4\n",
      "THEM agents hit = 48.9\n",
      "Training time per epochs: 3.39 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 489.8\n",
      "Av. agent reward = 54.42\n",
      "Num laser fired = 304.5\n",
      "Total US Hit (friendly fire) = 48.9\n",
      "Total THEM Hit = 133.3\n",
      "friendly fire (%) = 0.269\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 29.0\n",
      "Tribe Saxons has total reward of 221.7\n",
      "Tribe Franks has total reward of 239.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.91x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 29.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 43.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 42.3\n",
      "US agents hit = 1.6\n",
      "THEM agents hit = 4.0\n",
      "Agent5 of Saxons aggressiveness is 0.21\n",
      "Agent5 reward is 135.7\n",
      "US agents hit = 19.8\n",
      "THEM agents hit = 45.9\n",
      "Agent6 of Franks aggressiveness is 0.03\n",
      "Agent6 reward is 89.5\n",
      "US agents hit = 7.4\n",
      "THEM agents hit = 15.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 39.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 110.1\n",
      "US agents hit = 20.0\n",
      "THEM agents hit = 67.6\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Dir = MA_models/3T-9L/no_fragging/p-1.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 535.8\n",
      "Av. agent reward = 59.53\n",
      "Num laser fired = 213.9\n",
      "Total US Hit (friendly fire) = 41.9\n",
      "Total THEM Hit = 107.9\n",
      "friendly fire (%) = 0.280\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 86.0\n",
      "Tribe Saxons has total reward of 113.6\n",
      "Tribe Franks has total reward of 336.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.37x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 28.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 29.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 27.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 36.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 36.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 40.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 39.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 54.3\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.7\n",
      "Agent8 of Franks aggressiveness is 0.21\n",
      "Agent8 reward is 242.2\n",
      "US agents hit = 40.9\n",
      "THEM agents hit = 105.8\n",
      "Training time per epochs: 3.10 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 516.9\n",
      "Av. agent reward = 57.44\n",
      "Num laser fired = 201.9\n",
      "Total US Hit (friendly fire) = 49.9\n",
      "Total THEM Hit = 111.9\n",
      "friendly fire (%) = 0.308\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 93.8\n",
      "Tribe Saxons has total reward of 104.4\n",
      "Tribe Franks has total reward of 318.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.22x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 25.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 42.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 25.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 29.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 39.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 36.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.11\n",
      "Agent6 reward is 154.9\n",
      "US agents hit = 27.3\n",
      "THEM agents hit = 60.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 42.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 121.5\n",
      "US agents hit = 22.6\n",
      "THEM agents hit = 51.6\n",
      "Training time per epochs: 3.14 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 490.1\n",
      "Av. agent reward = 54.45\n",
      "Num laser fired = 378.9\n",
      "Total US Hit (friendly fire) = 38.2\n",
      "Total THEM Hit = 97.0\n",
      "friendly fire (%) = 0.283\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 54.0\n",
      "Tribe Saxons has total reward of 106.6\n",
      "Tribe Franks has total reward of 329.5\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.10x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 23.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 23.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 7.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 26.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 47.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 33.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.10\n",
      "Agent6 reward is 108.1\n",
      "US agents hit = 17.4\n",
      "THEM agents hit = 40.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 36.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.28\n",
      "Agent8 reward is 185.0\n",
      "US agents hit = 20.9\n",
      "THEM agents hit = 56.8\n",
      "Training time per epochs: 3.14 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 549.7\n",
      "Av. agent reward = 61.08\n",
      "Num laser fired = 207.9\n",
      "Total US Hit (friendly fire) = 47.7\n",
      "Total THEM Hit = 107.6\n",
      "friendly fire (%) = 0.307\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 70.1\n",
      "Tribe Saxons has total reward of 104.8\n",
      "Tribe Franks has total reward of 374.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.29x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 29.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 34.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 5.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 25.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 39.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 40.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.12\n",
      "Agent6 reward is 171.4\n",
      "US agents hit = 27.1\n",
      "THEM agents hit = 61.9\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 52.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 151.3\n",
      "US agents hit = 20.5\n",
      "THEM agents hit = 45.6\n",
      "Training time per epochs: 3.12 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 544.1\n",
      "Av. agent reward = 60.46\n",
      "Num laser fired = 206.6\n",
      "Total US Hit (friendly fire) = 48.6\n",
      "Total THEM Hit = 124.6\n",
      "friendly fire (%) = 0.281\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 68.2\n",
      "Tribe Saxons has total reward of 107.3\n",
      "Tribe Franks has total reward of 368.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.20x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 27.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 33.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 7.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 23.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 40.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 43.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.12\n",
      "Agent6 reward is 160.3\n",
      "US agents hit = 25.7\n",
      "THEM agents hit = 76.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 57.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 150.7\n",
      "US agents hit = 22.9\n",
      "THEM agents hit = 48.7\n",
      "Training time per epochs: 3.14 sec\n",
      "###### Dir = MA_models/3T-9L/no_fragging/p-10.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 662.1\n",
      "Av. agent reward = 73.56\n",
      "Num laser fired = 0.3\n",
      "Total US Hit (friendly fire) = 0.1\n",
      "Total THEM Hit = 0.4\n",
      "friendly fire (%) = 0.235\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 241.5\n",
      "Tribe Saxons has total reward of 150.2\n",
      "Tribe Franks has total reward of 270.4\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.38x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 85.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 76.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 79.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 77.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 72.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 95.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 86.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 88.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 3.23 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 682.2\n",
      "Av. agent reward = 75.80\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 255.6\n",
      "Tribe Saxons has total reward of 149.5\n",
      "Tribe Franks has total reward of 277.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.37x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 83.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 87.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 84.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 81.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 1.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 66.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 104.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 89.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 83.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.27 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 697.4\n",
      "Av. agent reward = 77.49\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.1\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 255.3\n",
      "Tribe Saxons has total reward of 154.1\n",
      "Tribe Franks has total reward of 288.0\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.41x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 85.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 97.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 72.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 79.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 74.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 84.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 106.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 97.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.23 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 706.5\n",
      "Av. agent reward = 78.50\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 294.6\n",
      "Tribe Saxons has total reward of 130.0\n",
      "Tribe Franks has total reward of 281.9\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.43x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 92.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 99.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 102.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 61.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 68.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 103.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 79.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 98.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.20 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 725.1\n",
      "Av. agent reward = 80.57\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 281.0\n",
      "Tribe Saxons has total reward of 161.0\n",
      "Tribe Franks has total reward of 283.0\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.28x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 94.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 83.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 103.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 84.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 76.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 100.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 91.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 91.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.27 sec\n",
      "###### Dir = MA_models/3T-9L/no_fragging/p-100.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 644.3\n",
      "Av. agent reward = 71.59\n",
      "Num laser fired = 0.3\n",
      "Total US Hit (friendly fire) = 0.1\n",
      "Total THEM Hit = 0.6\n",
      "friendly fire (%) = 0.150\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 224.5\n",
      "Tribe Saxons has total reward of 218.2\n",
      "Tribe Franks has total reward of 201.6\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.07x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 79.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 77.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 68.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 76.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 75.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 66.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 63.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 71.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 67.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.29 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 679.0\n",
      "Av. agent reward = 75.44\n",
      "Num laser fired = 0.2\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.3\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 231.4\n",
      "Tribe Saxons has total reward of 234.2\n",
      "Tribe Franks has total reward of 213.4\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.05x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 80.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 90.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 60.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 78.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 77.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 78.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 70.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 69.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 72.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.23 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 697.6\n",
      "Av. agent reward = 77.51\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 231.0\n",
      "Tribe Saxons has total reward of 232.4\n",
      "Tribe Franks has total reward of 234.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.01x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 86.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 77.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 67.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 86.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 80.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 65.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 81.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 62.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 90.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.38 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 706.2\n",
      "Av. agent reward = 78.46\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 225.4\n",
      "Tribe Saxons has total reward of 236.7\n",
      "Tribe Franks has total reward of 244.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.06x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 66.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 98.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 61.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 80.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 74.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 82.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 84.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 74.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 85.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 723.4\n",
      "Av. agent reward = 80.38\n",
      "Num laser fired = 0.0\n",
      "Total US Hit (friendly fire) = 0.0\n",
      "Total THEM Hit = 0.0\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 240.5\n",
      "Tribe Saxons has total reward of 229.1\n",
      "Tribe Franks has total reward of 253.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.08x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 75.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 103.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 61.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 84.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 69.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 74.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 81.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 82.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 90.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.06 sec\n",
      "[45.17037037037037, 50.82222222222222, 45.31481481481481, 48.1925925925926, 43.596296296296295]\n",
      "[39.74814814814815, 51.111111111111114, 50.074074074074076, 48.355555555555554, 54.422222222222224]\n",
      "[59.529629629629625, 57.43703703703703, 54.45185185185185, 61.08148148148148, 60.459259259259255]\n",
      "[73.56296296296297, 75.79629629629629, 77.49259259259259, 78.5037037037037, 80.56666666666666]\n",
      "[71.58518518518518, 75.44074074074075, 77.51111111111112, 78.46296296296296, 80.37777777777778]\n",
      "['Saxons', 'Saxons', 'Saxons', 'Vikings', 'Saxons']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Vikings', 'Franks']\n",
      "['Vikings', 'Saxons', 'Franks', 'Franks', 'Franks']\n",
      "[1.6319237633434558, 2.448695087035064, 2.012133135491058, 1.636160401648829, 1.337397220808986]\n",
      "[3.706992817805616, 2.3574360581339535, 3.606469000227793, 2.5192107981458296, 1.907978722566977]\n",
      "[3.3693001484685667, 3.21715727323522, 4.102947278219234, 4.285060972915263, 4.20094966498326]\n",
      "[1.3807659570590187, 1.3678927010191686, 1.4065450989383264, 1.4300509746161367, 1.2805006783120458]\n",
      "[1.0696418642476124, 1.0529076736005247, 1.010789814175255, 1.0567780099929756, 1.0813573758647965]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\"MA_models/3T-9L/no_fragging/p-0.01/\",\n",
    "             \"MA_models/3T-9L/no_fragging/p-0.1/\", \n",
    "             \"MA_models/3T-9L/no_fragging/p-1.0/\",\n",
    "             \"MA_models/3T-9L/no_fragging/p-10.0/\",\n",
    "             \"MA_models/3T-9L/no_fragging/p-100.0/\"]\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"no_fragging\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominating_tribe = [[None for i in episodes] for j in dir_names]\n",
    "dom_tribe_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominance = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 9 agents - 3 teams of 3 AI agents each and 0 random agent\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather_ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        # tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        total_rewards = cum_rewards/max_episodes\n",
    "        print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print ('Av. agent reward = {:.2f}'.format(av_agent_reward[dir_num][eps_num]))\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "       \n",
    "        for i, tribe in enumerate(tribes):\n",
    "            if tribe.name is not 'Crazies':\n",
    "                tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                # Keep track of dominating team and the rewards gathered\n",
    "                if tribe_reward > dom_tribe_reward[dir_num][eps_num]:   \n",
    "                    dom_tribe_reward[dir_num][eps_num] = tribe_reward\n",
    "                    dominating_tribe[dir_num][eps_num]  = tribe.name\n",
    "\n",
    "        # Team dominance calculation                           \n",
    "        print ('Dominating Tribe: {}'.format(dominating_tribe[dir_num][eps_num]))\n",
    "        dominance[dir_num][eps_num] = dom_tribe_reward[dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "        print ('Team dominance: {0:.2f}x'.format(dominance[dir_num][eps_num]))\n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "    \n",
    "for tribe in dominating_tribe:   # Dominating team\n",
    "    print(tribe)\n",
    "\n",
    "for value in dominance:      # Team dominance\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Stats - Cooperative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L/cooperative/cf0.01/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 343.3\n",
      "Av. agent reward = 38.15\n",
      "Num laser fired = 284.9\n",
      "Total US Hit (friendly fire) = 33.9\n",
      "Total THEM Hit = 127.0\n",
      "friendly fire (%) = 0.211\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 191.4\n",
      "Tribe Saxons has total reward of 44.9\n",
      "Tribe Franks has total reward of 107.0\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 2.52x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 21.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 2.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent2 of Vikings aggressiveness is 0.15\n",
      "Agent2 reward is 168.1\n",
      "US agents hit = 14.6\n",
      "THEM agents hit = 59.8\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 37.5\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 3.8\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 6.6\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 4.8\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 0.8\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 12.1\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 22.1\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 9.2\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 5.6\n",
      "THEM agents hit = 26.5\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 84.9\n",
      "US agents hit = 3.1\n",
      "THEM agents hit = 10.2\n",
      "Training time per epochs: 2.95 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 350.5\n",
      "Av. agent reward = 38.95\n",
      "Num laser fired = 322.3\n",
      "Total US Hit (friendly fire) = 44.2\n",
      "Total THEM Hit = 146.3\n",
      "friendly fire (%) = 0.232\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 150.3\n",
      "Tribe Saxons has total reward of 77.6\n",
      "Tribe Franks has total reward of 122.7\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.50x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 15.1\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 2.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 10.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.12\n",
      "Agent2 reward is 124.5\n",
      "US agents hit = 22.5\n",
      "THEM agents hit = 80.2\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 42.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 5.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 24.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.05\n",
      "Agent5 reward is 10.7\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 11.7\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 37.7\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 3.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.2\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 3.2\n",
      "Agent8 of Franks aggressiveness is 0.12\n",
      "Agent8 reward is 84.8\n",
      "US agents hit = 15.0\n",
      "THEM agents hit = 40.2\n",
      "Training time per epochs: 2.91 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 355.6\n",
      "Av. agent reward = 39.51\n",
      "Num laser fired = 364.1\n",
      "Total US Hit (friendly fire) = 46.9\n",
      "Total THEM Hit = 162.7\n",
      "friendly fire (%) = 0.224\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 141.0\n",
      "Tribe Saxons has total reward of 92.0\n",
      "Tribe Franks has total reward of 122.6\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.31x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 13.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 15.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.19\n",
      "Agent2 reward is 112.2\n",
      "US agents hit = 24.4\n",
      "THEM agents hit = 84.0\n",
      "Agent3 of Saxons aggressiveness is 0.06\n",
      "Agent3 reward is 29.9\n",
      "US agents hit = 3.9\n",
      "THEM agents hit = 13.5\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 23.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 38.5\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 23.5\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 35.9\n",
      "US agents hit = 2.7\n",
      "THEM agents hit = 15.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 22.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 64.1\n",
      "US agents hit = 9.4\n",
      "THEM agents hit = 26.1\n",
      "Training time per epochs: 2.91 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 368.9\n",
      "Av. agent reward = 40.99\n",
      "Num laser fired = 414.0\n",
      "Total US Hit (friendly fire) = 47.4\n",
      "Total THEM Hit = 169.2\n",
      "friendly fire (%) = 0.219\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 85.6\n",
      "Tribe Saxons has total reward of 97.4\n",
      "Tribe Franks has total reward of 185.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.03x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 12.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 19.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.07\n",
      "Agent2 reward is 53.5\n",
      "US agents hit = 9.6\n",
      "THEM agents hit = 48.9\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 39.3\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 8.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 26.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 32.1\n",
      "US agents hit = 4.9\n",
      "THEM agents hit = 17.5\n",
      "Agent6 of Franks aggressiveness is 0.07\n",
      "Agent6 reward is 49.2\n",
      "US agents hit = 6.1\n",
      "THEM agents hit = 39.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 23.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.22\n",
      "Agent8 reward is 113.6\n",
      "US agents hit = 25.4\n",
      "THEM agents hit = 54.9\n",
      "Training time per epochs: 2.94 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 376.6\n",
      "Av. agent reward = 41.84\n",
      "Num laser fired = 612.2\n",
      "Total US Hit (friendly fire) = 47.7\n",
      "Total THEM Hit = 167.2\n",
      "friendly fire (%) = 0.222\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 152.7\n",
      "Tribe Saxons has total reward of 88.0\n",
      "Tribe Franks has total reward of 135.9\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.36x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 8.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 20.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.22\n",
      "Agent2 reward is 123.5\n",
      "US agents hit = 25.5\n",
      "THEM agents hit = 82.5\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 37.2\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.9\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 16.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 34.4\n",
      "US agents hit = 2.6\n",
      "THEM agents hit = 15.0\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 46.2\n",
      "US agents hit = 3.4\n",
      "THEM agents hit = 29.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 24.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.33\n",
      "Agent8 reward is 65.0\n",
      "US agents hit = 15.6\n",
      "THEM agents hit = 38.2\n",
      "Training time per epochs: 2.95 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf0.1/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 363.3\n",
      "Av. agent reward = 40.36\n",
      "Num laser fired = 842.1\n",
      "Total US Hit (friendly fire) = 26.3\n",
      "Total THEM Hit = 172.2\n",
      "friendly fire (%) = 0.132\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 34.7\n",
      "Tribe Saxons has total reward of 138.6\n",
      "Tribe Franks has total reward of 190.0\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.19x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.4\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 23.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 10.7\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 2.4\n",
      "Agent3 of Saxons aggressiveness is 0.02\n",
      "Agent3 reward is 10.0\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 6.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.9\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.9\n",
      "Agent5 of Saxons aggressiveness is 0.13\n",
      "Agent5 reward is 120.7\n",
      "US agents hit = 9.0\n",
      "THEM agents hit = 38.9\n",
      "Agent6 of Franks aggressiveness is 0.66\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 110.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 94.5\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 1.4\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 95.4\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 8.9\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 377.1\n",
      "Av. agent reward = 41.90\n",
      "Num laser fired = 1056.3\n",
      "Total US Hit (friendly fire) = 26.5\n",
      "Total THEM Hit = 220.2\n",
      "friendly fire (%) = 0.108\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 25.5\n",
      "Tribe Saxons has total reward of 18.4\n",
      "Tribe Franks has total reward of 333.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 15.17x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 5.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 11.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 8.8\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 4.5\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 3.5\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.5\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 3.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 1.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 11.7\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 7.2\n",
      "Agent6 of Franks aggressiveness is 0.89\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 197.4\n",
      "Agent7 of Franks aggressiveness is 0.09\n",
      "Agent7 reward is 186.5\n",
      "US agents hit = 14.4\n",
      "THEM agents hit = 5.8\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 146.7\n",
      "US agents hit = 10.4\n",
      "THEM agents hit = 3.8\n",
      "Training time per epochs: 2.95 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 408.3\n",
      "Av. agent reward = 45.36\n",
      "Num laser fired = 1084.7\n",
      "Total US Hit (friendly fire) = 28.9\n",
      "Total THEM Hit = 227.5\n",
      "friendly fire (%) = 0.113\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 14.8\n",
      "Tribe Saxons has total reward of 20.6\n",
      "Tribe Franks has total reward of 372.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 21.07x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 4.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 8.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 2.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 4.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 8.4\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 2.9\n",
      "Agent6 of Franks aggressiveness is 0.92\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 207.7\n",
      "Agent7 of Franks aggressiveness is 0.11\n",
      "Agent7 reward is 207.6\n",
      "US agents hit = 14.3\n",
      "THEM agents hit = 5.6\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 165.3\n",
      "US agents hit = 13.6\n",
      "THEM agents hit = 10.5\n",
      "Training time per epochs: 2.93 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 406.1\n",
      "Av. agent reward = 45.13\n",
      "Num laser fired = 1118.5\n",
      "Total US Hit (friendly fire) = 29.1\n",
      "Total THEM Hit = 243.9\n",
      "friendly fire (%) = 0.106\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 1.7\n",
      "Tribe Saxons has total reward of 1.9\n",
      "Tribe Franks has total reward of 402.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 225.74x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 1.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.8\n",
      "Agent6 of Franks aggressiveness is 0.97\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 235.9\n",
      "Agent7 of Franks aggressiveness is 0.07\n",
      "Agent7 reward is 216.5\n",
      "US agents hit = 13.3\n",
      "THEM agents hit = 0.5\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 186.1\n",
      "US agents hit = 15.5\n",
      "THEM agents hit = 6.3\n",
      "Training time per epochs: 2.92 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 390.8\n",
      "Av. agent reward = 43.42\n",
      "Num laser fired = 802.8\n",
      "Total US Hit (friendly fire) = 43.2\n",
      "Total THEM Hit = 158.0\n",
      "friendly fire (%) = 0.215\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 66.5\n",
      "Tribe Saxons has total reward of 31.0\n",
      "Tribe Franks has total reward of 293.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 6.02x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 26.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 24.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 15.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 7.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.11\n",
      "Agent5 reward is 23.6\n",
      "US agents hit = 5.0\n",
      "THEM agents hit = 29.9\n",
      "Agent6 of Franks aggressiveness is 0.51\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 86.6\n",
      "Agent7 of Franks aggressiveness is 0.10\n",
      "Agent7 reward is 160.7\n",
      "US agents hit = 10.6\n",
      "THEM agents hit = 19.6\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 132.7\n",
      "US agents hit = 27.4\n",
      "THEM agents hit = 21.6\n",
      "Training time per epochs: 2.95 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf1.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 287.9\n",
      "Av. agent reward = 31.99\n",
      "Num laser fired = 425.3\n",
      "Total US Hit (friendly fire) = 39.7\n",
      "Total THEM Hit = 144.7\n",
      "friendly fire (%) = 0.215\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 50.6\n",
      "Tribe Saxons has total reward of 76.3\n",
      "Tribe Franks has total reward of 161.0\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.54x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.03\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 7.0\n",
      "Agent1 of Vikings aggressiveness is 0.06\n",
      "Agent1 reward is 46.2\n",
      "US agents hit = 5.3\n",
      "THEM agents hit = 36.7\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 4.4\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 3.8\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 2.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.7\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.8\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.7\n",
      "Agent5 of Saxons aggressiveness is 0.08\n",
      "Agent5 reward is 73.6\n",
      "US agents hit = 4.6\n",
      "THEM agents hit = 16.5\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 4.6\n",
      "US agents hit = 3.3\n",
      "THEM agents hit = 13.4\n",
      "Agent7 of Franks aggressiveness is 0.14\n",
      "Agent7 reward is 26.6\n",
      "US agents hit = 14.8\n",
      "THEM agents hit = 38.8\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 129.9\n",
      "US agents hit = 7.6\n",
      "THEM agents hit = 26.2\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 322.7\n",
      "Av. agent reward = 35.86\n",
      "Num laser fired = 352.4\n",
      "Total US Hit (friendly fire) = 34.3\n",
      "Total THEM Hit = 152.1\n",
      "friendly fire (%) = 0.184\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 104.7\n",
      "Tribe Saxons has total reward of 81.9\n",
      "Tribe Franks has total reward of 136.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.46x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent1 of Vikings aggressiveness is 0.09\n",
      "Agent1 reward is 58.2\n",
      "US agents hit = 10.7\n",
      "THEM agents hit = 42.6\n",
      "Agent2 of Vikings aggressiveness is 0.09\n",
      "Agent2 reward is 46.4\n",
      "US agents hit = 6.6\n",
      "THEM agents hit = 41.7\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 2.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.07\n",
      "Agent5 reward is 79.6\n",
      "US agents hit = 3.5\n",
      "THEM agents hit = 20.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 7.1\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.6\n",
      "Agent7 of Franks aggressiveness is 0.09\n",
      "Agent7 reward is 59.4\n",
      "US agents hit = 10.8\n",
      "THEM agents hit = 37.0\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 69.7\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 9.8\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 304.7\n",
      "Av. agent reward = 33.86\n",
      "Num laser fired = 396.1\n",
      "Total US Hit (friendly fire) = 30.7\n",
      "Total THEM Hit = 149.9\n",
      "friendly fire (%) = 0.170\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 158.1\n",
      "Tribe Saxons has total reward of 32.9\n",
      "Tribe Franks has total reward of 113.7\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 2.16x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.09\n",
      "Agent1 reward is 56.9\n",
      "US agents hit = 11.3\n",
      "THEM agents hit = 38.0\n",
      "Agent2 of Vikings aggressiveness is 0.14\n",
      "Agent2 reward is 101.1\n",
      "US agents hit = 10.3\n",
      "THEM agents hit = 69.9\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 5.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 27.1\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 3.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 10.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent7 of Franks aggressiveness is 0.03\n",
      "Agent7 reward is 21.0\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 7.1\n",
      "Agent8 of Franks aggressiveness is 0.13\n",
      "Agent8 reward is 82.4\n",
      "US agents hit = 6.7\n",
      "THEM agents hit = 31.7\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 316.3\n",
      "Av. agent reward = 35.15\n",
      "Num laser fired = 398.4\n",
      "Total US Hit (friendly fire) = 24.4\n",
      "Total THEM Hit = 134.0\n",
      "friendly fire (%) = 0.154\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 167.6\n",
      "Tribe Saxons has total reward of 27.6\n",
      "Tribe Franks has total reward of 121.2\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 2.25x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.06\n",
      "Agent1 reward is 58.8\n",
      "US agents hit = 8.5\n",
      "THEM agents hit = 32.1\n",
      "Agent2 of Vikings aggressiveness is 0.22\n",
      "Agent2 reward is 108.8\n",
      "US agents hit = 8.2\n",
      "THEM agents hit = 79.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 2.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.05\n",
      "Agent5 reward is 25.4\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 8.7\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 17.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 42.2\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 7.4\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 61.5\n",
      "US agents hit = 2.8\n",
      "THEM agents hit = 6.4\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 359.1\n",
      "Av. agent reward = 39.90\n",
      "Num laser fired = 354.0\n",
      "Total US Hit (friendly fire) = 26.4\n",
      "Total THEM Hit = 123.0\n",
      "friendly fire (%) = 0.177\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 136.9\n",
      "Tribe Saxons has total reward of 79.5\n",
      "Tribe Franks has total reward of 142.7\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.32x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.10\n",
      "Agent1 reward is 55.2\n",
      "US agents hit = 8.3\n",
      "THEM agents hit = 44.5\n",
      "Agent2 of Vikings aggressiveness is 0.11\n",
      "Agent2 reward is 81.7\n",
      "US agents hit = 8.2\n",
      "THEM agents hit = 37.7\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 3.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.08\n",
      "Agent5 reward is 75.7\n",
      "US agents hit = 2.8\n",
      "THEM agents hit = 25.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 28.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.06\n",
      "Agent7 reward is 52.7\n",
      "US agents hit = 5.1\n",
      "THEM agents hit = 10.3\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 61.9\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 5.3\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf5.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 353.5\n",
      "Av. agent reward = 39.27\n",
      "Num laser fired = 186.9\n",
      "Total US Hit (friendly fire) = 30.7\n",
      "Total THEM Hit = 124.1\n",
      "friendly fire (%) = 0.198\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 115.2\n",
      "Tribe Saxons has total reward of 131.5\n",
      "Tribe Franks has total reward of 106.7\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.19x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.10\n",
      "Agent0 reward is 109.7\n",
      "US agents hit = 12.4\n",
      "THEM agents hit = 69.6\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 3.2\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.0\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 2.2\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 2.2\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 42.1\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 2.5\n",
      "Agent4 of Saxons aggressiveness is 0.05\n",
      "Agent4 reward is 72.5\n",
      "US agents hit = 13.2\n",
      "THEM agents hit = 42.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 17.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 18.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 18.6\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 1.9\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 69.4\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 3.8\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 399.7\n",
      "Av. agent reward = 44.41\n",
      "Num laser fired = 205.1\n",
      "Total US Hit (friendly fire) = 33.3\n",
      "Total THEM Hit = 119.9\n",
      "friendly fire (%) = 0.217\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 108.1\n",
      "Tribe Saxons has total reward of 165.7\n",
      "Tribe Franks has total reward of 125.9\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.42x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.07\n",
      "Agent0 reward is 105.2\n",
      "US agents hit = 12.2\n",
      "THEM agents hit = 51.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 1.8\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 0.9\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 1.1\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 0.6\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 45.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.07\n",
      "Agent4 reward is 104.5\n",
      "US agents hit = 15.6\n",
      "THEM agents hit = 45.0\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 16.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 8.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 22.6\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.2\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 94.3\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 20.3\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 417.8\n",
      "Av. agent reward = 46.43\n",
      "Num laser fired = 187.8\n",
      "Total US Hit (friendly fire) = 24.1\n",
      "Total THEM Hit = 98.5\n",
      "friendly fire (%) = 0.197\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 75.1\n",
      "Tribe Saxons has total reward of 211.2\n",
      "Tribe Franks has total reward of 131.5\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 2.04x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 39.6\n",
      "US agents hit = 4.6\n",
      "THEM agents hit = 17.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 19.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.03\n",
      "Agent2 reward is 16.2\n",
      "US agents hit = 4.7\n",
      "THEM agents hit = 11.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 37.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent4 of Saxons aggressiveness is 0.07\n",
      "Agent4 reward is 165.0\n",
      "US agents hit = 11.6\n",
      "THEM agents hit = 40.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 8.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.5\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.9\n",
      "Agent8 of Franks aggressiveness is 0.05\n",
      "Agent8 reward is 131.0\n",
      "US agents hit = 3.0\n",
      "THEM agents hit = 28.0\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 442.0\n",
      "Av. agent reward = 49.11\n",
      "Num laser fired = 195.2\n",
      "Total US Hit (friendly fire) = 28.6\n",
      "Total THEM Hit = 96.0\n",
      "friendly fire (%) = 0.230\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 68.2\n",
      "Tribe Saxons has total reward of 207.1\n",
      "Tribe Franks has total reward of 166.6\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.76x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 27.5\n",
      "US agents hit = 3.3\n",
      "THEM agents hit = 11.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 25.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 15.5\n",
      "US agents hit = 2.8\n",
      "THEM agents hit = 5.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 45.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.09\n",
      "Agent4 reward is 157.2\n",
      "US agents hit = 14.0\n",
      "THEM agents hit = 38.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 4.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 23.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 142.8\n",
      "US agents hit = 8.5\n",
      "THEM agents hit = 41.6\n",
      "Training time per epochs: 3.09 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 468.8\n",
      "Av. agent reward = 52.09\n",
      "Num laser fired = 154.1\n",
      "Total US Hit (friendly fire) = 21.0\n",
      "Total THEM Hit = 71.6\n",
      "friendly fire (%) = 0.227\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 70.9\n",
      "Tribe Saxons has total reward of 225.7\n",
      "Tribe Franks has total reward of 172.2\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.86x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 31.6\n",
      "US agents hit = 6.0\n",
      "THEM agents hit = 15.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 30.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.03\n",
      "Agent2 reward is 8.7\n",
      "US agents hit = 2.7\n",
      "THEM agents hit = 6.7\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.06\n",
      "Agent4 reward is 222.4\n",
      "US agents hit = 8.3\n",
      "THEM agents hit = 32.7\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 3.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 16.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 155.6\n",
      "US agents hit = 4.1\n",
      "THEM agents hit = 16.4\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf10/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 333.9\n",
      "Av. agent reward = 37.10\n",
      "Num laser fired = 245.5\n",
      "Total US Hit (friendly fire) = 28.8\n",
      "Total THEM Hit = 130.7\n",
      "friendly fire (%) = 0.180\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 106.6\n",
      "Tribe Saxons has total reward of 144.5\n",
      "Tribe Franks has total reward of 82.8\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.53x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 1.7\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 2.4\n",
      "US agents hit = 7.1\n",
      "THEM agents hit = 10.7\n",
      "Agent2 of Vikings aggressiveness is 0.05\n",
      "Agent2 reward is 104.2\n",
      "US agents hit = 3.9\n",
      "THEM agents hit = 43.8\n",
      "Agent3 of Saxons aggressiveness is 0.09\n",
      "Agent3 reward is 143.0\n",
      "US agents hit = 5.4\n",
      "THEM agents hit = 39.6\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.1\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 2.8\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 1.5\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.9\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 2.0\n",
      "US agents hit = 2.4\n",
      "THEM agents hit = 8.3\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 2.4\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 21.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 78.4\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.6\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 453.5\n",
      "Av. agent reward = 50.39\n",
      "Num laser fired = 204.3\n",
      "Total US Hit (friendly fire) = 17.8\n",
      "Total THEM Hit = 113.6\n",
      "friendly fire (%) = 0.135\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 152.0\n",
      "Tribe Saxons has total reward of 224.7\n",
      "Tribe Franks has total reward of 76.9\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.96x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 2.7\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 2.2\n",
      "Agent2 of Vikings aggressiveness is 0.11\n",
      "Agent2 reward is 149.3\n",
      "US agents hit = 4.8\n",
      "THEM agents hit = 59.1\n",
      "Agent3 of Saxons aggressiveness is 0.05\n",
      "Agent3 reward is 223.8\n",
      "US agents hit = 4.5\n",
      "THEM agents hit = 27.8\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 1.8\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 1.2\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 11.4\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 0.7\n",
      "US agents hit = 3.8\n",
      "THEM agents hit = 10.7\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 75.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 394.8\n",
      "Av. agent reward = 43.87\n",
      "Num laser fired = 323.0\n",
      "Total US Hit (friendly fire) = 21.1\n",
      "Total THEM Hit = 116.0\n",
      "friendly fire (%) = 0.154\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 122.5\n",
      "Tribe Saxons has total reward of 149.8\n",
      "Tribe Franks has total reward of 122.6\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.22x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 8.3\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.2\n",
      "Agent2 of Vikings aggressiveness is 0.16\n",
      "Agent2 reward is 114.2\n",
      "US agents hit = 7.5\n",
      "THEM agents hit = 56.5\n",
      "Agent3 of Saxons aggressiveness is 0.05\n",
      "Agent3 reward is 149.6\n",
      "US agents hit = 5.4\n",
      "THEM agents hit = 23.4\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.2\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.3\n",
      "Agent6 of Franks aggressiveness is 0.03\n",
      "Agent6 reward is 1.7\n",
      "US agents hit = 2.6\n",
      "THEM agents hit = 9.6\n",
      "Agent7 of Franks aggressiveness is 0.02\n",
      "Agent7 reward is 0.8\n",
      "US agents hit = 3.1\n",
      "THEM agents hit = 11.1\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 120.1\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 13.8\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 378.3\n",
      "Av. agent reward = 42.04\n",
      "Num laser fired = 357.5\n",
      "Total US Hit (friendly fire) = 15.8\n",
      "Total THEM Hit = 126.4\n",
      "friendly fire (%) = 0.111\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 86.6\n",
      "Tribe Saxons has total reward of 115.9\n",
      "Tribe Franks has total reward of 175.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.74x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.06\n",
      "Agent2 reward is 86.2\n",
      "US agents hit = 9.4\n",
      "THEM agents hit = 60.9\n",
      "Agent3 of Saxons aggressiveness is 0.07\n",
      "Agent3 reward is 115.9\n",
      "US agents hit = 3.0\n",
      "THEM agents hit = 20.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.16\n",
      "Agent6 reward is 0.5\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 29.3\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.8\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 175.3\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 14.3\n",
      "Training time per epochs: 2.94 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 459.6\n",
      "Av. agent reward = 51.07\n",
      "Num laser fired = 988.8\n",
      "Total US Hit (friendly fire) = 0.1\n",
      "Total THEM Hit = 202.3\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 10.9\n",
      "Tribe Saxons has total reward of 18.9\n",
      "Tribe Franks has total reward of 429.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 28.85x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 10.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 6.7\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 18.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.96\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 193.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 429.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.6\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf15/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 313.9\n",
      "Av. agent reward = 34.88\n",
      "Num laser fired = 378.0\n",
      "Total US Hit (friendly fire) = 42.1\n",
      "Total THEM Hit = 124.8\n",
      "friendly fire (%) = 0.252\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 5.0\n",
      "Tribe Saxons has total reward of 82.8\n",
      "Tribe Franks has total reward of 226.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 5.15x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.3\n",
      "US agents hit = 8.3\n",
      "THEM agents hit = 19.5\n",
      "Agent1 of Vikings aggressiveness is 0.09\n",
      "Agent1 reward is 4.6\n",
      "US agents hit = 16.4\n",
      "THEM agents hit = 42.6\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 0.2\n",
      "US agents hit = 5.8\n",
      "THEM agents hit = 7.5\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.6\n",
      "Agent4 of Saxons aggressiveness is 0.03\n",
      "Agent4 reward is 82.8\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 8.9\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 2.3\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 9.3\n",
      "Agent7 of Franks aggressiveness is 0.14\n",
      "Agent7 reward is 223.0\n",
      "US agents hit = 6.7\n",
      "THEM agents hit = 32.4\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 0.7\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 3.8\n",
      "Training time per epochs: 3.04 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 325.9\n",
      "Av. agent reward = 36.21\n",
      "Num laser fired = 334.9\n",
      "Total US Hit (friendly fire) = 42.3\n",
      "Total THEM Hit = 159.4\n",
      "friendly fire (%) = 0.210\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 56.9\n",
      "Tribe Saxons has total reward of 83.3\n",
      "Tribe Franks has total reward of 185.7\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.65x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 1.9\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.6\n",
      "Agent1 of Vikings aggressiveness is 0.14\n",
      "Agent1 reward is 55.0\n",
      "US agents hit = 20.9\n",
      "THEM agents hit = 70.8\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 83.3\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 14.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 1.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent7 of Franks aggressiveness is 0.13\n",
      "Agent7 reward is 181.7\n",
      "US agents hit = 17.5\n",
      "THEM agents hit = 68.5\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 2.2\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 3.9\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 297.1\n",
      "Av. agent reward = 33.01\n",
      "Num laser fired = 385.5\n",
      "Total US Hit (friendly fire) = 44.6\n",
      "Total THEM Hit = 167.3\n",
      "friendly fire (%) = 0.210\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 94.1\n",
      "Tribe Saxons has total reward of 79.6\n",
      "Tribe Franks has total reward of 123.4\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.42x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 5.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.18\n",
      "Agent1 reward is 88.7\n",
      "US agents hit = 19.7\n",
      "THEM agents hit = 71.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.10\n",
      "Agent4 reward is 79.6\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 16.6\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.10\n",
      "Agent7 reward is 122.8\n",
      "US agents hit = 22.5\n",
      "THEM agents hit = 76.1\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 0.6\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 3.1\n",
      "Training time per epochs: 2.92 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 313.6\n",
      "Av. agent reward = 34.84\n",
      "Num laser fired = 329.7\n",
      "Total US Hit (friendly fire) = 41.7\n",
      "Total THEM Hit = 153.1\n",
      "friendly fire (%) = 0.214\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 118.5\n",
      "Tribe Saxons has total reward of 61.8\n",
      "Tribe Franks has total reward of 133.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.48x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 6.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.22\n",
      "Agent1 reward is 112.5\n",
      "US agents hit = 16.5\n",
      "THEM agents hit = 65.7\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 61.8\n",
      "US agents hit = 6.5\n",
      "THEM agents hit = 13.9\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.08\n",
      "Agent7 reward is 129.4\n",
      "US agents hit = 18.3\n",
      "THEM agents hit = 72.6\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 3.9\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.6\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 344.0\n",
      "Av. agent reward = 38.23\n",
      "Num laser fired = 322.8\n",
      "Total US Hit (friendly fire) = 43.9\n",
      "Total THEM Hit = 166.3\n",
      "friendly fire (%) = 0.209\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 85.1\n",
      "Tribe Saxons has total reward of 33.8\n",
      "Tribe Franks has total reward of 225.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.79x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 1.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.15\n",
      "Agent1 reward is 84.1\n",
      "US agents hit = 20.6\n",
      "THEM agents hit = 78.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 33.8\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 2.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.16\n",
      "Agent7 reward is 217.5\n",
      "US agents hit = 23.0\n",
      "THEM agents hit = 85.5\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 7.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 2.93 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf20/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 370.1\n",
      "Av. agent reward = 41.12\n",
      "Num laser fired = 1006.1\n",
      "Total US Hit (friendly fire) = 36.0\n",
      "Total THEM Hit = 224.9\n",
      "friendly fire (%) = 0.138\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 6.3\n",
      "Tribe Saxons has total reward of 22.8\n",
      "Tribe Franks has total reward of 340.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 23.41x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 0.4\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.2\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 5.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.9\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 0.3\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.9\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 21.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 1.5\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 0.9\n",
      "Agent7 of Franks aggressiveness is 0.96\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 34.0\n",
      "THEM agents hit = 219.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 339.4\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Training time per epochs: 2.92 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 271.6\n",
      "Av. agent reward = 30.18\n",
      "Num laser fired = 813.8\n",
      "Total US Hit (friendly fire) = 36.6\n",
      "Total THEM Hit = 154.3\n",
      "friendly fire (%) = 0.192\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 28.5\n",
      "Tribe Saxons has total reward of 132.5\n",
      "Tribe Franks has total reward of 110.6\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.91x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 0.3\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 3.2\n",
      "Agent1 of Vikings aggressiveness is 0.06\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 8.0\n",
      "THEM agents hit = 27.8\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 28.2\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 4.2\n",
      "Agent3 of Saxons aggressiveness is 0.31\n",
      "Agent3 reward is 0.3\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 32.0\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 10.0\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 1.7\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 122.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 1.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.6\n",
      "Agent7 of Franks aggressiveness is 0.42\n",
      "Agent7 reward is 0.1\n",
      "US agents hit = 25.0\n",
      "THEM agents hit = 84.6\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 109.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 393.9\n",
      "Av. agent reward = 43.76\n",
      "Num laser fired = 155.5\n",
      "Total US Hit (friendly fire) = 9.9\n",
      "Total THEM Hit = 78.3\n",
      "friendly fire (%) = 0.113\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 78.6\n",
      "Tribe Saxons has total reward of 188.0\n",
      "Tribe Franks has total reward of 127.2\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.83x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.7\n",
      "Agent2 of Vikings aggressiveness is 0.05\n",
      "Agent2 reward is 78.6\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 33.8\n",
      "Agent3 of Saxons aggressiveness is 0.07\n",
      "Agent3 reward is 5.5\n",
      "US agents hit = 3.1\n",
      "THEM agents hit = 17.2\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 22.5\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 160.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 3.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 1.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.8\n",
      "Agent7 of Franks aggressiveness is 0.03\n",
      "Agent7 reward is 0.1\n",
      "US agents hit = 5.1\n",
      "THEM agents hit = 21.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 126.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 467.2\n",
      "Av. agent reward = 51.91\n",
      "Num laser fired = 579.6\n",
      "Total US Hit (friendly fire) = 6.2\n",
      "Total THEM Hit = 83.5\n",
      "friendly fire (%) = 0.069\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 50.9\n",
      "Tribe Saxons has total reward of 248.4\n",
      "Tribe Franks has total reward of 167.8\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 2.27x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.8\n",
      "Agent2 of Vikings aggressiveness is 0.16\n",
      "Agent2 reward is 50.4\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 24.2\n",
      "Agent3 of Saxons aggressiveness is 0.41\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 3.0\n",
      "THEM agents hit = 54.2\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 31.3\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 3.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 217.1\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 1.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 167.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 585.4\n",
      "Av. agent reward = 65.05\n",
      "Num laser fired = 19.7\n",
      "Total US Hit (friendly fire) = 2.4\n",
      "Total THEM Hit = 11.4\n",
      "friendly fire (%) = 0.174\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 22.3\n",
      "Tribe Saxons has total reward of 426.5\n",
      "Tribe Franks has total reward of 136.6\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 5.37x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.8\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 21.6\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 4.5\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.4\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 6.8\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 419.6\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 4.9\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 136.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf25/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 250.2\n",
      "Av. agent reward = 27.80\n",
      "Num laser fired = 500.6\n",
      "Total US Hit (friendly fire) = 39.1\n",
      "Total THEM Hit = 126.6\n",
      "friendly fire (%) = 0.236\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 96.9\n",
      "Tribe Saxons has total reward of 44.0\n",
      "Tribe Franks has total reward of 109.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.55x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.31\n",
      "Agent0 reward is 80.4\n",
      "US agents hit = 21.3\n",
      "THEM agents hit = 60.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.5\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 16.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 6.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 43.9\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 6.1\n",
      "Agent6 of Franks aggressiveness is 0.07\n",
      "Agent6 reward is 0.4\n",
      "US agents hit = 8.1\n",
      "THEM agents hit = 24.6\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 4.7\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 108.9\n",
      "US agents hit = 5.5\n",
      "THEM agents hit = 22.5\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 400.4\n",
      "Av. agent reward = 44.49\n",
      "Num laser fired = 424.6\n",
      "Total US Hit (friendly fire) = 33.3\n",
      "Total THEM Hit = 137.6\n",
      "friendly fire (%) = 0.195\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 111.3\n",
      "Tribe Saxons has total reward of 37.0\n",
      "Tribe Franks has total reward of 252.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.40x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.11\n",
      "Agent0 reward is 92.0\n",
      "US agents hit = 17.0\n",
      "THEM agents hit = 53.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 19.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.02\n",
      "Agent3 reward is 0.1\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 7.6\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.3\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 0.6\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 29.5\n",
      "US agents hit = 4.3\n",
      "THEM agents hit = 12.4\n",
      "Agent6 of Franks aggressiveness is 0.10\n",
      "Agent6 reward is 1.0\n",
      "US agents hit = 5.6\n",
      "THEM agents hit = 18.2\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 2.2\n",
      "Agent8 of Franks aggressiveness is 0.16\n",
      "Agent8 reward is 251.1\n",
      "US agents hit = 4.2\n",
      "THEM agents hit = 43.3\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 475.8\n",
      "Av. agent reward = 52.87\n",
      "Num laser fired = 259.1\n",
      "Total US Hit (friendly fire) = 27.5\n",
      "Total THEM Hit = 125.2\n",
      "friendly fire (%) = 0.180\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 105.9\n",
      "Tribe Saxons has total reward of 60.0\n",
      "Tribe Franks has total reward of 309.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.74x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.08\n",
      "Agent0 reward is 91.3\n",
      "US agents hit = 17.8\n",
      "THEM agents hit = 62.3\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 14.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 4.5\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 3.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 16.8\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 38.7\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.1\n",
      "Agent6 of Franks aggressiveness is 0.06\n",
      "Agent6 reward is 0.3\n",
      "US agents hit = 5.7\n",
      "THEM agents hit = 21.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.10\n",
      "Agent8 reward is 309.6\n",
      "US agents hit = 2.7\n",
      "THEM agents hit = 36.6\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 526.8\n",
      "Av. agent reward = 58.54\n",
      "Num laser fired = 925.6\n",
      "Total US Hit (friendly fire) = 12.4\n",
      "Total THEM Hit = 195.6\n",
      "friendly fire (%) = 0.060\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 46.2\n",
      "Tribe Saxons has total reward of 23.5\n",
      "Tribe Franks has total reward of 457.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 13.12x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.07\n",
      "Agent0 reward is 43.2\n",
      "US agents hit = 5.8\n",
      "THEM agents hit = 27.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 3.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 15.0\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 2.2\n",
      "Agent6 of Franks aggressiveness is 0.82\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 5.8\n",
      "THEM agents hit = 157.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 457.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 7.9\n",
      "Training time per epochs: 2.94 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 495.5\n",
      "Av. agent reward = 55.05\n",
      "Num laser fired = 610.5\n",
      "Total US Hit (friendly fire) = 15.3\n",
      "Total THEM Hit = 172.0\n",
      "friendly fire (%) = 0.082\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 63.6\n",
      "Tribe Saxons has total reward of 53.7\n",
      "Tribe Franks has total reward of 378.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 6.44x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.05\n",
      "Agent0 reward is 60.7\n",
      "US agents hit = 12.1\n",
      "THEM agents hit = 42.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 2.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 4.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 1.1\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 21.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 28.0\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 6.3\n",
      "Agent6 of Franks aggressiveness is 0.51\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 103.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 378.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 18.1\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf50/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 402.0\n",
      "Av. agent reward = 44.66\n",
      "Num laser fired = 824.4\n",
      "Total US Hit (friendly fire) = 28.6\n",
      "Total THEM Hit = 197.3\n",
      "friendly fire (%) = 0.127\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 58.7\n",
      "Tribe Saxons has total reward of 60.4\n",
      "Tribe Franks has total reward of 282.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.75x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 58.7\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 3.8\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.5\n",
      "Agent3 of Saxons aggressiveness is 0.03\n",
      "Agent3 reward is 1.3\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 3.0\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 59.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 4.8\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 2.2\n",
      "US agents hit = 6.1\n",
      "THEM agents hit = 12.0\n",
      "Agent7 of Franks aggressiveness is 0.69\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 19.2\n",
      "THEM agents hit = 167.5\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 280.6\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 4.4\n",
      "Training time per epochs: 2.93 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 481.8\n",
      "Av. agent reward = 53.53\n",
      "Num laser fired = 1058.5\n",
      "Total US Hit (friendly fire) = 29.8\n",
      "Total THEM Hit = 213.9\n",
      "friendly fire (%) = 0.122\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 16.0\n",
      "Tribe Saxons has total reward of 10.2\n",
      "Tribe Franks has total reward of 455.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 34.78x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 16.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.9\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 0.7\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 0.7\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 9.4\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 1.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 0.5\n",
      "Agent7 of Franks aggressiveness is 0.95\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 27.5\n",
      "THEM agents hit = 208.6\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 455.4\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.8\n",
      "Training time per epochs: 2.93 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 469.7\n",
      "Av. agent reward = 52.19\n",
      "Num laser fired = 1069.9\n",
      "Total US Hit (friendly fire) = 42.4\n",
      "Total THEM Hit = 175.1\n",
      "friendly fire (%) = 0.195\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 103.2\n",
      "Tribe Saxons has total reward of 21.2\n",
      "Tribe Franks has total reward of 345.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 5.55x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 103.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 2.3\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.9\n",
      "Agent3 of Saxons aggressiveness is 0.06\n",
      "Agent3 reward is 1.5\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 2.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 19.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.5\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.7\n",
      "Agent7 of Franks aggressiveness is 0.96\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 40.7\n",
      "THEM agents hit = 165.4\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 344.8\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 3.1\n",
      "Training time per epochs: 2.94 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 389.6\n",
      "Av. agent reward = 43.29\n",
      "Num laser fired = 1010.7\n",
      "Total US Hit (friendly fire) = 1.1\n",
      "Total THEM Hit = 231.7\n",
      "friendly fire (%) = 0.005\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 368.5\n",
      "Tribe Saxons has total reward of 12.4\n",
      "Tribe Franks has total reward of 8.7\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 34.99x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 368.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.9\n",
      "Agent2 of Vikings aggressiveness is 0.97\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 225.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 12.4\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 5.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 8.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 2.90 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 488.4\n",
      "Av. agent reward = 54.27\n",
      "Num laser fired = 1012.6\n",
      "Total US Hit (friendly fire) = 1.6\n",
      "Total THEM Hit = 209.2\n",
      "friendly fire (%) = 0.008\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 438.1\n",
      "Tribe Saxons has total reward of 44.9\n",
      "Tribe Franks has total reward of 5.4\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 17.42x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 438.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.1\n",
      "Agent2 of Vikings aggressiveness is 0.97\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 200.8\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 44.9\n",
      "US agents hit = 1.4\n",
      "THEM agents hit = 7.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 5.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 2.91 sec\n",
      "[38.148148148148145, 38.94814814814815, 39.51111111111111, 40.992592592592594, 41.84074074074074]\n",
      "[40.36296296296296, 41.903703703703705, 45.36296296296296, 45.12592592592593, 43.422222222222224]\n",
      "[31.992592592592594, 35.85925925925926, 33.855555555555554, 35.148148148148145, 39.903703703703705]\n",
      "[39.27407407407407, 44.40740740740741, 46.425925925925924, 49.10740740740741, 52.09259259259259]\n",
      "[37.096296296296295, 50.39259259259259, 43.87037037037037, 42.03703703703704, 51.07037037037037]\n",
      "[34.88148148148148, 36.21111111111111, 33.01111111111111, 34.84444444444445, 38.22592592592593]\n",
      "[41.11851851851852, 30.17777777777778, 43.762962962962966, 51.90740740740741, 65.04814814814814]\n",
      "[27.799999999999997, 44.48888888888889, 52.87037037037037, 58.53703703703704, 55.05185185185185]\n",
      "[44.66296296296296, 53.529629629629625, 52.18518518518519, 43.28888888888889, 54.266666666666666]\n",
      "['Vikings', 'Vikings', 'Vikings', 'Franks', 'Vikings']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Vikings', 'Vikings', 'Franks']\n",
      "['Saxons', 'Saxons', 'Saxons', 'Saxons', 'Saxons']\n",
      "['Saxons', 'Saxons', 'Saxons', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Saxons', 'Saxons', 'Saxons', 'Saxons']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Vikings', 'Vikings']\n",
      "[2.519526106117939, 1.5012485425413484, 1.3140726927094686, 2.030589947796623, 1.364204883189119]\n",
      "[2.193151210612274, 15.168436987818023, 21.065913305539077, 225.7383107949869, 6.0191518399920625]\n",
      "[2.537956393912462, 1.45971055836751, 2.155944531231049, 2.2527447888339553, 1.319162044924024]\n",
      "[1.1853409426386867, 1.416441087808198, 2.0442006764404157, 1.7640880048514564, 1.8560657976524992]\n",
      "[1.5261397632395244, 1.9632974065716744, 1.222690789819769, 1.7360105323026938, 28.847874613872488]\n",
      "[5.145675259112014, 2.6479676708489914, 1.4208405287490358, 1.479289939925729, 3.7853138978442993]\n",
      "[23.40503423657139, 1.9051042400462868, 1.827044533436559, 2.2715635465565134, 5.365485423001447]\n",
      "[1.5506149467556694, 3.402293678608597, 3.7352350316741108, 13.124401893152855, 6.443055943975554]\n",
      "[4.748181305073028, 34.77608127892996, 5.55495978060821, 34.98734158946484, 17.41948306329737]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\"MA_models/3T-9L/cooperative/cf0.01/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf0.1/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf1.0/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf5.0/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf10/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf15/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf20/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf25/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf50/\"]\n",
    "\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"cooperative\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominating_tribe = [[None for i in episodes] for j in dir_names]\n",
    "dom_tribe_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominance = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 9 agents - 3 teams of 3 AI agents each and 0 random agent\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather_ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        # tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        total_rewards = cum_rewards/max_episodes\n",
    "        print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print ('Av. agent reward = {:.2f}'.format(av_agent_reward[dir_num][eps_num]))\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "       \n",
    "        for i, tribe in enumerate(tribes):\n",
    "            if tribe.name is not 'Crazies':\n",
    "                tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                # Keep track of dominating team and the rewards gathered\n",
    "                if tribe_reward > dom_tribe_reward[dir_num][eps_num]:   \n",
    "                    dom_tribe_reward[dir_num][eps_num] = tribe_reward\n",
    "                    dominating_tribe[dir_num][eps_num]  = tribe.name\n",
    "\n",
    "        # Team dominance calculation                           \n",
    "        print ('Dominating Tribe: {}'.format(dominating_tribe[dir_num][eps_num]))\n",
    "        dominance[dir_num][eps_num] = dom_tribe_reward[dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "        print ('Team dominance: {0:.2f}x'.format(dominance[dir_num][eps_num]))\n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "    \n",
    "for tribe in dominating_tribe:   # Dominating team\n",
    "    print(tribe)\n",
    "\n",
    "for value in dominance:      # Team dominance\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L/cooperative/cf30/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 374.0\n",
      "Av. agent reward = 41.56\n",
      "Num laser fired = 194.1\n",
      "Total US Hit (friendly fire) = 28.0\n",
      "Total THEM Hit = 117.7\n",
      "friendly fire (%) = 0.192\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 183.2\n",
      "Tribe Saxons has total reward of 106.5\n",
      "Tribe Franks has total reward of 84.3\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.92x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.10\n",
      "Agent0 reward is 174.8\n",
      "US agents hit = 12.1\n",
      "THEM agents hit = 63.5\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 8.4\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 33.7\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.7\n",
      "Agent4 of Saxons aggressiveness is 0.05\n",
      "Agent4 reward is 70.7\n",
      "US agents hit = 9.5\n",
      "THEM agents hit = 28.3\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 2.1\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 2.0\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 1.4\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 12.5\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 18.1\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 4.7\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 64.7\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 4.2\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 357.3\n",
      "Av. agent reward = 39.70\n",
      "Num laser fired = 670.9\n",
      "Total US Hit (friendly fire) = 44.6\n",
      "Total THEM Hit = 173.7\n",
      "friendly fire (%) = 0.204\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.0\n",
      "Tribe Saxons has total reward of 102.3\n",
      "Tribe Franks has total reward of 71.0\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 2.12x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.13\n",
      "Agent0 reward is 178.0\n",
      "US agents hit = 15.2\n",
      "THEM agents hit = 41.8\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 6.1\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 0.5\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 83.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent4 of Saxons aggressiveness is 0.44\n",
      "Agent4 reward is 11.3\n",
      "US agents hit = 14.6\n",
      "THEM agents hit = 69.5\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 7.7\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 2.5\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.4\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 14.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.3\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 55.9\n",
      "US agents hit = 12.6\n",
      "THEM agents hit = 58.3\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 377.3\n",
      "Av. agent reward = 41.92\n",
      "Num laser fired = 325.9\n",
      "Total US Hit (friendly fire) = 51.7\n",
      "Total THEM Hit = 163.1\n",
      "friendly fire (%) = 0.241\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 133.8\n",
      "Tribe Saxons has total reward of 91.9\n",
      "Tribe Franks has total reward of 151.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.34x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.12\n",
      "Agent0 reward is 124.4\n",
      "US agents hit = 21.5\n",
      "THEM agents hit = 68.9\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 9.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 25.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.05\n",
      "Agent4 reward is 49.5\n",
      "US agents hit = 9.1\n",
      "THEM agents hit = 26.1\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 17.2\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 2.2\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 16.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent8 of Franks aggressiveness is 0.13\n",
      "Agent8 reward is 135.2\n",
      "US agents hit = 20.2\n",
      "THEM agents hit = 65.4\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 314.2\n",
      "Av. agent reward = 34.91\n",
      "Num laser fired = 892.0\n",
      "Total US Hit (friendly fire) = 38.4\n",
      "Total THEM Hit = 163.4\n",
      "friendly fire (%) = 0.190\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 196.6\n",
      "Tribe Saxons has total reward of 60.3\n",
      "Tribe Franks has total reward of 57.3\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 3.34x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.20\n",
      "Agent0 reward is 170.2\n",
      "US agents hit = 18.8\n",
      "THEM agents hit = 36.6\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 26.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 39.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.62\n",
      "Agent4 reward is 21.4\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 92.7\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 33.5\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 2.4\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 23.8\n",
      "US agents hit = 12.8\n",
      "THEM agents hit = 31.7\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 398.3\n",
      "Av. agent reward = 44.25\n",
      "Num laser fired = 293.9\n",
      "Total US Hit (friendly fire) = 40.7\n",
      "Total THEM Hit = 225.4\n",
      "friendly fire (%) = 0.153\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 64.7\n",
      "Tribe Saxons has total reward of 71.4\n",
      "Tribe Franks has total reward of 262.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.85x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 44.4\n",
      "US agents hit = 2.6\n",
      "THEM agents hit = 8.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 20.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 66.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.08\n",
      "Agent4 reward is 4.4\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 69.7\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.5\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 1.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.10\n",
      "Agent7 reward is 242.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 39.9\n",
      "Agent8 of Franks aggressiveness is 0.09\n",
      "Agent8 reward is 20.1\n",
      "US agents hit = 34.8\n",
      "THEM agents hit = 106.7\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf40/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 277.1\n",
      "Av. agent reward = 30.79\n",
      "Num laser fired = 312.0\n",
      "Total US Hit (friendly fire) = 34.0\n",
      "Total THEM Hit = 115.2\n",
      "friendly fire (%) = 0.228\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 45.0\n",
      "Tribe Saxons has total reward of 118.2\n",
      "Tribe Franks has total reward of 114.0\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.49x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 42.3\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 3.1\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 0.3\n",
      "US agents hit = 3.9\n",
      "THEM agents hit = 9.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 2.4\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.9\n",
      "Agent3 of Saxons aggressiveness is 0.18\n",
      "Agent3 reward is 106.6\n",
      "US agents hit = 11.1\n",
      "THEM agents hit = 42.3\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 7.1\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 11.6\n",
      "US agents hit = 7.3\n",
      "THEM agents hit = 22.0\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 0.5\n",
      "US agents hit = 3.3\n",
      "THEM agents hit = 11.6\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.9\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 8.3\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 112.5\n",
      "US agents hit = 3.1\n",
      "THEM agents hit = 9.8\n",
      "Training time per epochs: 3.08 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 375.8\n",
      "Av. agent reward = 41.75\n",
      "Num laser fired = 847.4\n",
      "Total US Hit (friendly fire) = 18.7\n",
      "Total THEM Hit = 163.9\n",
      "friendly fire (%) = 0.103\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 28.5\n",
      "Tribe Saxons has total reward of 103.0\n",
      "Tribe Franks has total reward of 244.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.72x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 28.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.10\n",
      "Agent3 reward is 76.4\n",
      "US agents hit = 5.3\n",
      "THEM agents hit = 14.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 2.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 24.1\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 2.5\n",
      "Agent6 of Franks aggressiveness is 0.67\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 4.5\n",
      "THEM agents hit = 134.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 1.0\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 244.3\n",
      "US agents hit = 7.2\n",
      "THEM agents hit = 11.2\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 481.9\n",
      "Av. agent reward = 53.54\n",
      "Num laser fired = 1066.0\n",
      "Total US Hit (friendly fire) = 10.1\n",
      "Total THEM Hit = 220.4\n",
      "friendly fire (%) = 0.044\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 5.6\n",
      "Tribe Saxons has total reward of 49.5\n",
      "Tribe Franks has total reward of 426.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 15.50x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 5.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 3.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.4\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 46.1\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 4.9\n",
      "Agent6 of Franks aggressiveness is 0.96\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 5.7\n",
      "THEM agents hit = 207.9\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 7.5\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 419.3\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 7.2\n",
      "Training time per epochs: 3.06 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 462.5\n",
      "Av. agent reward = 51.39\n",
      "Num laser fired = 1069.4\n",
      "Total US Hit (friendly fire) = 2.9\n",
      "Total THEM Hit = 227.1\n",
      "friendly fire (%) = 0.013\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 3.3\n",
      "Tribe Saxons has total reward of 22.9\n",
      "Tribe Franks has total reward of 436.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 33.31x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 3.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 3.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 19.6\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 5.9\n",
      "Agent6 of Franks aggressiveness is 0.95\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 1.0\n",
      "THEM agents hit = 217.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 436.3\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 4.1\n",
      "Training time per epochs: 3.05 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 575.9\n",
      "Av. agent reward = 63.99\n",
      "Num laser fired = 1012.1\n",
      "Total US Hit (friendly fire) = 1.3\n",
      "Total THEM Hit = 219.2\n",
      "friendly fire (%) = 0.006\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.6\n",
      "Tribe Saxons has total reward of 12.0\n",
      "Tribe Franks has total reward of 563.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 89.42x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 11.6\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.8\n",
      "Agent6 of Franks aggressiveness is 0.98\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 214.9\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 563.3\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 2.4\n",
      "Training time per epochs: 2.93 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf50/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 393.6\n",
      "Av. agent reward = 43.74\n",
      "Num laser fired = 815.1\n",
      "Total US Hit (friendly fire) = 26.9\n",
      "Total THEM Hit = 194.4\n",
      "friendly fire (%) = 0.121\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 58.1\n",
      "Tribe Saxons has total reward of 62.1\n",
      "Tribe Franks has total reward of 273.4\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.55x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 58.1\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 4.4\n",
      "Agent2 of Vikings aggressiveness is 0.01\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 1.2\n",
      "Agent3 of Saxons aggressiveness is 0.03\n",
      "Agent3 reward is 1.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 3.5\n",
      "Agent4 of Saxons aggressiveness is 0.01\n",
      "Agent4 reward is 61.2\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 5.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 2.5\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 13.8\n",
      "Agent7 of Franks aggressiveness is 0.67\n",
      "Agent7 reward is 0.4\n",
      "US agents hit = 17.1\n",
      "THEM agents hit = 161.3\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 270.6\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 4.5\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 478.9\n",
      "Av. agent reward = 53.21\n",
      "Num laser fired = 1060.8\n",
      "Total US Hit (friendly fire) = 30.1\n",
      "Total THEM Hit = 214.5\n",
      "friendly fire (%) = 0.123\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 19.8\n",
      "Tribe Saxons has total reward of 7.5\n",
      "Tribe Franks has total reward of 451.6\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 33.12x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 19.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 0.4\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.5\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 7.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.9\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.7\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 0.3\n",
      "Agent7 of Franks aggressiveness is 0.96\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 28.3\n",
      "THEM agents hit = 209.9\n",
      "Agent8 of Franks aggressiveness is 0.08\n",
      "Agent8 reward is 450.9\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 1.5\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 476.2\n",
      "Av. agent reward = 52.91\n",
      "Num laser fired = 1083.5\n",
      "Total US Hit (friendly fire) = 42.5\n",
      "Total THEM Hit = 168.4\n",
      "friendly fire (%) = 0.202\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 115.3\n",
      "Tribe Saxons has total reward of 25.7\n",
      "Tribe Franks has total reward of 335.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 4.76x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 115.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 3.1\n",
      "Agent2 of Vikings aggressiveness is 0.02\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 1.1\n",
      "Agent3 of Saxons aggressiveness is 0.07\n",
      "Agent3 reward is 0.9\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 2.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 24.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.4\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.1\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 0.8\n",
      "Agent7 of Franks aggressiveness is 0.95\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 40.7\n",
      "THEM agents hit = 157.1\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 335.2\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 3.7\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 387.9\n",
      "Av. agent reward = 43.10\n",
      "Num laser fired = 1003.2\n",
      "Total US Hit (friendly fire) = 1.4\n",
      "Total THEM Hit = 227.9\n",
      "friendly fire (%) = 0.006\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 370.6\n",
      "Tribe Saxons has total reward of 8.5\n",
      "Tribe Franks has total reward of 8.8\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 42.93x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 370.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.0\n",
      "Agent2 of Vikings aggressiveness is 0.96\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 220.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 8.5\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 6.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 8.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 2.95 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 489.3\n",
      "Av. agent reward = 54.37\n",
      "Num laser fired = 1010.0\n",
      "Total US Hit (friendly fire) = 1.2\n",
      "Total THEM Hit = 200.1\n",
      "friendly fire (%) = 0.006\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 451.9\n",
      "Tribe Saxons has total reward of 34.6\n",
      "Tribe Franks has total reward of 2.8\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 24.14x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 451.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.0\n",
      "Agent2 of Vikings aggressiveness is 0.97\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 192.9\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.03\n",
      "Agent4 reward is 34.6\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 6.2\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 2.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.04 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf60/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 181.8\n",
      "Av. agent reward = 20.20\n",
      "Num laser fired = 993.9\n",
      "Total US Hit (friendly fire) = 2.1\n",
      "Total THEM Hit = 212.1\n",
      "friendly fire (%) = 0.010\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 110.4\n",
      "Tribe Saxons has total reward of 16.6\n",
      "Tribe Franks has total reward of 54.7\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 3.10x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 110.4\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.97\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 205.6\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 1.2\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 16.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.5\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.6\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 2.6\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 54.1\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.9\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 176.7\n",
      "Av. agent reward = 19.63\n",
      "Num laser fired = 1012.7\n",
      "Total US Hit (friendly fire) = 0.8\n",
      "Total THEM Hit = 229.4\n",
      "friendly fire (%) = 0.003\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 145.6\n",
      "Tribe Saxons has total reward of 5.0\n",
      "Tribe Franks has total reward of 26.1\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 9.36x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 145.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.98\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 226.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.2\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.9\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 4.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.4\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 26.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 1.5\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 207.6\n",
      "Av. agent reward = 23.07\n",
      "Num laser fired = 997.3\n",
      "Total US Hit (friendly fire) = 0.6\n",
      "Total THEM Hit = 232.8\n",
      "friendly fire (%) = 0.003\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 178.9\n",
      "Tribe Saxons has total reward of 8.3\n",
      "Tribe Franks has total reward of 20.5\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 12.45x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 178.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.98\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 230.8\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.3\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 8.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 20.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 1.4\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 170.6\n",
      "Av. agent reward = 18.96\n",
      "Num laser fired = 929.4\n",
      "Total US Hit (friendly fire) = 7.3\n",
      "Total THEM Hit = 166.0\n",
      "friendly fire (%) = 0.042\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 111.0\n",
      "Tribe Saxons has total reward of 43.3\n",
      "Tribe Franks has total reward of 16.4\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 3.72x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.09\n",
      "Agent0 reward is 111.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 4.7\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.83\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 4.4\n",
      "THEM agents hit = 158.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.9\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 43.3\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 1.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 0.7\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 16.4\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Training time per epochs: 3.20 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 226.4\n",
      "Av. agent reward = 25.15\n",
      "Num laser fired = 840.4\n",
      "Total US Hit (friendly fire) = 2.4\n",
      "Total THEM Hit = 216.1\n",
      "friendly fire (%) = 0.011\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 175.1\n",
      "Tribe Saxons has total reward of 48.9\n",
      "Tribe Franks has total reward of 2.3\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 6.83x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 175.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.84\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 215.8\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 48.9\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.3\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 2.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.03 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf70/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 358.3\n",
      "Av. agent reward = 39.81\n",
      "Num laser fired = 279.2\n",
      "Total US Hit (friendly fire) = 23.0\n",
      "Total THEM Hit = 86.7\n",
      "friendly fire (%) = 0.209\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 62.1\n",
      "Tribe Saxons has total reward of 113.8\n",
      "Tribe Franks has total reward of 182.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 2.07x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 5.8\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 0.8\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 20.9\n",
      "US agents hit = 3.3\n",
      "THEM agents hit = 10.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 35.4\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 4.7\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 8.1\n",
      "US agents hit = 2.4\n",
      "THEM agents hit = 4.9\n",
      "Agent5 of Saxons aggressiveness is 0.17\n",
      "Agent5 reward is 105.7\n",
      "US agents hit = 11.4\n",
      "THEM agents hit = 38.4\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 1.6\n",
      "THEM agents hit = 5.7\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 1.6\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 3.4\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 180.7\n",
      "US agents hit = 1.8\n",
      "THEM agents hit = 18.1\n",
      "Training time per epochs: 3.07 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 425.7\n",
      "Av. agent reward = 47.30\n",
      "Num laser fired = 1014.8\n",
      "Total US Hit (friendly fire) = 6.0\n",
      "Total THEM Hit = 186.7\n",
      "friendly fire (%) = 0.031\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 21.9\n",
      "Tribe Saxons has total reward of 95.6\n",
      "Tribe Franks has total reward of 308.2\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 5.25x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 1.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.01\n",
      "Agent1 reward is 13.7\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 3.3\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 6.9\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 4.8\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.2\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 90.8\n",
      "US agents hit = 1.9\n",
      "THEM agents hit = 8.3\n",
      "Agent6 of Franks aggressiveness is 0.92\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 170.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 308.2\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 3.7\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 323.2\n",
      "Av. agent reward = 35.91\n",
      "Num laser fired = 1004.4\n",
      "Total US Hit (friendly fire) = 0.8\n",
      "Total THEM Hit = 235.6\n",
      "friendly fire (%) = 0.003\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 8.0\n",
      "Tribe Saxons has total reward of 3.2\n",
      "Tribe Franks has total reward of 312.0\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 55.54x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 2.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 5.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 3.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent6 of Franks aggressiveness is 0.99\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 234.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.01\n",
      "Agent8 reward is 312.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.1\n",
      "Training time per epochs: 2.93 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 538.2\n",
      "Av. agent reward = 59.80\n",
      "Num laser fired = 1067.4\n",
      "Total US Hit (friendly fire) = 0.4\n",
      "Total THEM Hit = 241.0\n",
      "friendly fire (%) = 0.002\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.3\n",
      "Tribe Saxons has total reward of 2.0\n",
      "Tribe Franks has total reward of 535.9\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 466.00x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.2\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 2.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent6 of Franks aggressiveness is 1.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 238.7\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 535.9\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 2.1\n",
      "Training time per epochs: 2.92 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 516.6\n",
      "Av. agent reward = 57.40\n",
      "Num laser fired = 999.4\n",
      "Total US Hit (friendly fire) = 0.1\n",
      "Total THEM Hit = 235.6\n",
      "friendly fire (%) = 0.000\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 6.3\n",
      "Tribe Saxons has total reward of 0.0\n",
      "Tribe Franks has total reward of 510.3\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 162.86x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 6.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.00\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 1.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 235.5\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 510.3\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 2.93 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf80/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 334.3\n",
      "Av. agent reward = 37.14\n",
      "Num laser fired = 604.9\n",
      "Total US Hit (friendly fire) = 34.5\n",
      "Total THEM Hit = 125.1\n",
      "friendly fire (%) = 0.216\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 36.4\n",
      "Tribe Saxons has total reward of 207.9\n",
      "Tribe Franks has total reward of 90.0\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 3.29x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 0.5\n",
      "US agents hit = 3.9\n",
      "THEM agents hit = 8.2\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 34.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 1.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent3 of Saxons aggressiveness is 0.10\n",
      "Agent3 reward is 1.4\n",
      "US agents hit = 5.2\n",
      "THEM agents hit = 10.1\n",
      "Agent4 of Saxons aggressiveness is 0.15\n",
      "Agent4 reward is 206.5\n",
      "US agents hit = 7.2\n",
      "THEM agents hit = 42.0\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 2.3\n",
      "Agent6 of Franks aggressiveness is 0.32\n",
      "Agent6 reward is 1.2\n",
      "US agents hit = 16.2\n",
      "THEM agents hit = 59.6\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.5\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 2.3\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 88.2\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.5\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 329.2\n",
      "Av. agent reward = 36.58\n",
      "Num laser fired = 926.5\n",
      "Total US Hit (friendly fire) = 20.3\n",
      "Total THEM Hit = 112.3\n",
      "friendly fire (%) = 0.153\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 184.4\n",
      "Tribe Saxons has total reward of 66.1\n",
      "Tribe Franks has total reward of 78.7\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 2.55x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 0.1\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 3.1\n",
      "Agent1 of Vikings aggressiveness is 0.22\n",
      "Agent1 reward is 182.7\n",
      "US agents hit = 4.8\n",
      "THEM agents hit = 46.5\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 1.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.24\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 6.1\n",
      "Agent4 of Saxons aggressiveness is 0.03\n",
      "Agent4 reward is 66.1\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 9.2\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 7.2\n",
      "Agent6 of Franks aggressiveness is 0.42\n",
      "Agent6 reward is 1.0\n",
      "US agents hit = 7.3\n",
      "THEM agents hit = 36.9\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 1.4\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 3.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 76.3\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.2\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 339.4\n",
      "Av. agent reward = 37.71\n",
      "Num laser fired = 353.8\n",
      "Total US Hit (friendly fire) = 16.6\n",
      "Total THEM Hit = 128.9\n",
      "friendly fire (%) = 0.114\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 173.7\n",
      "Tribe Saxons has total reward of 79.0\n",
      "Tribe Franks has total reward of 86.7\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 2.10x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.15\n",
      "Agent1 reward is 173.7\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 36.9\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 79.0\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 10.8\n",
      "Agent5 of Saxons aggressiveness is 0.01\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 2.9\n",
      "THEM agents hit = 13.5\n",
      "Agent6 of Franks aggressiveness is 0.15\n",
      "Agent6 reward is 0.3\n",
      "US agents hit = 12.9\n",
      "THEM agents hit = 67.2\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.8\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.4\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 85.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 440.2\n",
      "Av. agent reward = 48.91\n",
      "Num laser fired = 753.9\n",
      "Total US Hit (friendly fire) = 4.0\n",
      "Total THEM Hit = 118.0\n",
      "friendly fire (%) = 0.033\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 220.0\n",
      "Tribe Saxons has total reward of 133.3\n",
      "Tribe Franks has total reward of 86.8\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 2.00x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.13\n",
      "Agent1 reward is 220.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 25.7\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.06\n",
      "Agent4 reward is 133.3\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 10.9\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.9\n",
      "Agent6 of Franks aggressiveness is 0.57\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 3.0\n",
      "THEM agents hit = 79.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.7\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.3\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 86.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 3.00 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 514.6\n",
      "Av. agent reward = 57.18\n",
      "Num laser fired = 1043.2\n",
      "Total US Hit (friendly fire) = 6.5\n",
      "Total THEM Hit = 207.9\n",
      "friendly fire (%) = 0.030\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 123.4\n",
      "Tribe Saxons has total reward of 164.2\n",
      "Tribe Franks has total reward of 227.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.58x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 123.4\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 8.6\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.05\n",
      "Agent4 reward is 164.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 11.5\n",
      "Agent5 of Saxons aggressiveness is 0.12\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 22.2\n",
      "Agent6 of Franks aggressiveness is 0.84\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 165.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.00\n",
      "Agent8 reward is 227.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf90/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 339.5\n",
      "Av. agent reward = 37.72\n",
      "Num laser fired = 245.6\n",
      "Total US Hit (friendly fire) = 31.0\n",
      "Total THEM Hit = 115.5\n",
      "friendly fire (%) = 0.212\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 44.7\n",
      "Tribe Saxons has total reward of 165.3\n",
      "Tribe Franks has total reward of 129.5\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.90x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.4\n",
      "US agents hit = 1.5\n",
      "THEM agents hit = 1.1\n",
      "Agent2 of Vikings aggressiveness is 0.12\n",
      "Agent2 reward is 44.3\n",
      "US agents hit = 10.1\n",
      "THEM agents hit = 42.1\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 3.2\n",
      "Agent4 of Saxons aggressiveness is 0.06\n",
      "Agent4 reward is 127.5\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 25.1\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 37.8\n",
      "US agents hit = 0.5\n",
      "THEM agents hit = 1.1\n",
      "Agent6 of Franks aggressiveness is 0.02\n",
      "Agent6 reward is 2.0\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 18.6\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 9.1\n",
      "US agents hit = 1.7\n",
      "THEM agents hit = 5.6\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 118.4\n",
      "US agents hit = 9.0\n",
      "THEM agents hit = 18.6\n",
      "Training time per epochs: 3.02 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 364.5\n",
      "Av. agent reward = 40.50\n",
      "Num laser fired = 326.2\n",
      "Total US Hit (friendly fire) = 24.7\n",
      "Total THEM Hit = 126.0\n",
      "friendly fire (%) = 0.164\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 94.3\n",
      "Tribe Saxons has total reward of 178.0\n",
      "Tribe Franks has total reward of 92.1\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.91x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.1\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 0.9\n",
      "Agent2 of Vikings aggressiveness is 0.16\n",
      "Agent2 reward is 94.2\n",
      "US agents hit = 10.4\n",
      "THEM agents hit = 57.6\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.5\n",
      "Agent4 of Saxons aggressiveness is 0.11\n",
      "Agent4 reward is 128.2\n",
      "US agents hit = 6.2\n",
      "THEM agents hit = 42.0\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 49.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 3.0\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 0.8\n",
      "US agents hit = 0.9\n",
      "THEM agents hit = 3.1\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 91.3\n",
      "US agents hit = 6.3\n",
      "THEM agents hit = 18.8\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 378.0\n",
      "Av. agent reward = 42.00\n",
      "Num laser fired = 318.2\n",
      "Total US Hit (friendly fire) = 11.8\n",
      "Total THEM Hit = 117.7\n",
      "friendly fire (%) = 0.091\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 139.7\n",
      "Tribe Saxons has total reward of 143.7\n",
      "Tribe Franks has total reward of 94.6\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 1.23x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent2 of Vikings aggressiveness is 0.18\n",
      "Agent2 reward is 139.7\n",
      "US agents hit = 3.4\n",
      "THEM agents hit = 67.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.07\n",
      "Agent4 reward is 88.7\n",
      "US agents hit = 2.9\n",
      "THEM agents hit = 25.4\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 55.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 1.9\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 2.5\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.3\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 92.0\n",
      "US agents hit = 5.0\n",
      "THEM agents hit = 21.7\n",
      "Training time per epochs: 2.99 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 337.7\n",
      "Av. agent reward = 37.52\n",
      "Num laser fired = 265.4\n",
      "Total US Hit (friendly fire) = 8.7\n",
      "Total THEM Hit = 111.9\n",
      "friendly fire (%) = 0.072\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 132.5\n",
      "Tribe Saxons has total reward of 125.4\n",
      "Tribe Franks has total reward of 79.8\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.29x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.08\n",
      "Agent2 reward is 132.5\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 71.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.10\n",
      "Agent4 reward is 97.5\n",
      "US agents hit = 3.4\n",
      "THEM agents hit = 25.6\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 27.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.5\n",
      "Agent7 of Franks aggressiveness is 0.01\n",
      "Agent7 reward is 2.9\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 1.1\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 77.0\n",
      "US agents hit = 3.7\n",
      "THEM agents hit = 13.3\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 383.0\n",
      "Av. agent reward = 42.56\n",
      "Num laser fired = 251.2\n",
      "Total US Hit (friendly fire) = 4.0\n",
      "Total THEM Hit = 92.3\n",
      "friendly fire (%) = 0.042\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 171.9\n",
      "Tribe Saxons has total reward of 93.9\n",
      "Tribe Franks has total reward of 117.2\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.63x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.00\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent2 of Vikings aggressiveness is 0.09\n",
      "Agent2 reward is 171.9\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 69.4\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent4 of Saxons aggressiveness is 0.08\n",
      "Agent4 reward is 92.1\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 16.5\n",
      "Agent5 of Saxons aggressiveness is 0.00\n",
      "Agent5 reward is 1.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 20.0\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.0\n",
      "Agent8 of Franks aggressiveness is 0.07\n",
      "Agent8 reward is 97.1\n",
      "US agents hit = 3.2\n",
      "THEM agents hit = 5.4\n",
      "Training time per epochs: 3.01 sec\n",
      "###### Dir = MA_models/3T-9L/cooperative/cf100/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 373.8\n",
      "Av. agent reward = 41.53\n",
      "Num laser fired = 261.9\n",
      "Total US Hit (friendly fire) = 25.4\n",
      "Total THEM Hit = 92.7\n",
      "friendly fire (%) = 0.215\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 116.7\n",
      "Tribe Saxons has total reward of 101.5\n",
      "Tribe Franks has total reward of 155.5\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 1.43x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.02\n",
      "Agent0 reward is 3.5\n",
      "US agents hit = 2.1\n",
      "THEM agents hit = 4.5\n",
      "Agent1 of Vikings aggressiveness is 0.07\n",
      "Agent1 reward is 106.7\n",
      "US agents hit = 9.3\n",
      "THEM agents hit = 37.2\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 6.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.2\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 0.2\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.03\n",
      "Agent4 reward is 1.1\n",
      "US agents hit = 3.4\n",
      "THEM agents hit = 9.7\n",
      "Agent5 of Saxons aggressiveness is 0.02\n",
      "Agent5 reward is 100.2\n",
      "US agents hit = 1.2\n",
      "THEM agents hit = 8.0\n",
      "Agent6 of Franks aggressiveness is 0.01\n",
      "Agent6 reward is 1.6\n",
      "US agents hit = 2.2\n",
      "THEM agents hit = 5.6\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 1.9\n",
      "US agents hit = 0.4\n",
      "THEM agents hit = 1.0\n",
      "Agent8 of Franks aggressiveness is 0.10\n",
      "Agent8 reward is 152.0\n",
      "US agents hit = 6.6\n",
      "THEM agents hit = 26.3\n",
      "Training time per epochs: 3.10 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 330.6\n",
      "Av. agent reward = 36.73\n",
      "Num laser fired = 324.1\n",
      "Total US Hit (friendly fire) = 22.4\n",
      "Total THEM Hit = 105.7\n",
      "friendly fire (%) = 0.175\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 136.1\n",
      "Tribe Saxons has total reward of 76.5\n",
      "Tribe Franks has total reward of 117.9\n",
      "Dominating Tribe: Vikings\n",
      "Team dominance: 1.40x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.01\n",
      "Agent0 reward is 4.6\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.6\n",
      "Agent1 of Vikings aggressiveness is 0.13\n",
      "Agent1 reward is 127.9\n",
      "US agents hit = 6.4\n",
      "THEM agents hit = 33.0\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 3.6\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.01\n",
      "Agent3 reward is 2.4\n",
      "US agents hit = 1.3\n",
      "THEM agents hit = 3.5\n",
      "Agent4 of Saxons aggressiveness is 0.02\n",
      "Agent4 reward is 0.2\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 10.0\n",
      "Agent5 of Saxons aggressiveness is 0.10\n",
      "Agent5 reward is 73.9\n",
      "US agents hit = 9.8\n",
      "THEM agents hit = 38.9\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 2.1\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.1\n",
      "US agents hit = 0.2\n",
      "THEM agents hit = 0.4\n",
      "Agent8 of Franks aggressiveness is 0.06\n",
      "Agent8 reward is 115.8\n",
      "US agents hit = 2.0\n",
      "THEM agents hit = 19.1\n",
      "Training time per epochs: 2.97 sec\n",
      "###### Trained episodes = 3000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 393.3\n",
      "Av. agent reward = 43.70\n",
      "Num laser fired = 1116.1\n",
      "Total US Hit (friendly fire) = 33.2\n",
      "Total THEM Hit = 145.1\n",
      "friendly fire (%) = 0.186\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 16.3\n",
      "Tribe Saxons has total reward of 202.1\n",
      "Tribe Franks has total reward of 174.9\n",
      "Dominating Tribe: Saxons\n",
      "Team dominance: 2.11x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.5\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.1\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 15.8\n",
      "US agents hit = 0.6\n",
      "THEM agents hit = 4.1\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.06\n",
      "Agent3 reward is 0.7\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 4.3\n",
      "Agent4 of Saxons aggressiveness is 0.90\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 28.2\n",
      "THEM agents hit = 109.8\n",
      "Agent5 of Saxons aggressiveness is 0.10\n",
      "Agent5 reward is 201.4\n",
      "US agents hit = 0.8\n",
      "THEM agents hit = 17.1\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 1.3\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 0.4\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 173.6\n",
      "US agents hit = 2.3\n",
      "THEM agents hit = 9.2\n",
      "Training time per epochs: 2.96 sec\n",
      "###### Trained episodes = 4000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 413.9\n",
      "Av. agent reward = 45.99\n",
      "Num laser fired = 1188.2\n",
      "Total US Hit (friendly fire) = 28.6\n",
      "Total THEM Hit = 117.1\n",
      "friendly fire (%) = 0.196\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 28.3\n",
      "Tribe Saxons has total reward of 61.8\n",
      "Tribe Franks has total reward of 323.8\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 7.18x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.9\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 0.4\n",
      "Agent1 of Vikings aggressiveness is 0.02\n",
      "Agent1 reward is 27.5\n",
      "US agents hit = 0.3\n",
      "THEM agents hit = 3.7\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.26\n",
      "Agent3 reward is 0.2\n",
      "US agents hit = 1.1\n",
      "THEM agents hit = 2.6\n",
      "Agent4 of Saxons aggressiveness is 0.82\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 26.4\n",
      "THEM agents hit = 98.5\n",
      "Agent5 of Saxons aggressiveness is 0.06\n",
      "Agent5 reward is 61.7\n",
      "US agents hit = 0.7\n",
      "THEM agents hit = 7.5\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.00\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent8 of Franks aggressiveness is 0.03\n",
      "Agent8 reward is 323.8\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 4.3\n",
      "Training time per epochs: 2.98 sec\n",
      "###### Trained episodes = 5000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 420.7\n",
      "Av. agent reward = 46.74\n",
      "Num laser fired = 1510.3\n",
      "Total US Hit (friendly fire) = 8.4\n",
      "Total THEM Hit = 62.9\n",
      "friendly fire (%) = 0.118\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 111.2\n",
      "Tribe Saxons has total reward of 50.4\n",
      "Tribe Franks has total reward of 259.1\n",
      "Dominating Tribe: Franks\n",
      "Team dominance: 3.21x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.00\n",
      "Agent0 reward is 0.5\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent1 of Vikings aggressiveness is 0.06\n",
      "Agent1 reward is 110.7\n",
      "US agents hit = 0.1\n",
      "THEM agents hit = 11.7\n",
      "Agent2 of Vikings aggressiveness is 0.00\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent3 of Saxons aggressiveness is 0.00\n",
      "Agent3 reward is 1.7\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent4 of Saxons aggressiveness is 0.48\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 5.6\n",
      "THEM agents hit = 33.4\n",
      "Agent5 of Saxons aggressiveness is 0.03\n",
      "Agent5 reward is 48.8\n",
      "US agents hit = 2.6\n",
      "THEM agents hit = 9.0\n",
      "Agent6 of Franks aggressiveness is 0.00\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.0\n",
      "Agent7 of Franks aggressiveness is 0.92\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 0.1\n",
      "Agent8 of Franks aggressiveness is 0.02\n",
      "Agent8 reward is 259.1\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 8.6\n",
      "Training time per epochs: 3.13 sec\n",
      "[41.559259259259264, 39.7, 41.922222222222224, 34.91111111111111, 44.25185185185185]\n",
      "[30.79259259259259, 41.75185185185185, 53.544444444444444, 51.39259259259259, 63.99259259259259]\n",
      "[43.737037037037034, 53.20740740740741, 52.91481481481482, 43.099999999999994, 54.36666666666667]\n",
      "[20.196296296296296, 19.62962962962963, 23.066666666666666, 18.95925925925926, 25.151851851851852]\n",
      "[39.8074074074074, 47.3, 35.91111111111111, 59.800000000000004, 57.3962962962963]\n",
      "[37.14074074074074, 36.58148148148148, 37.71111111111111, 48.90740740740741, 57.181481481481484]\n",
      "[37.718518518518515, 40.49629629629629, 42.00370370370371, 37.51851851851852, 42.55555555555556]\n",
      "[41.529629629629625, 36.733333333333334, 43.7, 45.992592592592594, 46.74074074074074]\n",
      "['Vikings', 'Vikings', 'Franks', 'Vikings', 'Franks']\n",
      "['Saxons', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Vikings', 'Vikings']\n",
      "['Vikings', 'Vikings', 'Vikings', 'Vikings', 'Vikings']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Saxons', 'Vikings', 'Vikings', 'Vikings', 'Franks']\n",
      "['Saxons', 'Saxons', 'Saxons', 'Vikings', 'Vikings']\n",
      "['Franks', 'Vikings', 'Saxons', 'Franks', 'Franks']\n",
      "[1.9206848346718617, 2.124278567331643, 1.3433761623935694, 3.342023232919049, 3.84969399933807]\n",
      "[1.4874161063530886, 3.716531437052599, 15.502421276538747, 33.307887900870135, 89.41798863735683]\n",
      "[4.547823672024446, 33.12469424289551, 4.755082738607146, 42.930501657006495, 24.142475441077316]\n",
      "[3.096261677468381, 9.36120039561419, 12.450115961617893, 3.719553065768422, 6.8309492701286505]\n",
      "[2.0719833288809353, 5.2480136159709305, 55.543026162338236, 465.99997771303066, 162.86169926891588]\n",
      "[3.2918205776087057, 2.5474217291881924, 2.0957361208938194, 1.9990914587224404, 1.5796429393446767]\n",
      "[1.898181816982967, 1.9091884150339078, 1.2269170573269557, 1.29109811496741, 1.6286120313635846]\n",
      "[1.425385672108787, 1.4000685628007836, 2.11401673518545, 7.181515702883916, 3.2062706248802195]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\n",
    "             \"MA_models/3T-9L/cooperative/cf30/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf40/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf50/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf60/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf70/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf80/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf90/\",\n",
    "             \"MA_models/3T-9L/cooperative/cf100/\"\n",
    "            ]\n",
    "\n",
    "episodes = [1000,2000,3000,4000,5000]  \n",
    "culture = \"cooperative\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominating_tribe = [[None for i in episodes] for j in dir_names]\n",
    "dom_tribe_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominance = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 9 agents - 3 teams of 3 AI agents each and 0 random agent\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather_ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        # tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        total_rewards = cum_rewards/max_episodes\n",
    "        print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print ('Av. agent reward = {:.2f}'.format(av_agent_reward[dir_num][eps_num]))\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "       \n",
    "        for i, tribe in enumerate(tribes):\n",
    "            if tribe.name is not 'Crazies':\n",
    "                tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                # Keep track of dominating team and the rewards gathered\n",
    "                if tribe_reward > dom_tribe_reward[dir_num][eps_num]:   \n",
    "                    dom_tribe_reward[dir_num][eps_num] = tribe_reward\n",
    "                    dominating_tribe[dir_num][eps_num]  = tribe.name\n",
    "\n",
    "        # Team dominance calculation                           \n",
    "        print ('Dominating Tribe: {}'.format(dominating_tribe[dir_num][eps_num]))\n",
    "        dominance[dir_num][eps_num] = dom_tribe_reward[dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "        print ('Team dominance: {0:.2f}x'.format(dominance[dir_num][eps_num]))\n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "    \n",
    "for tribe in dominating_tribe:   # Dominating team\n",
    "    print(tribe)\n",
    "\n",
    "for value in dominance:      # Team dominance\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Stats - Warlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Dir = MA_models/3T-9L/warlike/p-1.0_r0.5/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 0.0\n",
      "Av. agent reward = 0.00\n",
      "Num laser fired = 350.8\n",
      "Total US Hit (friendly fire) = 272.7\n",
      "Total THEM Hit = 1753.8\n",
      "friendly fire (%) = 0.135\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.0\n",
      "Tribe Saxons has total reward of 0.0\n",
      "Tribe Franks has total reward of 0.0\n",
      "Dominating Tribe: None\n",
      "Team dominance: 0.00x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 234.0\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 233.8\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 117.0\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 234.0\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 38.9\n",
      "THEM agents hit = 233.6\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 0.0\n",
      "US agents hit = 77.8\n",
      "THEM agents hit = 233.4\n",
      "Training time per epochs: 2.86 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 0.0\n",
      "Av. agent reward = 0.00\n",
      "Num laser fired = 351.0\n",
      "Total US Hit (friendly fire) = 273.0\n",
      "Total THEM Hit = 1754.8\n",
      "friendly fire (%) = 0.135\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.0\n",
      "Tribe Saxons has total reward of 0.0\n",
      "Tribe Franks has total reward of 0.0\n",
      "Dominating Tribe: None\n",
      "Team dominance: 0.00x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 234.0\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 233.8\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 117.0\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 234.0\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 234.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Training time per epochs: 2.86 sec\n",
      "###### Dir = MA_models/3T-9L/warlike/p-1.0_r1.0/ #######\n",
      "###### Trained episodes = 1000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 0.0\n",
      "Av. agent reward = 0.00\n",
      "Num laser fired = 350.9\n",
      "Total US Hit (friendly fire) = 272.5\n",
      "Total THEM Hit = 1753.3\n",
      "friendly fire (%) = 0.135\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.0\n",
      "Tribe Saxons has total reward of 0.0\n",
      "Tribe Franks has total reward of 0.0\n",
      "Dominating Tribe: None\n",
      "Team dominance: 0.00x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 77.6\n",
      "THEM agents hit = 232.8\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 234.0\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 233.8\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 116.9\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 234.0\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 233.8\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Training time per epochs: 2.89 sec\n",
      "###### Trained episodes = 2000 #######\n",
      "Load saved model for agent 0\n",
      "Load saved model for agent 1\n",
      "Load saved model for agent 2\n",
      "Load saved model for agent 3\n",
      "Load saved model for agent 4\n",
      "Load saved model for agent 5\n",
      "Load saved model for agent 6\n",
      "Load saved model for agent 7\n",
      "Load saved model for agent 8\n",
      "..............................\n",
      "Average Statistics in Aggregate\n",
      "=================================\n",
      "Total rewards gathered = 0.0\n",
      "Av. agent reward = 0.00\n",
      "Num laser fired = 351.0\n",
      "Total US Hit (friendly fire) = 273.0\n",
      "Total THEM Hit = 1755.0\n",
      "friendly fire (%) = 0.135\n",
      "\n",
      "Average Statistics by Tribe\n",
      "=============================\n",
      "Tribe Vikings has total reward of 0.0\n",
      "Tribe Saxons has total reward of 0.0\n",
      "Tribe Franks has total reward of 0.0\n",
      "Dominating Tribe: None\n",
      "Team dominance: 0.00x\n",
      "\n",
      "Average Statistics by Agent\n",
      "=============================\n",
      "Agent0 of Vikings aggressiveness is 0.04\n",
      "Agent0 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Agent1 of Vikings aggressiveness is 0.04\n",
      "Agent1 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 234.0\n",
      "Agent2 of Vikings aggressiveness is 0.04\n",
      "Agent2 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 234.0\n",
      "Agent3 of Saxons aggressiveness is 0.04\n",
      "Agent3 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent4 of Saxons aggressiveness is 0.04\n",
      "Agent4 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 117.0\n",
      "Agent5 of Saxons aggressiveness is 0.04\n",
      "Agent5 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 117.0\n",
      "Agent6 of Franks aggressiveness is 0.04\n",
      "Agent6 reward is 0.0\n",
      "US agents hit = 0.0\n",
      "THEM agents hit = 234.0\n",
      "Agent7 of Franks aggressiveness is 0.04\n",
      "Agent7 reward is 0.0\n",
      "US agents hit = 39.0\n",
      "THEM agents hit = 234.0\n",
      "Agent8 of Franks aggressiveness is 0.04\n",
      "Agent8 reward is 0.0\n",
      "US agents hit = 78.0\n",
      "THEM agents hit = 234.0\n",
      "Training time per epochs: 2.90 sec\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n",
      "[None, None]\n",
      "[None, None]\n",
      "[0.0, 0.0]\n",
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dir_names = [\n",
    "             #\"MA_models/3T-9L/warlike/p-1.0_r0.001/\",\n",
    "             #\"MA_models/3T-9L/warlike/p-1.0_r0.005/\",  \n",
    "             #\"MA_models/3T-9L/warlike/p-1.0_r0.01/\",   \n",
    "             #\"MA_models/3T-9L/warlike/p-1.0_r0.05/\",   \n",
    "             #\"MA_models/3T-9L/warlike/p-1.0_r0.1/\",\n",
    "             \"MA_models/3T-9L/warlike/p-1.0_r0.5/\",\n",
    "             \"MA_models/3T-9L/warlike/p-1.0_r1.0/\"]\n",
    "\n",
    "episodes = [1000,2000\n",
    "            #,3000,4000,5000\n",
    "           ]  \n",
    "culture = \"warlike\"\n",
    "\n",
    "# Performance Statistics - for Research Report\n",
    "av_agent_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominating_tribe = [[None for i in episodes] for j in dir_names]\n",
    "dom_tribe_reward = [[0 for i in episodes] for j in dir_names]\n",
    "dominance = [[0 for i in episodes] for j in dir_names]\n",
    "\n",
    "# There will be 9 agents - 3 teams of 3 AI agents each and 0 random agent\n",
    "num_ai_agents = 9\n",
    "num_rdn_agents = 0\n",
    "num_agents = num_ai_agents+num_rdn_agents  # just the sum of the two\n",
    "\n",
    "# Data structure for AI agents (agents will form their own Class later on)\n",
    "agents = []\n",
    "actions = []\n",
    "tags = []\n",
    "\n",
    "# Initialize environment\n",
    "render = False\n",
    "num_actions = 8                       # There are 8 actions defined in Gathering\n",
    "\n",
    "# Initialize constants\n",
    "num_frames = 4\n",
    "max_episodes = 30\n",
    "max_frames = 1000\n",
    "verbose = False\n",
    "\n",
    "def unpack_env_obs(env_obs):\n",
    "    \"\"\"\n",
    "    Gathering is a partially-observable Markov Game. env_obs returned by GatheringEnv is a numpy \n",
    "    array of dimension (num_agent, 800), which represents the agents' observations of the game.\n",
    "\n",
    "    The 800 elements (view_box) encodes 4 layers of 10x20 pixels frames in the format:\n",
    "    (viewbox_width, viewbox_depth, 4).\n",
    "    \n",
    "    This code reshapes the above into stacked frames that can be accepted by the Policy class:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    num_agents = len(env_obs)  # environ observations is a list of agents' observations\n",
    "    \n",
    "    obs = []\n",
    "    for i in range(num_agents):\n",
    "        x = env_obs[i]   # take the indexed agent's observation\n",
    "        x = torch.Tensor(x)   # Convert to tensor\n",
    "        \n",
    "        # Policy is a 3-layer CNN\n",
    "        x = x.view(1, 10, 20, -1)  # reshape into environment defined stacked frames\n",
    "        x = x.permute(0, 3, 1, 2)  # permute to Policy accepted stacked frames\n",
    "        obs.append(x)\n",
    "        \n",
    "    return obs  # return a list of Policy accepted stacked frames (tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "For now, we do not implement LSTM            \n",
    "# LSTM Change: Need to cycle hx and cx thru function\n",
    "def select_action(model, state, lstm_hc, cuda):\n",
    "    hx , cx = lstm_hc \n",
    "    num_frames, height, width = state.shape\n",
    "    state = torch.FloatTensor(state.reshape(-1, num_frames, height, width))\n",
    "\n",
    "    if cuda:\n",
    "        state = state.cuda()\n",
    "\n",
    "    probs, value, (hx, cx) = model((Variable(state), (hx, cx)))\n",
    "\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "    # LSTM Change: Need to cycle hx and cx thru function\n",
    "    return action.data[0], log_prob, value, (hx, cx)\n",
    "\"\"\"\n",
    "\n",
    "def select_action(model, obs, cuda):\n",
    "    \"\"\"\n",
    "    This code expects obs to be an array of stacked frames of the following dim:\n",
    "    (batch_idx, in_channel, width, height)\n",
    "    \n",
    "    This is inputted into model - the agent's Policy, which outputs a probability \n",
    "    distribution over available actions.\n",
    "    \n",
    "    Policy gradient is implemented using torch.distributions.Categorical. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Policy is a 3-layer CNN\n",
    "    # _, num_frames, width, height = obs.shape\n",
    "    # obs = torch.FloatTensor(obs.reshape(-1, num_frames, width, height))\n",
    "    \n",
    "    # Policy is a 2-layer NN for now\n",
    "    # obs = obs.view(1, -1)\n",
    "   \n",
    "    if cuda:\n",
    "        obs = obs.cuda()\n",
    "      \n",
    "    probs = model(obs)\n",
    "    m = torch.distributions.Categorical(probs)\n",
    "    action = m.sample()\n",
    "    log_prob = m.log_prob(action)\n",
    "\n",
    "    return action.item(), log_prob \n",
    "\n",
    "\n",
    "def load_info(agents, narrate=False):\n",
    "    for i in range(num_agents):    \n",
    "        agents[i].load_info(info[i])\n",
    "        if narrate:\n",
    "            if agents[i].tagged:\n",
    "                print('frame {}, agent{} is tagged'.format(frame,i))\n",
    "            if agents[i].laser_fired:\n",
    "                print('frame {}, agent{} fires its laser'.format(frame,i))\n",
    "                print('and hit {} US and {} THEM'.format(agents[i].US_hit, agents[i].THEM_hit))\n",
    "    return\n",
    "\n",
    "for dir_num, dir_name in enumerate(dir_names):\n",
    "    print (\"###### Dir = {} #######\".format(dir_name))\n",
    "    \n",
    "    for eps_num, eps in enumerate(episodes):\n",
    "        print (\"###### Trained episodes = {} #######\".format(eps))\n",
    "    \n",
    "        # Load models for AI agents\n",
    "        agents= [[] for i in range(num_ai_agents)]\n",
    "        # If episodes is provided (not 0), load the model for each AI agent\n",
    "        for i in range(num_ai_agents):\n",
    "            model_file = dir_name+'MA{}_Gather_ep{}.p'.format(i,eps)\n",
    "            try:\n",
    "                with open(model_file, 'rb') as f:\n",
    "                    # Model File include both model and optim parameters\n",
    "                    saved_model = pickle.load(f)\n",
    "                    agents[i], _ = saved_model\n",
    "                    print(\"Load saved model for agent {}\".format(i))\n",
    "            except OSError:\n",
    "                print('Model file not found.')\n",
    "                raise\n",
    "\n",
    "        # Load random agents    \n",
    "        for i in range(num_ai_agents,num_agents):\n",
    "            print(\"Load random agent {}\".format(i))\n",
    "            agents.append(Rdn_Policy())\n",
    "        \n",
    "        # Establish tribal association\n",
    "        tribes = []\n",
    "        tribes.append(Tribe(name='Vikings',color='blue', culture=culture, \\\n",
    "                    agents=[agents[0], agents[1], agents[2]]))\n",
    "        tribes.append(Tribe(name='Saxons', color='red', culture=culture, \\\n",
    "                    agents=[agents[3], agents[4], agents[5]]))\n",
    "        tribes.append(Tribe(name='Franks', color='purple', culture=culture, \\\n",
    "                    agents=[agents[6], agents[7], agents[8]]))\n",
    "        # tribes.append(Tribe(name='Crazies', color='yellow', agents=[agents[9]]))   # random agents are crazy!!!\n",
    "\n",
    "\n",
    "        # 9 agents in 4 tribes, used map defined in default.txt\n",
    "        agent_colors = [agent.color for agent in agents]\n",
    "        agent_tribes = [agent.tribe for agent in agents]\n",
    "\n",
    "        env = GatheringEnv(n_agents=num_agents,agent_colors=agent_colors, agent_tribes=agent_tribes, \\\n",
    "                       map_name='default')    \n",
    "\n",
    "        # Used to accumulate episode stats for averaging\n",
    "        cum_rewards = 0\n",
    "        cum_tags = 0\n",
    "        cum_US_hits = 0\n",
    "        cum_THEM_hits = 0\n",
    "        cum_agent_rewards = [0 for agent in agents]\n",
    "        cum_agent_tags = [0 for agent in agents]\n",
    "        cum_agent_US_hits = [0 for agent in agents]\n",
    "        cum_agent_THEM_hits = [0 for agent in agents]\n",
    "        cum_tribe_rewards = [0 for t in tribes if t.name is not 'Crazies']\n",
    "\n",
    "        cuda = False\n",
    "        start = time.time()\n",
    "\n",
    "        for ep in range(max_episodes):\n",
    "    \n",
    "            print('.', end='')  # To show progress\n",
    "    \n",
    "            # Initialize AI and random agent data\n",
    "            actions = [0 for i in range(num_agents)]\n",
    "            tags = [0 for i in range(num_agents)]\n",
    "            US_hits = [0 for i in range(num_agents)]\n",
    "            THEM_hits = [0 for i in range(num_agents)]\n",
    "\n",
    "            env_obs = env.reset()  # Environment return observations\n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            # Unpack observations into data structure compatible with agent Policy\n",
    "            agents_obs = unpack_env_obs(env_obs)\n",
    "    \n",
    "            for i in range(num_ai_agents):    # Reset agent info - laser tag statistics\n",
    "                agents[i].reset_info()    \n",
    "    \n",
    "            if render:\n",
    "                env.render()\n",
    "                time.sleep(1/15)  # Change speed of video rendering\n",
    "    \n",
    "            \"\"\"\n",
    "            # For Debug only\n",
    "            print (len(agents_obs))\n",
    "            print (agents_obs[0].shape)\n",
    "            \"\"\"\n",
    "    \n",
    "            \"\"\"\n",
    "            For now, we do not stack observations, and we do not implement LSTM\n",
    "    \n",
    "            state = np.stack([state]*num_frames)\n",
    "\n",
    "            # Reset LSTM hidden units when episode begins\n",
    "            cx = Variable(torch.zeros(1, 256))\n",
    "            hx = Variable(torch.zeros(1, 256))\n",
    "            \"\"\"\n",
    "\n",
    "            for frame in range(max_frames):\n",
    "\n",
    "                for i in range(num_ai_agents):    # For AI agents\n",
    "                    actions[i], _ = select_action(agents[i], agents_obs[i], cuda=cuda)\n",
    "                    if actions[i] is 6:  # action[i] is a tensor, .item() returns the integer\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "                \n",
    "                for i in range(num_ai_agents, num_agents):   # For random agents\n",
    "                    actions[i] = agents[i].select_action(agents_obs[i])\n",
    "                    if actions[i] is 6:\n",
    "                        tags[i] += 1   # record a tag for accessing aggressiveness\n",
    "        \n",
    "                \"\"\"\n",
    "                For now, we do not implement LSTM\n",
    "                # Select action\n",
    "                action, log_prob, state_value, (hx,cx)  = select_action(model, state, (hx,cx))        \n",
    "                \"\"\"\n",
    "\n",
    "                # if frame % 10 == 0:\n",
    "                #     print (actions)    \n",
    "            \n",
    "                # Perform step        \n",
    "                env_obs, reward, done, info = env.step(actions)\n",
    "        \n",
    "                \"\"\"\n",
    "                For Debug only\n",
    "                print (env_obs)\n",
    "                print (reward)\n",
    "                print (done) \n",
    "                \"\"\"\n",
    "\n",
    "                for i in range(num_ai_agents):\n",
    "                    agents[i].rewards.append(reward[i])  # Stack rewards\n",
    "\n",
    "        \n",
    "                # Unpack observations into data structure compatible with agent Policy\n",
    "                agents_obs = unpack_env_obs(env_obs)\n",
    "                load_info(agents, narrate=False)   # Load agent info for AI agents\n",
    "        \n",
    "                for i in range(num_agents):\n",
    "                    US_hits[i] += agents[i].US_hit\n",
    "                    THEM_hits[i] += agents[i].THEM_hit\n",
    "            \n",
    "                \"\"\"\n",
    "                For now, we do not stack observation, may come in handy later on\n",
    "        \n",
    "                # Evict oldest diff add new diff to state\n",
    "                next_state = np.stack([next_state]*num_frames)\n",
    "                next_state[1:, :, :] = state[:-1, :, :]\n",
    "                state = next_state\n",
    "                \"\"\"\n",
    "        \n",
    "                if render:\n",
    "                    env.render()\n",
    "                    time.sleep(1/15)  # Change speed of video rendering\n",
    "\n",
    "                if any(done):\n",
    "                    print(\"Done after {} frames\".format(frame))\n",
    "                    break\n",
    "            \n",
    "            # Print out statistics of AI agents\n",
    "            ep_rewards = 0\n",
    "            ep_tags = 0\n",
    "            ep_US_hits = 0\n",
    "            ep_THEM_hits = 0\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Agent')\n",
    "                print ('===================')\n",
    "            for i in range(num_ai_agents):\n",
    "                agent_tags = sum(agents[i].tag_hist)\n",
    "                ep_tags += agent_tags\n",
    "                cum_agent_tags[i] += agent_tags\n",
    "\n",
    "                agent_reward = sum(agents[i].rewards)\n",
    "                ep_rewards += agent_reward\n",
    "                cum_agent_rewards[i] += agent_reward\n",
    "\n",
    "                agent_US_hits = sum(agents[i].US_hits)\n",
    "                agent_THEM_hits = sum(agents[i].THEM_hits)\n",
    "                ep_US_hits += agent_US_hits\n",
    "                ep_THEM_hits += agent_THEM_hits\n",
    "                cum_agent_US_hits[i] += agent_US_hits\n",
    "                cum_agent_THEM_hits[i] += agent_THEM_hits\n",
    "        \n",
    "                if verbose:\n",
    "                    print (\"Agent{} aggressiveness is {:.2f}\".format(i, agent_tags/frame))\n",
    "                    print (\"Agent{} reward is {:d}\".format(i, agent_reward))\n",
    "                    print('US agents hit = {}'.format(agent_US_hits))\n",
    "                    print('THEM agents hit = {}'.format(agent_THEM_hits ))\n",
    "        \n",
    "            cum_rewards += ep_rewards\n",
    "            cum_tags += ep_tags\n",
    "            cum_US_hits += ep_US_hits\n",
    "            cum_THEM_hits += ep_THEM_hits\n",
    "    \n",
    "            if verbose:\n",
    "                print ('\\nStatistics in Aggregate')\n",
    "                print ('=======================')\n",
    "                print ('Total rewards gathered = {}'.format(ep_rewards))\n",
    "                print ('Num laser fired = {}'.format(ep_tags))\n",
    "                print ('Total US Hit (friendly fire) = {}'.format(ep_US_hits))\n",
    "                print ('Total THEM Hit = {}'.format(ep_THEM_hits))\n",
    "                print ('friendly fire (%) = {0:.3f}'.format(ep_US_hits/(ep_US_hits+ep_THEM_hits+1e-7)))\n",
    "\n",
    "            if verbose:\n",
    "                print ('\\nStatistics by Tribe')\n",
    "                print ('===================')\n",
    "            for i, t in enumerate(tribes):\n",
    "                if t.name is not 'Crazies':\n",
    "                    ep_tribe_reward = sum(t.sum_rewards())\n",
    "                    cum_tribe_rewards[i] += ep_tribe_reward\n",
    "                    if verbose:\n",
    "                        print ('Tribe {} has total reward of {}'.format(t.name, ep_tribe_reward))\n",
    "\n",
    "            for i in range(num_ai_agents):\n",
    "                agents[i].clear_history()\n",
    "\n",
    "        env.close()  # Close the rendering window\n",
    "        end = time.time()\n",
    "\n",
    "        print ('\\nAverage Statistics in Aggregate')\n",
    "        print ('=================================')\n",
    "        total_rewards = cum_rewards/max_episodes\n",
    "        print ('Total rewards gathered = {:.1f}'.format(total_rewards))\n",
    "        av_agent_reward[dir_num][eps_num] = cum_rewards/max_episodes/num_ai_agents\n",
    "        print ('Av. agent reward = {:.2f}'.format(av_agent_reward[dir_num][eps_num]))\n",
    "        print ('Num laser fired = {:.1f}'.format(cum_tags/max_episodes))\n",
    "        print ('Total US Hit (friendly fire) = {:.1f}'.format(cum_US_hits/max_episodes))\n",
    "        print ('Total THEM Hit = {:.1f}'.format(cum_THEM_hits/max_episodes))\n",
    "        print ('friendly fire (%) = {:.3f}'.format(cum_US_hits/(cum_US_hits+cum_THEM_hits+1e-7)))\n",
    "\n",
    "        print ('\\nAverage Statistics by Tribe')\n",
    "        print ('=============================')\n",
    "       \n",
    "        for i, tribe in enumerate(tribes):\n",
    "            if tribe.name is not 'Crazies':\n",
    "                tribe_reward = cum_tribe_rewards[i]/max_episodes\n",
    "                print ('Tribe {} has total reward of {:.1f}'.format(tribe.name, tribe_reward))    \n",
    "                \n",
    "                # Keep track of dominating team and the rewards gathered\n",
    "                if tribe_reward > dom_tribe_reward[dir_num][eps_num]:   \n",
    "                    dom_tribe_reward[dir_num][eps_num] = tribe_reward\n",
    "                    dominating_tribe[dir_num][eps_num]  = tribe.name\n",
    "\n",
    "        # Team dominance calculation                           \n",
    "        print ('Dominating Tribe: {}'.format(dominating_tribe[dir_num][eps_num]))\n",
    "        dominance[dir_num][eps_num] = dom_tribe_reward[dir_num][eps_num]/((total_rewards - \\\n",
    "                                                dom_tribe_reward[dir_num][eps_num]+1.1e-7)/(len(tribes)-1))    \n",
    "        print ('Team dominance: {0:.2f}x'.format(dominance[dir_num][eps_num]))\n",
    "\n",
    "        print ('\\nAverage Statistics by Agent')\n",
    "        print ('=============================')\n",
    "        for i in range(num_ai_agents):\n",
    "            print (\"Agent{} of {} aggressiveness is {:.2f}\".format(i, agents[i].tribe, \\\n",
    "                                                           cum_agent_tags[i]/(max_episodes*max_frames)))\n",
    "            print (\"Agent{} reward is {:.1f}\".format(i, cum_agent_rewards[i]/max_episodes))\n",
    "            print('US agents hit = {:.1f}'.format(cum_agent_US_hits[i]/max_episodes))\n",
    "            print('THEM agents hit = {:.1f}'.format(cum_agent_THEM_hits[i]/max_episodes))\n",
    "\n",
    "        print('Training time per epochs: {:.2f} sec'.format((end-start)/max_episodes))\n",
    "\n",
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "    \n",
    "for tribe in dominating_tribe:   # Dominating team\n",
    "    print(tribe)\n",
    "\n",
    "for value in dominance:      # Team dominance\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.3, 47.68888888888889, 44.7962962962963, 42.82962962962963, 45.81111111111111]\n",
      "[48.97777777777778, 54.507407407407406, 50.48148148148148, 50.51851851851852, 47.04814814814815]\n",
      "[50.03703703703704, 48.7, 49.47777777777778, 45.18518518518519, 48.98888888888889]\n",
      "[48.492592592592594, 43.166666666666664, 42.67777777777778, 41.10740740740741, 40.40740740740741]\n",
      "[47.833333333333336, 46.81481481481481, 46.7, 49.88518518518518, 0.0]\n",
      "[0.0, 0.0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "['Vikings', 'Vikings', 'Vikings', 'Vikings', 'Vikings']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', 'Franks']\n",
      "['Franks', 'Franks', 'Franks', 'Vikings', 'Vikings']\n",
      "['Franks', 'Franks', 'Franks', 'Franks', None]\n",
      "[None, None, None, None, None]\n",
      "[None, None, None, None, None]\n",
      "[1.4652014645454938, 1.7337973023457258, 1.6729426046886255, 2.831418422948887, 1.9958003542907217]\n",
      "[1.8125991053796198, 2.1544107258843255, 2.381227899733518, 1.9530502816338113, 2.7170441869724757]\n",
      "[3.464105154412225, 2.5100325830418266, 1.872173912148091, 2.2324371192771824, 2.3225490183554887]\n",
      "[1.1679167670149864, 1.9575551771714883, 1.5072287315516883, 1.7332660602556718, 2.6663815207871986]\n",
      "[2.006514656953389, 1.768072737243309, 2.0426418713144088, 1.7533788482950885, 0.0]\n",
      "[0.0, 0.0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Note: Statistics for Research Report        \n",
    "for reward in av_agent_reward:   # Average agent reward\n",
    "    print(reward)\n",
    "    \n",
    "for tribe in dominating_tribe:   # Dominating team\n",
    "    print(tribe)\n",
    "\n",
    "for value in dominance:      # Team dominance\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
